{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4188f49",
   "metadata": {},
   "source": [
    "# Projet App Stat (étude basique de la database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cd57232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e-09, 2.51188643e-07, 6.30957344e-05, 1.58489319e-02,\n",
       "       3.98107171e+00, 1.00000000e+03])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.logspace(-9, 3, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d1c270a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e-02, 2.51188643e+00, 6.30957344e+02, 1.58489319e+05,\n",
       "       3.98107171e+07, 1.00000000e+10])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(-2, 10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "777c0713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange (0, 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "37b482bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# options d'affichage\n",
    "pd.set_option(\"display.min_rows\", 20)\n",
    "pd.set_option(\"display.max_column\", 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ac9049c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>pc</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>188</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>756</td>\n",
       "      <td>2549</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.7</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>905</td>\n",
       "      <td>1988</td>\n",
       "      <td>2631</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>563</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0.9</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1263</td>\n",
       "      <td>1716</td>\n",
       "      <td>2603</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>615</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>131</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1216</td>\n",
       "      <td>1786</td>\n",
       "      <td>2769</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1821</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0.6</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>1208</td>\n",
       "      <td>1212</td>\n",
       "      <td>1411</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1859</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.7</td>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1004</td>\n",
       "      <td>1654</td>\n",
       "      <td>1067</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1821</td>\n",
       "      <td>0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>139</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>381</td>\n",
       "      <td>1018</td>\n",
       "      <td>3220</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1954</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.8</td>\n",
       "      <td>187</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>512</td>\n",
       "      <td>1149</td>\n",
       "      <td>700</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1445</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0.7</td>\n",
       "      <td>174</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>386</td>\n",
       "      <td>836</td>\n",
       "      <td>1099</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>509</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>93</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>1137</td>\n",
       "      <td>1224</td>\n",
       "      <td>513</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>1617</td>\n",
       "      <td>1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>0.8</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>743</td>\n",
       "      <td>1426</td>\n",
       "      <td>296</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>1882</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0.8</td>\n",
       "      <td>113</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>743</td>\n",
       "      <td>3579</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>674</td>\n",
       "      <td>1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0.2</td>\n",
       "      <td>198</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>576</td>\n",
       "      <td>1809</td>\n",
       "      <td>1180</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>1467</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.6</td>\n",
       "      <td>122</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>888</td>\n",
       "      <td>1099</td>\n",
       "      <td>3962</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>858</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0.1</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>528</td>\n",
       "      <td>1416</td>\n",
       "      <td>3978</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>794</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>106</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>1222</td>\n",
       "      <td>1890</td>\n",
       "      <td>668</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1965</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0.2</td>\n",
       "      <td>187</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>915</td>\n",
       "      <td>1965</td>\n",
       "      <td>2032</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1911</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>0.7</td>\n",
       "      <td>108</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>868</td>\n",
       "      <td>1632</td>\n",
       "      <td>3057</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1512</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0.1</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>336</td>\n",
       "      <td>670</td>\n",
       "      <td>869</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>510</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0.9</td>\n",
       "      <td>168</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>483</td>\n",
       "      <td>754</td>\n",
       "      <td>3919</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  \\\n",
       "0               842     0          2.2         0   1       0           7   \n",
       "1              1021     1          0.5         1   0       1          53   \n",
       "2               563     1          0.5         1   2       1          41   \n",
       "3               615     1          2.5         0   0       0          10   \n",
       "4              1821     1          1.2         0  13       1          44   \n",
       "5              1859     0          0.5         1   3       0          22   \n",
       "6              1821     0          1.7         0   4       1          10   \n",
       "7              1954     0          0.5         1   0       0          24   \n",
       "8              1445     1          0.5         0   0       0          53   \n",
       "9               509     1          0.6         1   2       1           9   \n",
       "...             ...   ...          ...       ...  ..     ...         ...   \n",
       "1990           1617     1          2.4         0   8       1          36   \n",
       "1991           1882     0          2.0         0  11       1          44   \n",
       "1992            674     1          2.9         1   1       0          21   \n",
       "1993           1467     1          0.5         0   0       0          18   \n",
       "1994            858     0          2.2         0   1       0          50   \n",
       "1995            794     1          0.5         1   0       1           2   \n",
       "1996           1965     1          2.6         1   0       0          39   \n",
       "1997           1911     0          0.9         1   1       1          36   \n",
       "1998           1512     0          0.9         0   4       1          46   \n",
       "1999            510     1          2.0         1   5       1          45   \n",
       "\n",
       "      m_dep  mobile_wt  n_cores  pc  px_height  px_width   ram  sc_h  sc_w  \\\n",
       "0       0.6        188        2   2         20       756  2549     9     7   \n",
       "1       0.7        136        3   6        905      1988  2631    17     3   \n",
       "2       0.9        145        5   6       1263      1716  2603    11     2   \n",
       "3       0.8        131        6   9       1216      1786  2769    16     8   \n",
       "4       0.6        141        2  14       1208      1212  1411     8     2   \n",
       "5       0.7        164        1   7       1004      1654  1067    17     1   \n",
       "6       0.8        139        8  10        381      1018  3220    13     8   \n",
       "7       0.8        187        4   0        512      1149   700    16     3   \n",
       "8       0.7        174        7  14        386       836  1099    17     1   \n",
       "9       0.1         93        5  15       1137      1224   513    19    10   \n",
       "...     ...        ...      ...  ..        ...       ...   ...   ...   ...   \n",
       "1990    0.8         85        1   9        743      1426   296     5     3   \n",
       "1991    0.8        113        8  19          4       743  3579    19     8   \n",
       "1992    0.2        198        3   4        576      1809  1180     6     3   \n",
       "1993    0.6        122        5   0        888      1099  3962    15    11   \n",
       "1994    0.1         84        1   2        528      1416  3978    17    16   \n",
       "1995    0.8        106        6  14       1222      1890   668    13     4   \n",
       "1996    0.2        187        4   3        915      1965  2032    11    10   \n",
       "1997    0.7        108        8   3        868      1632  3057     9     1   \n",
       "1998    0.1        145        5   5        336       670   869    18    10   \n",
       "1999    0.9        168        6  16        483       754  3919    19     4   \n",
       "\n",
       "      talk_time  three_g  touch_screen  wifi  price_range  \n",
       "0            19        0             0     1            1  \n",
       "1             7        1             1     0            2  \n",
       "2             9        1             1     0            2  \n",
       "3            11        1             0     0            2  \n",
       "4            15        1             1     0            1  \n",
       "5            10        1             0     0            1  \n",
       "6            18        1             0     1            3  \n",
       "7             5        1             1     1            0  \n",
       "8            20        1             0     0            0  \n",
       "9            12        1             0     0            0  \n",
       "...         ...      ...           ...   ...          ...  \n",
       "1990          7        1             0     0            0  \n",
       "1991         20        1             1     0            3  \n",
       "1992          4        1             1     1            0  \n",
       "1993          5        1             1     1            3  \n",
       "1994          3        1             1     0            3  \n",
       "1995         19        1             1     0            0  \n",
       "1996         16        1             1     1            2  \n",
       "1997          5        1             1     0            3  \n",
       "1998         19        1             1     1            0  \n",
       "1999          2        1             1     1            3  \n",
       "\n",
       "[2000 rows x 21 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./MobilePriceDescription/train.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8973f09f",
   "metadata": {},
   "source": [
    "# 1/ Pre-processing ( traitement de base de la donnée)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f904e11c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>pc</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [battery_power, blue, clock_speed, dual_sim, fc, four_g, int_memory, m_dep, mobile_wt, n_cores, pc, px_height, px_width, ram, sc_h, sc_w, talk_time, three_g, touch_screen, wifi, price_range]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b94406c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    2000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b53d3d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   battery_power  2000 non-null   int64  \n",
      " 1   blue           2000 non-null   int64  \n",
      " 2   clock_speed    2000 non-null   float64\n",
      " 3   dual_sim       2000 non-null   int64  \n",
      " 4   fc             2000 non-null   int64  \n",
      " 5   four_g         2000 non-null   int64  \n",
      " 6   int_memory     2000 non-null   int64  \n",
      " 7   m_dep          2000 non-null   float64\n",
      " 8   mobile_wt      2000 non-null   int64  \n",
      " 9   n_cores        2000 non-null   int64  \n",
      " 10  pc             2000 non-null   int64  \n",
      " 11  px_height      2000 non-null   int64  \n",
      " 12  px_width       2000 non-null   int64  \n",
      " 13  ram            2000 non-null   int64  \n",
      " 14  sc_h           2000 non-null   int64  \n",
      " 15  sc_w           2000 non-null   int64  \n",
      " 16  talk_time      2000 non-null   int64  \n",
      " 17  three_g        2000 non-null   int64  \n",
      " 18  touch_screen   2000 non-null   int64  \n",
      " 19  wifi           2000 non-null   int64  \n",
      " 20  price_range    2000 non-null   int64  \n",
      "dtypes: float64(2), int64(19)\n",
      "memory usage: 328.2 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c9d0909",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_count(df,range_):\n",
    "    for i in range_:\n",
    "        if df.columns[i] == 'price_range':\n",
    "            print(df.columns[i], \" : \", len(df[df.columns[i]].unique()), \" \", df[df.columns[i]].unique())\n",
    "        else :\n",
    "            print(df.columns[i], \" : \", len(df[df.columns[i]].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c96b000e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "battery_power  :  1094\n",
      "blue  :  2\n",
      "clock_speed  :  26\n",
      "dual_sim  :  2\n",
      "fc  :  20\n",
      "four_g  :  2\n",
      "int_memory  :  63\n",
      "m_dep  :  10\n",
      "mobile_wt  :  121\n",
      "n_cores  :  8\n",
      "pc  :  21\n",
      "px_height  :  1137\n",
      "px_width  :  1109\n",
      "ram  :  1562\n",
      "sc_h  :  15\n",
      "sc_w  :  19\n",
      "talk_time  :  19\n",
      "three_g  :  2\n",
      "touch_screen  :  2\n",
      "wifi  :  2\n",
      "price_range  :  4   [1 2 3 0]\n"
     ]
    }
   ],
   "source": [
    "unique_count(df, range(0,len(df.axes[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55162e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dual_value(df,range_):\n",
    "    for i in range_:\n",
    "        if len(df[df.columns[i]].unique()) < 3:\n",
    "            print(df.columns[i], \" : \", df[df.columns[i]].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "806d2591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blue  :  [0 1]\n",
      "dual_sim  :  [0 1]\n",
      "four_g  :  [0 1]\n",
      "three_g  :  [0 1]\n",
      "touch_screen  :  [0 1]\n",
      "wifi  :  [1 0]\n"
     ]
    }
   ],
   "source": [
    "dual_value(df, range(0,len(df.axes[1])))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "72abd47b",
   "metadata": {},
   "source": [
    "Pas besoin d'encoder ces valeurs là :\n",
    "blue  :  [0 1]\n",
    "dual_sim  :  [0 1]\n",
    "four_g  :  [0 1]\n",
    "three_g  :  [0 1]\n",
    "touch_screen  :  [0 1]\n",
    "wifi  :  [1 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "47f662d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_dual_value(df,range_):\n",
    "    list_ = []\n",
    "    for i in range_:\n",
    "        if len(df[df.columns[i]].unique()) > 2 and df.columns[i] != 'price_range':\n",
    "            list_.append(df.columns[i])\n",
    "    return list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5549f848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['battery_power',\n",
       " 'clock_speed',\n",
       " 'fc',\n",
       " 'int_memory',\n",
       " 'm_dep',\n",
       " 'mobile_wt',\n",
       " 'n_cores',\n",
       " 'pc',\n",
       " 'px_height',\n",
       " 'px_width',\n",
       " 'ram',\n",
       " 'sc_h',\n",
       " 'sc_w',\n",
       " 'talk_time']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_columns_encoding = no_dual_value(df, range(0,len(df.axes[1])))\n",
    "list_columns_encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63aa0d17",
   "metadata": {},
   "source": [
    "# 2/ Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "16067d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler, PowerTransformer, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "730c80be",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fb7c06b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Quant_enc = pd.DataFrame(scaler.fit_transform(df[list_columns_encoding]), columns=[list_columns_encoding])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "090a1098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>pc</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.902597</td>\n",
       "      <td>0</td>\n",
       "      <td>0.830779</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.762495</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.380644</td>\n",
       "      <td>0.340740</td>\n",
       "      <td>1.349249</td>\n",
       "      <td>-1.101971</td>\n",
       "      <td>-1.305750</td>\n",
       "      <td>-1.408949</td>\n",
       "      <td>-1.146784</td>\n",
       "      <td>0.391703</td>\n",
       "      <td>-0.784983</td>\n",
       "      <td>0.283103</td>\n",
       "      <td>1.462493</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.495139</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.253064</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.992890</td>\n",
       "      <td>1</td>\n",
       "      <td>1.155024</td>\n",
       "      <td>0.687548</td>\n",
       "      <td>-0.120059</td>\n",
       "      <td>-0.664768</td>\n",
       "      <td>-0.645989</td>\n",
       "      <td>0.585778</td>\n",
       "      <td>1.704465</td>\n",
       "      <td>0.467317</td>\n",
       "      <td>1.114266</td>\n",
       "      <td>-0.635317</td>\n",
       "      <td>-0.734267</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.537686</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.253064</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.532099</td>\n",
       "      <td>1</td>\n",
       "      <td>0.493546</td>\n",
       "      <td>1.381165</td>\n",
       "      <td>0.134244</td>\n",
       "      <td>0.209639</td>\n",
       "      <td>-0.645989</td>\n",
       "      <td>1.392684</td>\n",
       "      <td>1.074968</td>\n",
       "      <td>0.441498</td>\n",
       "      <td>-0.310171</td>\n",
       "      <td>-0.864922</td>\n",
       "      <td>-0.368140</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.419319</td>\n",
       "      <td>1</td>\n",
       "      <td>1.198517</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.992890</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.215274</td>\n",
       "      <td>1.034357</td>\n",
       "      <td>-0.261339</td>\n",
       "      <td>0.646842</td>\n",
       "      <td>-0.151168</td>\n",
       "      <td>1.286750</td>\n",
       "      <td>1.236971</td>\n",
       "      <td>0.594569</td>\n",
       "      <td>0.876859</td>\n",
       "      <td>0.512708</td>\n",
       "      <td>-0.002014</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.325906</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.395011</td>\n",
       "      <td>0</td>\n",
       "      <td>2.002254</td>\n",
       "      <td>1</td>\n",
       "      <td>0.658915</td>\n",
       "      <td>0.340740</td>\n",
       "      <td>0.021220</td>\n",
       "      <td>-1.101971</td>\n",
       "      <td>0.673534</td>\n",
       "      <td>1.268718</td>\n",
       "      <td>-0.091452</td>\n",
       "      <td>-0.657666</td>\n",
       "      <td>-1.022389</td>\n",
       "      <td>-0.864922</td>\n",
       "      <td>0.730240</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.412405</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.253064</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.301703</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.553795</td>\n",
       "      <td>0.687548</td>\n",
       "      <td>0.671107</td>\n",
       "      <td>-1.539175</td>\n",
       "      <td>-0.481048</td>\n",
       "      <td>0.808917</td>\n",
       "      <td>0.931480</td>\n",
       "      <td>-0.974874</td>\n",
       "      <td>1.114266</td>\n",
       "      <td>-1.094526</td>\n",
       "      <td>-0.185077</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.325906</td>\n",
       "      <td>0</td>\n",
       "      <td>0.217884</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.071307</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.215274</td>\n",
       "      <td>1.034357</td>\n",
       "      <td>-0.035292</td>\n",
       "      <td>1.521249</td>\n",
       "      <td>0.013773</td>\n",
       "      <td>-0.595280</td>\n",
       "      <td>-0.540431</td>\n",
       "      <td>1.010444</td>\n",
       "      <td>0.164641</td>\n",
       "      <td>0.512708</td>\n",
       "      <td>1.279430</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.628654</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.253064</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.992890</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.443549</td>\n",
       "      <td>1.034357</td>\n",
       "      <td>1.320993</td>\n",
       "      <td>-0.227564</td>\n",
       "      <td>-1.635631</td>\n",
       "      <td>-0.300016</td>\n",
       "      <td>-0.237254</td>\n",
       "      <td>-1.313291</td>\n",
       "      <td>0.876859</td>\n",
       "      <td>-0.635317</td>\n",
       "      <td>-1.100394</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.470015</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.253064</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.992890</td>\n",
       "      <td>0</td>\n",
       "      <td>1.155024</td>\n",
       "      <td>0.687548</td>\n",
       "      <td>0.953666</td>\n",
       "      <td>1.084046</td>\n",
       "      <td>0.673534</td>\n",
       "      <td>-0.584011</td>\n",
       "      <td>-0.961638</td>\n",
       "      <td>-0.945367</td>\n",
       "      <td>1.114266</td>\n",
       "      <td>-1.094526</td>\n",
       "      <td>1.645557</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1.660607</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.130485</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.532099</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.270397</td>\n",
       "      <td>-1.393304</td>\n",
       "      <td>-1.335064</td>\n",
       "      <td>0.209639</td>\n",
       "      <td>0.838474</td>\n",
       "      <td>1.108689</td>\n",
       "      <td>-0.063680</td>\n",
       "      <td>-1.485727</td>\n",
       "      <td>1.589078</td>\n",
       "      <td>0.971917</td>\n",
       "      <td>0.181050</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>0.861540</td>\n",
       "      <td>1</td>\n",
       "      <td>1.075937</td>\n",
       "      <td>0</td>\n",
       "      <td>0.850275</td>\n",
       "      <td>1</td>\n",
       "      <td>0.217930</td>\n",
       "      <td>1.034357</td>\n",
       "      <td>-1.561112</td>\n",
       "      <td>-1.539175</td>\n",
       "      <td>-0.151168</td>\n",
       "      <td>0.220642</td>\n",
       "      <td>0.403814</td>\n",
       "      <td>-1.685827</td>\n",
       "      <td>-1.734608</td>\n",
       "      <td>-0.635317</td>\n",
       "      <td>-0.734267</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>1.464760</td>\n",
       "      <td>0</td>\n",
       "      <td>0.585621</td>\n",
       "      <td>0</td>\n",
       "      <td>1.541463</td>\n",
       "      <td>1</td>\n",
       "      <td>0.658915</td>\n",
       "      <td>1.034357</td>\n",
       "      <td>-0.769946</td>\n",
       "      <td>1.521249</td>\n",
       "      <td>1.498235</td>\n",
       "      <td>-1.445011</td>\n",
       "      <td>-1.176870</td>\n",
       "      <td>1.341484</td>\n",
       "      <td>1.589078</td>\n",
       "      <td>0.512708</td>\n",
       "      <td>1.645557</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>-1.285017</td>\n",
       "      <td>1</td>\n",
       "      <td>1.688833</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.762495</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.608919</td>\n",
       "      <td>-1.046495</td>\n",
       "      <td>1.631808</td>\n",
       "      <td>-0.664768</td>\n",
       "      <td>-0.975869</td>\n",
       "      <td>-0.155764</td>\n",
       "      <td>1.290200</td>\n",
       "      <td>-0.870675</td>\n",
       "      <td>-1.497202</td>\n",
       "      <td>-0.635317</td>\n",
       "      <td>-1.283457</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>0.520094</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.253064</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.992890</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.774288</td>\n",
       "      <td>0.340740</td>\n",
       "      <td>-0.515642</td>\n",
       "      <td>0.209639</td>\n",
       "      <td>-1.635631</td>\n",
       "      <td>0.547461</td>\n",
       "      <td>-0.352970</td>\n",
       "      <td>1.694655</td>\n",
       "      <td>0.639453</td>\n",
       "      <td>1.201522</td>\n",
       "      <td>-1.100394</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>-0.866176</td>\n",
       "      <td>0</td>\n",
       "      <td>0.830779</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.762495</td>\n",
       "      <td>0</td>\n",
       "      <td>0.989655</td>\n",
       "      <td>-1.393304</td>\n",
       "      <td>-1.589368</td>\n",
       "      <td>-1.539175</td>\n",
       "      <td>-1.305750</td>\n",
       "      <td>-0.263953</td>\n",
       "      <td>0.380671</td>\n",
       "      <td>1.709409</td>\n",
       "      <td>1.114266</td>\n",
       "      <td>2.349547</td>\n",
       "      <td>-1.466521</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>-1.011860</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.253064</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.992890</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.656260</td>\n",
       "      <td>1.034357</td>\n",
       "      <td>-0.967737</td>\n",
       "      <td>0.646842</td>\n",
       "      <td>0.673534</td>\n",
       "      <td>1.300273</td>\n",
       "      <td>1.477661</td>\n",
       "      <td>-1.342799</td>\n",
       "      <td>0.164641</td>\n",
       "      <td>-0.405712</td>\n",
       "      <td>1.462493</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1.653694</td>\n",
       "      <td>1</td>\n",
       "      <td>1.321096</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.992890</td>\n",
       "      <td>0</td>\n",
       "      <td>0.383299</td>\n",
       "      <td>-1.046495</td>\n",
       "      <td>1.320993</td>\n",
       "      <td>-0.227564</td>\n",
       "      <td>-1.140810</td>\n",
       "      <td>0.608317</td>\n",
       "      <td>1.651235</td>\n",
       "      <td>-0.085031</td>\n",
       "      <td>-0.310171</td>\n",
       "      <td>0.971917</td>\n",
       "      <td>0.913303</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1.530773</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.762748</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.762495</td>\n",
       "      <td>1</td>\n",
       "      <td>0.217930</td>\n",
       "      <td>0.687548</td>\n",
       "      <td>-0.911225</td>\n",
       "      <td>1.521249</td>\n",
       "      <td>-1.140810</td>\n",
       "      <td>0.502383</td>\n",
       "      <td>0.880565</td>\n",
       "      <td>0.860139</td>\n",
       "      <td>-0.784983</td>\n",
       "      <td>-1.094526</td>\n",
       "      <td>-1.100394</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.622527</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.762748</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.071307</td>\n",
       "      <td>1</td>\n",
       "      <td>0.769162</td>\n",
       "      <td>-1.393304</td>\n",
       "      <td>0.134244</td>\n",
       "      <td>0.209639</td>\n",
       "      <td>-0.810929</td>\n",
       "      <td>-0.696707</td>\n",
       "      <td>-1.345816</td>\n",
       "      <td>-1.157454</td>\n",
       "      <td>1.351672</td>\n",
       "      <td>0.971917</td>\n",
       "      <td>1.462493</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>-1.658331</td>\n",
       "      <td>1</td>\n",
       "      <td>0.585621</td>\n",
       "      <td>1</td>\n",
       "      <td>0.159088</td>\n",
       "      <td>1</td>\n",
       "      <td>0.714039</td>\n",
       "      <td>1.381165</td>\n",
       "      <td>0.784130</td>\n",
       "      <td>0.646842</td>\n",
       "      <td>1.003414</td>\n",
       "      <td>-0.365380</td>\n",
       "      <td>-1.151413</td>\n",
       "      <td>1.655004</td>\n",
       "      <td>1.589078</td>\n",
       "      <td>-0.405712</td>\n",
       "      <td>-1.649584</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      battery_power  blue  clock_speed  dual_sim        fc  four_g  \\\n",
       "0         -0.902597     0     0.830779         0 -0.762495       0   \n",
       "1         -0.495139     1    -1.253064         1 -0.992890       1   \n",
       "2         -1.537686     1    -1.253064         1 -0.532099       1   \n",
       "3         -1.419319     1     1.198517         0 -0.992890       0   \n",
       "4          1.325906     1    -0.395011         0  2.002254       1   \n",
       "5          1.412405     0    -1.253064         1 -0.301703       0   \n",
       "6          1.325906     0     0.217884         0 -0.071307       1   \n",
       "7          1.628654     0    -1.253064         1 -0.992890       0   \n",
       "8          0.470015     1    -1.253064         0 -0.992890       0   \n",
       "9         -1.660607     1    -1.130485         1 -0.532099       1   \n",
       "...             ...   ...          ...       ...       ...     ...   \n",
       "1990       0.861540     1     1.075937         0  0.850275       1   \n",
       "1991       1.464760     0     0.585621         0  1.541463       1   \n",
       "1992      -1.285017     1     1.688833         1 -0.762495       0   \n",
       "1993       0.520094     1    -1.253064         0 -0.992890       0   \n",
       "1994      -0.866176     0     0.830779         0 -0.762495       0   \n",
       "1995      -1.011860     1    -1.253064         1 -0.992890       1   \n",
       "1996       1.653694     1     1.321096         1 -0.992890       0   \n",
       "1997       1.530773     0    -0.762748         1 -0.762495       1   \n",
       "1998       0.622527     0    -0.762748         0 -0.071307       1   \n",
       "1999      -1.658331     1     0.585621         1  0.159088       1   \n",
       "\n",
       "      int_memory     m_dep  mobile_wt   n_cores        pc  px_height  \\\n",
       "0      -1.380644  0.340740   1.349249 -1.101971 -1.305750  -1.408949   \n",
       "1       1.155024  0.687548  -0.120059 -0.664768 -0.645989   0.585778   \n",
       "2       0.493546  1.381165   0.134244  0.209639 -0.645989   1.392684   \n",
       "3      -1.215274  1.034357  -0.261339  0.646842 -0.151168   1.286750   \n",
       "4       0.658915  0.340740   0.021220 -1.101971  0.673534   1.268718   \n",
       "5      -0.553795  0.687548   0.671107 -1.539175 -0.481048   0.808917   \n",
       "6      -1.215274  1.034357  -0.035292  1.521249  0.013773  -0.595280   \n",
       "7      -0.443549  1.034357   1.320993 -0.227564 -1.635631  -0.300016   \n",
       "8       1.155024  0.687548   0.953666  1.084046  0.673534  -0.584011   \n",
       "9      -1.270397 -1.393304  -1.335064  0.209639  0.838474   1.108689   \n",
       "...          ...       ...        ...       ...       ...        ...   \n",
       "1990    0.217930  1.034357  -1.561112 -1.539175 -0.151168   0.220642   \n",
       "1991    0.658915  1.034357  -0.769946  1.521249  1.498235  -1.445011   \n",
       "1992   -0.608919 -1.046495   1.631808 -0.664768 -0.975869  -0.155764   \n",
       "1993   -0.774288  0.340740  -0.515642  0.209639 -1.635631   0.547461   \n",
       "1994    0.989655 -1.393304  -1.589368 -1.539175 -1.305750  -0.263953   \n",
       "1995   -1.656260  1.034357  -0.967737  0.646842  0.673534   1.300273   \n",
       "1996    0.383299 -1.046495   1.320993 -0.227564 -1.140810   0.608317   \n",
       "1997    0.217930  0.687548  -0.911225  1.521249 -1.140810   0.502383   \n",
       "1998    0.769162 -1.393304   0.134244  0.209639 -0.810929  -0.696707   \n",
       "1999    0.714039  1.381165   0.784130  0.646842  1.003414  -0.365380   \n",
       "\n",
       "      px_width       ram      sc_h      sc_w  talk_time  three_g  \\\n",
       "0    -1.146784  0.391703 -0.784983  0.283103   1.462493        0   \n",
       "1     1.704465  0.467317  1.114266 -0.635317  -0.734267        1   \n",
       "2     1.074968  0.441498 -0.310171 -0.864922  -0.368140        1   \n",
       "3     1.236971  0.594569  0.876859  0.512708  -0.002014        1   \n",
       "4    -0.091452 -0.657666 -1.022389 -0.864922   0.730240        1   \n",
       "5     0.931480 -0.974874  1.114266 -1.094526  -0.185077        1   \n",
       "6    -0.540431  1.010444  0.164641  0.512708   1.279430        1   \n",
       "7    -0.237254 -1.313291  0.876859 -0.635317  -1.100394        1   \n",
       "8    -0.961638 -0.945367  1.114266 -1.094526   1.645557        1   \n",
       "9    -0.063680 -1.485727  1.589078  0.971917   0.181050        1   \n",
       "...        ...       ...       ...       ...        ...      ...   \n",
       "1990  0.403814 -1.685827 -1.734608 -0.635317  -0.734267        1   \n",
       "1991 -1.176870  1.341484  1.589078  0.512708   1.645557        1   \n",
       "1992  1.290200 -0.870675 -1.497202 -0.635317  -1.283457        1   \n",
       "1993 -0.352970  1.694655  0.639453  1.201522  -1.100394        1   \n",
       "1994  0.380671  1.709409  1.114266  2.349547  -1.466521        1   \n",
       "1995  1.477661 -1.342799  0.164641 -0.405712   1.462493        1   \n",
       "1996  1.651235 -0.085031 -0.310171  0.971917   0.913303        1   \n",
       "1997  0.880565  0.860139 -0.784983 -1.094526  -1.100394        1   \n",
       "1998 -1.345816 -1.157454  1.351672  0.971917   1.462493        1   \n",
       "1999 -1.151413  1.655004  1.589078 -0.405712  -1.649584        1   \n",
       "\n",
       "      touch_screen  wifi  price_range  \n",
       "0                0     1            1  \n",
       "1                1     0            2  \n",
       "2                1     0            2  \n",
       "3                0     0            2  \n",
       "4                1     0            1  \n",
       "5                0     0            1  \n",
       "6                0     1            3  \n",
       "7                1     1            0  \n",
       "8                0     0            0  \n",
       "9                0     0            0  \n",
       "...            ...   ...          ...  \n",
       "1990             0     0            0  \n",
       "1991             1     0            3  \n",
       "1992             1     1            0  \n",
       "1993             1     1            3  \n",
       "1994             1     0            3  \n",
       "1995             1     0            0  \n",
       "1996             1     1            2  \n",
       "1997             1     0            3  \n",
       "1998             1     1            0  \n",
       "1999             1     1            3  \n",
       "\n",
       "[2000 rows x 21 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replace old columns by new columns :\n",
    "df[list_columns_encoding] = Quant_enc[list_columns_encoding]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c54b2cb",
   "metadata": {},
   "source": [
    "# 3/ Variable selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "efeda6c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "cor = df.corr()\n",
    "sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "72d1bca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>pc</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>188</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>756</td>\n",
       "      <td>2549</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.7</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>905</td>\n",
       "      <td>1988</td>\n",
       "      <td>2631</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>563</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0.9</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1263</td>\n",
       "      <td>1716</td>\n",
       "      <td>2603</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>615</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>131</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1216</td>\n",
       "      <td>1786</td>\n",
       "      <td>2769</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1821</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0.6</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>1208</td>\n",
       "      <td>1212</td>\n",
       "      <td>1411</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1859</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0.7</td>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1004</td>\n",
       "      <td>1654</td>\n",
       "      <td>1067</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1821</td>\n",
       "      <td>0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>139</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>381</td>\n",
       "      <td>1018</td>\n",
       "      <td>3220</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1954</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0.8</td>\n",
       "      <td>187</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>512</td>\n",
       "      <td>1149</td>\n",
       "      <td>700</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1445</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0.7</td>\n",
       "      <td>174</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>386</td>\n",
       "      <td>836</td>\n",
       "      <td>1099</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>509</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>93</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>1137</td>\n",
       "      <td>1224</td>\n",
       "      <td>513</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>1617</td>\n",
       "      <td>1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>0.8</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>743</td>\n",
       "      <td>1426</td>\n",
       "      <td>296</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>1882</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0.8</td>\n",
       "      <td>113</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>743</td>\n",
       "      <td>3579</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>674</td>\n",
       "      <td>1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0.2</td>\n",
       "      <td>198</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>576</td>\n",
       "      <td>1809</td>\n",
       "      <td>1180</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>1467</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.6</td>\n",
       "      <td>122</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>888</td>\n",
       "      <td>1099</td>\n",
       "      <td>3962</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>858</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0.1</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>528</td>\n",
       "      <td>1416</td>\n",
       "      <td>3978</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>794</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>106</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>1222</td>\n",
       "      <td>1890</td>\n",
       "      <td>668</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1965</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0.2</td>\n",
       "      <td>187</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>915</td>\n",
       "      <td>1965</td>\n",
       "      <td>2032</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1911</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>0.7</td>\n",
       "      <td>108</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>868</td>\n",
       "      <td>1632</td>\n",
       "      <td>3057</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1512</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0.1</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>336</td>\n",
       "      <td>670</td>\n",
       "      <td>869</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>510</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0.9</td>\n",
       "      <td>168</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>483</td>\n",
       "      <td>754</td>\n",
       "      <td>3919</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      battery_power  blue  clock_speed  dual_sim  int_memory  m_dep  \\\n",
       "0               842     0          2.2         0           7    0.6   \n",
       "1              1021     1          0.5         1          53    0.7   \n",
       "2               563     1          0.5         1          41    0.9   \n",
       "3               615     1          2.5         0          10    0.8   \n",
       "4              1821     1          1.2         0          44    0.6   \n",
       "5              1859     0          0.5         1          22    0.7   \n",
       "6              1821     0          1.7         0          10    0.8   \n",
       "7              1954     0          0.5         1          24    0.8   \n",
       "8              1445     1          0.5         0          53    0.7   \n",
       "9               509     1          0.6         1           9    0.1   \n",
       "...             ...   ...          ...       ...         ...    ...   \n",
       "1990           1617     1          2.4         0          36    0.8   \n",
       "1991           1882     0          2.0         0          44    0.8   \n",
       "1992            674     1          2.9         1          21    0.2   \n",
       "1993           1467     1          0.5         0          18    0.6   \n",
       "1994            858     0          2.2         0          50    0.1   \n",
       "1995            794     1          0.5         1           2    0.8   \n",
       "1996           1965     1          2.6         1          39    0.2   \n",
       "1997           1911     0          0.9         1          36    0.7   \n",
       "1998           1512     0          0.9         0          46    0.1   \n",
       "1999            510     1          2.0         1          45    0.9   \n",
       "\n",
       "      mobile_wt  n_cores  pc  px_height  px_width   ram  sc_h  sc_w  \\\n",
       "0           188        2   2         20       756  2549     9     7   \n",
       "1           136        3   6        905      1988  2631    17     3   \n",
       "2           145        5   6       1263      1716  2603    11     2   \n",
       "3           131        6   9       1216      1786  2769    16     8   \n",
       "4           141        2  14       1208      1212  1411     8     2   \n",
       "5           164        1   7       1004      1654  1067    17     1   \n",
       "6           139        8  10        381      1018  3220    13     8   \n",
       "7           187        4   0        512      1149   700    16     3   \n",
       "8           174        7  14        386       836  1099    17     1   \n",
       "9            93        5  15       1137      1224   513    19    10   \n",
       "...         ...      ...  ..        ...       ...   ...   ...   ...   \n",
       "1990         85        1   9        743      1426   296     5     3   \n",
       "1991        113        8  19          4       743  3579    19     8   \n",
       "1992        198        3   4        576      1809  1180     6     3   \n",
       "1993        122        5   0        888      1099  3962    15    11   \n",
       "1994         84        1   2        528      1416  3978    17    16   \n",
       "1995        106        6  14       1222      1890   668    13     4   \n",
       "1996        187        4   3        915      1965  2032    11    10   \n",
       "1997        108        8   3        868      1632  3057     9     1   \n",
       "1998        145        5   5        336       670   869    18    10   \n",
       "1999        168        6  16        483       754  3919    19     4   \n",
       "\n",
       "      talk_time  three_g  touch_screen  wifi  price_range  \n",
       "0            19        0             0     1            1  \n",
       "1             7        1             1     0            2  \n",
       "2             9        1             1     0            2  \n",
       "3            11        1             0     0            2  \n",
       "4            15        1             1     0            1  \n",
       "5            10        1             0     0            1  \n",
       "6            18        1             0     1            3  \n",
       "7             5        1             1     1            0  \n",
       "8            20        1             0     0            0  \n",
       "9            12        1             0     0            0  \n",
       "...         ...      ...           ...   ...          ...  \n",
       "1990          7        1             0     0            0  \n",
       "1991         20        1             1     0            3  \n",
       "1992          4        1             1     1            0  \n",
       "1993          5        1             1     1            3  \n",
       "1994          3        1             1     0            3  \n",
       "1995         19        1             1     0            0  \n",
       "1996         16        1             1     1            2  \n",
       "1997          5        1             1     0            3  \n",
       "1998         19        1             1     1            0  \n",
       "1999          2        1             1     1            3  \n",
       "\n",
       "[2000 rows x 19 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop : fc, four_g\n",
    "df = df.drop(['fc', 'four_g'], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d01eb5",
   "metadata": {},
   "source": [
    "# 4/ Modelisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57921398",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "191af665",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "x = df.drop(['price_range'], axis=1)\n",
    "y = df['price_range']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c0c6cc80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c3f33efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0d09420a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09881043836960567\n",
      "0.9205767716665817\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error,r2_score\n",
    "lr.fit(x_train,y_train)\n",
    "\n",
    "# MSE\n",
    "y_pred = lr.predict(x_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(mse)\n",
    "\n",
    "print(lr.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "12620cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_x</th>\n",
       "      <th>0_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>battery_power</td>\n",
       "      <td>0.229881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blue</td>\n",
       "      <td>-0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clock_speed</td>\n",
       "      <td>-0.013398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dual_sim</td>\n",
       "      <td>-0.014872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fc</td>\n",
       "      <td>0.006571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>four_g</td>\n",
       "      <td>-0.020952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>int_memory</td>\n",
       "      <td>0.016255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>m_dep</td>\n",
       "      <td>-0.003185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mobile_wt</td>\n",
       "      <td>-0.030725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>n_cores</td>\n",
       "      <td>0.007319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pc</td>\n",
       "      <td>0.001292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>px_height</td>\n",
       "      <td>0.127669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>px_width</td>\n",
       "      <td>0.115859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ram</td>\n",
       "      <td>1.028027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sc_h</td>\n",
       "      <td>0.001329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sc_w</td>\n",
       "      <td>0.003146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>talk_time</td>\n",
       "      <td>-0.000625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>three_g</td>\n",
       "      <td>0.025947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>touch_screen</td>\n",
       "      <td>-0.003271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>wifi</td>\n",
       "      <td>-0.026117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0_x       0_y\n",
       "0   battery_power  0.229881\n",
       "1            blue -0.000183\n",
       "2     clock_speed -0.013398\n",
       "3        dual_sim -0.014872\n",
       "4              fc  0.006571\n",
       "5          four_g -0.020952\n",
       "6      int_memory  0.016255\n",
       "7           m_dep -0.003185\n",
       "8       mobile_wt -0.030725\n",
       "9         n_cores  0.007319\n",
       "10             pc  0.001292\n",
       "11      px_height  0.127669\n",
       "12       px_width  0.115859\n",
       "13            ram  1.028027\n",
       "14           sc_h  0.001329\n",
       "15           sc_w  0.003146\n",
       "16      talk_time -0.000625\n",
       "17        three_g  0.025947\n",
       "18   touch_screen -0.003271\n",
       "19           wifi -0.026117"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_coef = pd.DataFrame(lr.coef_)\n",
    "x_df = pd.DataFrame(x.columns)\n",
    "\n",
    "estimator_lr = pd.merge(x_df,lr_coef, how=\"right\", left_index=True, right_index=True)\n",
    "estimator_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b9a76a",
   "metadata": {},
   "source": [
    "### Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f8fa7727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.915"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random forest :\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 50, criterion = 'entropy')\n",
    "classifier.fit(x_train, y_train)\n",
    "classifier.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "232881bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9275"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#XGBoost :\n",
    "from xgboost import XGBClassifier\n",
    "XGBoost_model = XGBClassifier(learning_rate=0.1, n_estimators=100, max_depth=3)\n",
    "XGBoost_model.fit(x_train, y_train)\n",
    "XGBoost_model.score(x_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "20d87251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97        94\n",
      "           1       0.91      0.91      0.91       105\n",
      "           2       0.88      0.88      0.88        96\n",
      "           3       0.96      0.94      0.95       105\n",
      "\n",
      "    accuracy                           0.93       400\n",
      "   macro avg       0.93      0.93      0.93       400\n",
      "weighted avg       0.93      0.93      0.93       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = XGBoost_model.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a5e2b84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significant features from RFE Index(['battery_power', 'blue', 'fc', 'm_dep', 'mobile_wt', 'px_height',\n",
      "       'px_width', 'ram', 'sc_w', 'talk_time'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#feature selection\n",
    "\n",
    "X_trains_df=pd.DataFrame(x_train,columns=x_train.columns)\n",
    "from sklearn.feature_selection import RFE\n",
    "svc_lin=XGBClassifier(learning_rate=0.1, n_estimators=100, max_depth=3)\n",
    "svm_rfe_model=RFE(estimator=svc_lin)\n",
    "svm_rfe_model_fit=svm_rfe_model.fit(X_trains_df,y_train)\n",
    "feat_index = pd.Series(data = svm_rfe_model_fit.ranking_, index = x_train.columns)\n",
    "signi_feat_rfe = feat_index[feat_index==1].index\n",
    "print('Significant features from RFE',signi_feat_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "18fabf52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['battery_power',\n",
       " 'blue',\n",
       " 'fc',\n",
       " 'm_dep',\n",
       " 'mobile_wt',\n",
       " 'px_height',\n",
       " 'px_width',\n",
       " 'ram',\n",
       " 'sc_w',\n",
       " 'talk_time']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_feature = list(signi_feat_rfe)\n",
    "display(type(best_feature))\n",
    "best_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ef7eca14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9275"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trains_new=x_train[best_feature]\n",
    "X_tests_new=x_test[best_feature]\n",
    "\n",
    "XGBoost_model_rfe = XGBClassifier(learning_rate=0.1, n_estimators=100, max_depth=3)\n",
    "XGBoost_model_rfe.fit(X_trains_new, y_train)\n",
    "XGBoost_model_rfe.score(X_tests_new, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8044f3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96        94\n",
      "           1       0.92      0.90      0.91       105\n",
      "           2       0.88      0.90      0.89        96\n",
      "           3       0.96      0.94      0.95       105\n",
      "\n",
      "    accuracy                           0.93       400\n",
      "   macro avg       0.93      0.93      0.93       400\n",
      "weighted avg       0.93      0.93      0.93       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = XGBoost_model_rfe.predict(X_tests_new)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a6facf",
   "metadata": {},
   "source": [
    "# 5/ Prediction (A finir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e965f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>pc</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1043</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>193</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>226</td>\n",
       "      <td>1412</td>\n",
       "      <td>3476</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>841</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>0.8</td>\n",
       "      <td>191</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>746</td>\n",
       "      <td>857</td>\n",
       "      <td>3895</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1807</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.9</td>\n",
       "      <td>186</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1270</td>\n",
       "      <td>1366</td>\n",
       "      <td>2396</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1546</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>96</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>295</td>\n",
       "      <td>1752</td>\n",
       "      <td>3893</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1434</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>0.5</td>\n",
       "      <td>108</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>749</td>\n",
       "      <td>810</td>\n",
       "      <td>1773</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1464</td>\n",
       "      <td>1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>198</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>569</td>\n",
       "      <td>939</td>\n",
       "      <td>3506</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1718</td>\n",
       "      <td>0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>1.0</td>\n",
       "      <td>156</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1283</td>\n",
       "      <td>1374</td>\n",
       "      <td>3873</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>833</td>\n",
       "      <td>0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0.8</td>\n",
       "      <td>111</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1312</td>\n",
       "      <td>1880</td>\n",
       "      <td>1495</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1111</td>\n",
       "      <td>1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.6</td>\n",
       "      <td>101</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>556</td>\n",
       "      <td>876</td>\n",
       "      <td>3485</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1520</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>171</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>52</td>\n",
       "      <td>1009</td>\n",
       "      <td>651</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>1807</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0.8</td>\n",
       "      <td>162</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>246</td>\n",
       "      <td>932</td>\n",
       "      <td>2741</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>1797</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.6</td>\n",
       "      <td>174</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>57</td>\n",
       "      <td>1169</td>\n",
       "      <td>3359</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>1895</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>0.9</td>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1019</td>\n",
       "      <td>1698</td>\n",
       "      <td>2563</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>567</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>0.4</td>\n",
       "      <td>165</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>555</td>\n",
       "      <td>1290</td>\n",
       "      <td>336</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>936</td>\n",
       "      <td>1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0.8</td>\n",
       "      <td>139</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>265</td>\n",
       "      <td>886</td>\n",
       "      <td>684</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1700</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>0.5</td>\n",
       "      <td>170</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>644</td>\n",
       "      <td>913</td>\n",
       "      <td>2121</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>609</td>\n",
       "      <td>0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.9</td>\n",
       "      <td>186</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1152</td>\n",
       "      <td>1632</td>\n",
       "      <td>1933</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1185</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>477</td>\n",
       "      <td>825</td>\n",
       "      <td>1223</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1533</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0.4</td>\n",
       "      <td>171</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>38</td>\n",
       "      <td>832</td>\n",
       "      <td>2509</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1270</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>0.1</td>\n",
       "      <td>140</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>457</td>\n",
       "      <td>608</td>\n",
       "      <td>2828</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  \\\n",
       "0             1043     1          1.8         1  14       0           5   \n",
       "1              841     1          0.5         1   4       1          61   \n",
       "2             1807     1          2.8         0   1       0          27   \n",
       "3             1546     0          0.5         1  18       1          25   \n",
       "4             1434     0          1.4         0  11       1          49   \n",
       "5             1464     1          2.9         1   5       1          50   \n",
       "6             1718     0          2.4         0   1       0          47   \n",
       "7              833     0          2.4         1   0       0          62   \n",
       "8             1111     1          2.9         1   9       1          25   \n",
       "9             1520     0          0.5         0   1       0          25   \n",
       "..             ...   ...          ...       ...  ..     ...         ...   \n",
       "990           1807     0          1.2         0   4       0          37   \n",
       "991           1797     1          2.6         0   4       0          42   \n",
       "992           1895     0          0.5         1   0       1          62   \n",
       "993            567     1          2.7         1  14       1          56   \n",
       "994            936     1          1.4         1   0       0          46   \n",
       "995           1700     1          1.9         0   0       1          54   \n",
       "996            609     0          1.8         1   0       0          13   \n",
       "997           1185     0          1.4         0   1       1           8   \n",
       "998           1533     1          0.5         1   0       0          50   \n",
       "999           1270     1          0.5         0   4       1          35   \n",
       "\n",
       "     m_dep  mobile_wt  n_cores  pc  px_height  px_width   ram  sc_h  sc_w  \\\n",
       "0      0.1        193        3  16        226      1412  3476    12     7   \n",
       "1      0.8        191        5  12        746       857  3895     6     0   \n",
       "2      0.9        186        3   4       1270      1366  2396    17    10   \n",
       "3      0.5         96        8  20        295      1752  3893    10     0   \n",
       "4      0.5        108        6  18        749       810  1773    15     8   \n",
       "5      0.8        198        8   9        569       939  3506    10     7   \n",
       "6      1.0        156        2   3       1283      1374  3873    14     2   \n",
       "7      0.8        111        1   2       1312      1880  1495     7     2   \n",
       "8      0.6        101        5  19        556       876  3485    11     9   \n",
       "9      0.5        171        3  20         52      1009   651     6     0   \n",
       "..     ...        ...      ...  ..        ...       ...   ...   ...   ...   \n",
       "990    0.8        162        1  11        246       932  2741     7     1   \n",
       "991    0.6        174        3  20         57      1169  3359    16     6   \n",
       "992    0.9         99        2   0       1019      1698  2563    10     8   \n",
       "993    0.4        165        8  17        555      1290   336     7     6   \n",
       "994    0.8        139        2   0        265       886   684     8     5   \n",
       "995    0.5        170        7  17        644       913  2121    14     8   \n",
       "996    0.9        186        4   2       1152      1632  1933     8     1   \n",
       "997    0.5         80        1  12        477       825  1223     5     0   \n",
       "998    0.4        171        2  12         38       832  2509    15    11   \n",
       "999    0.1        140        6  19        457       608  2828     9     2   \n",
       "\n",
       "     talk_time  three_g  touch_screen  wifi  \n",
       "0            2        0             1     0  \n",
       "1            7        1             0     0  \n",
       "2           10        0             1     1  \n",
       "3            7        1             1     0  \n",
       "4            7        1             0     1  \n",
       "5            3        1             1     1  \n",
       "6           10        0             0     0  \n",
       "7           18        0             1     1  \n",
       "8           10        1             1     0  \n",
       "9            5        1             0     1  \n",
       "..         ...      ...           ...   ...  \n",
       "990          9        1             1     1  \n",
       "991         18        1             1     1  \n",
       "992         13        1             0     1  \n",
       "993          7        1             1     1  \n",
       "994         12        1             1     1  \n",
       "995         15        1             1     0  \n",
       "996         19        0             1     1  \n",
       "997         14        1             0     0  \n",
       "998          6        0             1     0  \n",
       "999          3        1             0     1  \n",
       "\n",
       "[1000 rows x 20 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"./MobilePriceDescription/test.csv\").drop(['id'], axis=1)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "238f37f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>pc</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.475451</td>\n",
       "      <td>1</td>\n",
       "      <td>0.312601</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.581269</td>\n",
       "      <td>-1.487247</td>\n",
       "      <td>1.535535</td>\n",
       "      <td>-0.580671</td>\n",
       "      <td>0.976026</td>\n",
       "      <td>-0.926990</td>\n",
       "      <td>0.391912</td>\n",
       "      <td>1.229373</td>\n",
       "      <td>0.001158</td>\n",
       "      <td>0.397363</td>\n",
       "      <td>-1.653355</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.942782</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.255832</td>\n",
       "      <td>1</td>\n",
       "      <td>1.509303</td>\n",
       "      <td>1.006341</td>\n",
       "      <td>1.478120</td>\n",
       "      <td>0.293833</td>\n",
       "      <td>0.319433</td>\n",
       "      <td>0.274729</td>\n",
       "      <td>-0.871028</td>\n",
       "      <td>1.614643</td>\n",
       "      <td>-1.388231</td>\n",
       "      <td>-1.254383</td>\n",
       "      <td>-0.743418</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.292077</td>\n",
       "      <td>1</td>\n",
       "      <td>1.519087</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.367116</td>\n",
       "      <td>1.362567</td>\n",
       "      <td>1.334582</td>\n",
       "      <td>-0.580671</td>\n",
       "      <td>-0.993754</td>\n",
       "      <td>1.485693</td>\n",
       "      <td>0.287236</td>\n",
       "      <td>0.236313</td>\n",
       "      <td>1.158982</td>\n",
       "      <td>1.105254</td>\n",
       "      <td>-0.197456</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.688249</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.255832</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.477493</td>\n",
       "      <td>-0.062340</td>\n",
       "      <td>-1.249091</td>\n",
       "      <td>1.605590</td>\n",
       "      <td>1.632619</td>\n",
       "      <td>-0.767532</td>\n",
       "      <td>1.165604</td>\n",
       "      <td>1.612804</td>\n",
       "      <td>-0.461972</td>\n",
       "      <td>-1.254383</td>\n",
       "      <td>-0.743418</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.429135</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.169994</td>\n",
       "      <td>0</td>\n",
       "      <td>0.847037</td>\n",
       "      <td>-0.062340</td>\n",
       "      <td>-0.904602</td>\n",
       "      <td>0.731085</td>\n",
       "      <td>1.304323</td>\n",
       "      <td>0.281662</td>\n",
       "      <td>-0.977979</td>\n",
       "      <td>-0.336535</td>\n",
       "      <td>0.695852</td>\n",
       "      <td>0.633326</td>\n",
       "      <td>-0.743418</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.498540</td>\n",
       "      <td>1</td>\n",
       "      <td>1.639736</td>\n",
       "      <td>1</td>\n",
       "      <td>0.902226</td>\n",
       "      <td>1.006341</td>\n",
       "      <td>1.679072</td>\n",
       "      <td>1.605590</td>\n",
       "      <td>-0.173012</td>\n",
       "      <td>-0.134318</td>\n",
       "      <td>-0.684431</td>\n",
       "      <td>1.256958</td>\n",
       "      <td>-0.461972</td>\n",
       "      <td>0.397363</td>\n",
       "      <td>-1.471368</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.086174</td>\n",
       "      <td>0</td>\n",
       "      <td>1.036493</td>\n",
       "      <td>0</td>\n",
       "      <td>0.736660</td>\n",
       "      <td>1.718794</td>\n",
       "      <td>0.473358</td>\n",
       "      <td>-1.017923</td>\n",
       "      <td>-1.157902</td>\n",
       "      <td>1.515736</td>\n",
       "      <td>0.305440</td>\n",
       "      <td>1.594414</td>\n",
       "      <td>0.464287</td>\n",
       "      <td>-0.782455</td>\n",
       "      <td>-0.197456</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.961290</td>\n",
       "      <td>0</td>\n",
       "      <td>1.036493</td>\n",
       "      <td>1</td>\n",
       "      <td>1.564491</td>\n",
       "      <td>1.006341</td>\n",
       "      <td>-0.818479</td>\n",
       "      <td>-1.455175</td>\n",
       "      <td>-1.322051</td>\n",
       "      <td>1.582755</td>\n",
       "      <td>1.456877</td>\n",
       "      <td>-0.592156</td>\n",
       "      <td>-1.156666</td>\n",
       "      <td>-0.782455</td>\n",
       "      <td>1.258443</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.318132</td>\n",
       "      <td>1</td>\n",
       "      <td>1.639736</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.477493</td>\n",
       "      <td>0.293887</td>\n",
       "      <td>-1.105554</td>\n",
       "      <td>0.293833</td>\n",
       "      <td>1.468471</td>\n",
       "      <td>-0.164361</td>\n",
       "      <td>-0.827792</td>\n",
       "      <td>1.237648</td>\n",
       "      <td>-0.230407</td>\n",
       "      <td>0.869290</td>\n",
       "      <td>-0.197456</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.628097</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.255832</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.477493</td>\n",
       "      <td>-0.062340</td>\n",
       "      <td>0.903970</td>\n",
       "      <td>-0.580671</td>\n",
       "      <td>1.632619</td>\n",
       "      <td>-1.329104</td>\n",
       "      <td>-0.525141</td>\n",
       "      <td>-1.368214</td>\n",
       "      <td>-1.388231</td>\n",
       "      <td>-1.254383</td>\n",
       "      <td>-1.107393</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>1.292077</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.411291</td>\n",
       "      <td>0</td>\n",
       "      <td>0.184772</td>\n",
       "      <td>1.006341</td>\n",
       "      <td>0.645603</td>\n",
       "      <td>-1.455175</td>\n",
       "      <td>0.155284</td>\n",
       "      <td>-0.880770</td>\n",
       "      <td>-0.700360</td>\n",
       "      <td>0.553541</td>\n",
       "      <td>-1.156666</td>\n",
       "      <td>-1.018419</td>\n",
       "      <td>-0.379444</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>1.268942</td>\n",
       "      <td>1</td>\n",
       "      <td>1.277790</td>\n",
       "      <td>0</td>\n",
       "      <td>0.460716</td>\n",
       "      <td>0.293887</td>\n",
       "      <td>0.990092</td>\n",
       "      <td>-0.580671</td>\n",
       "      <td>1.632619</td>\n",
       "      <td>-1.317549</td>\n",
       "      <td>-0.161051</td>\n",
       "      <td>1.121791</td>\n",
       "      <td>0.927417</td>\n",
       "      <td>0.161399</td>\n",
       "      <td>1.258443</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>1.495667</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.255832</td>\n",
       "      <td>1</td>\n",
       "      <td>1.564491</td>\n",
       "      <td>1.362567</td>\n",
       "      <td>-1.162969</td>\n",
       "      <td>-1.017923</td>\n",
       "      <td>-1.650347</td>\n",
       "      <td>0.905632</td>\n",
       "      <td>1.042724</td>\n",
       "      <td>0.389870</td>\n",
       "      <td>-0.461972</td>\n",
       "      <td>0.633326</td>\n",
       "      <td>0.348506</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>-1.576686</td>\n",
       "      <td>1</td>\n",
       "      <td>1.398439</td>\n",
       "      <td>1</td>\n",
       "      <td>1.233359</td>\n",
       "      <td>-0.418566</td>\n",
       "      <td>0.731725</td>\n",
       "      <td>1.605590</td>\n",
       "      <td>1.140174</td>\n",
       "      <td>-0.166672</td>\n",
       "      <td>0.114293</td>\n",
       "      <td>-1.657856</td>\n",
       "      <td>-1.156666</td>\n",
       "      <td>0.161399</td>\n",
       "      <td>-0.743418</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>-0.722998</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.169994</td>\n",
       "      <td>1</td>\n",
       "      <td>0.681471</td>\n",
       "      <td>1.006341</td>\n",
       "      <td>-0.014670</td>\n",
       "      <td>-1.017923</td>\n",
       "      <td>-1.650347</td>\n",
       "      <td>-0.836861</td>\n",
       "      <td>-0.805036</td>\n",
       "      <td>-1.337870</td>\n",
       "      <td>-0.925101</td>\n",
       "      <td>-0.074565</td>\n",
       "      <td>0.166518</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1.044531</td>\n",
       "      <td>1</td>\n",
       "      <td>0.433249</td>\n",
       "      <td>0</td>\n",
       "      <td>1.122981</td>\n",
       "      <td>-0.062340</td>\n",
       "      <td>0.875263</td>\n",
       "      <td>1.168338</td>\n",
       "      <td>1.140174</td>\n",
       "      <td>0.039007</td>\n",
       "      <td>-0.743596</td>\n",
       "      <td>-0.016549</td>\n",
       "      <td>0.464287</td>\n",
       "      <td>0.633326</td>\n",
       "      <td>0.712481</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-1.479519</td>\n",
       "      <td>0</td>\n",
       "      <td>0.312601</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.139759</td>\n",
       "      <td>1.362567</td>\n",
       "      <td>1.334582</td>\n",
       "      <td>-0.143419</td>\n",
       "      <td>-1.322051</td>\n",
       "      <td>1.212995</td>\n",
       "      <td>0.892536</td>\n",
       "      <td>-0.189415</td>\n",
       "      <td>-0.925101</td>\n",
       "      <td>-1.018419</td>\n",
       "      <td>1.440430</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-0.146932</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.169994</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.415702</td>\n",
       "      <td>-0.062340</td>\n",
       "      <td>-1.708411</td>\n",
       "      <td>-1.455175</td>\n",
       "      <td>0.319433</td>\n",
       "      <td>-0.346930</td>\n",
       "      <td>-0.943846</td>\n",
       "      <td>-0.842260</td>\n",
       "      <td>-1.619796</td>\n",
       "      <td>-1.254383</td>\n",
       "      <td>0.530493</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.658173</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.255832</td>\n",
       "      <td>1</td>\n",
       "      <td>0.902226</td>\n",
       "      <td>-0.418566</td>\n",
       "      <td>0.903970</td>\n",
       "      <td>-1.017923</td>\n",
       "      <td>0.319433</td>\n",
       "      <td>-1.361458</td>\n",
       "      <td>-0.927917</td>\n",
       "      <td>0.340217</td>\n",
       "      <td>0.695852</td>\n",
       "      <td>1.341217</td>\n",
       "      <td>-0.925406</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.049718</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.255832</td>\n",
       "      <td>0</td>\n",
       "      <td>0.074394</td>\n",
       "      <td>-1.487247</td>\n",
       "      <td>0.014038</td>\n",
       "      <td>0.731085</td>\n",
       "      <td>1.468471</td>\n",
       "      <td>-0.393150</td>\n",
       "      <td>-1.437643</td>\n",
       "      <td>0.633537</td>\n",
       "      <td>-0.693537</td>\n",
       "      <td>-0.782455</td>\n",
       "      <td>-1.471368</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     battery_power  blue  clock_speed  dual_sim  int_memory     m_dep  \\\n",
       "0        -0.475451     1     0.312601         1   -1.581269 -1.487247   \n",
       "1        -0.942782     1    -1.255832         1    1.509303  1.006341   \n",
       "2         1.292077     1     1.519087         0   -0.367116  1.362567   \n",
       "3         0.688249     0    -1.255832         1   -0.477493 -0.062340   \n",
       "4         0.429135     0    -0.169994         0    0.847037 -0.062340   \n",
       "5         0.498540     1     1.639736         1    0.902226  1.006341   \n",
       "6         1.086174     0     1.036493         0    0.736660  1.718794   \n",
       "7        -0.961290     0     1.036493         1    1.564491  1.006341   \n",
       "8        -0.318132     1     1.639736         1   -0.477493  0.293887   \n",
       "9         0.628097     0    -1.255832         0   -0.477493 -0.062340   \n",
       "..             ...   ...          ...       ...         ...       ...   \n",
       "990       1.292077     0    -0.411291         0    0.184772  1.006341   \n",
       "991       1.268942     1     1.277790         0    0.460716  0.293887   \n",
       "992       1.495667     0    -1.255832         1    1.564491  1.362567   \n",
       "993      -1.576686     1     1.398439         1    1.233359 -0.418566   \n",
       "994      -0.722998     1    -0.169994         1    0.681471  1.006341   \n",
       "995       1.044531     1     0.433249         0    1.122981 -0.062340   \n",
       "996      -1.479519     0     0.312601         1   -1.139759  1.362567   \n",
       "997      -0.146932     0    -0.169994         0   -1.415702 -0.062340   \n",
       "998       0.658173     1    -1.255832         1    0.902226 -0.418566   \n",
       "999       0.049718     1    -1.255832         0    0.074394 -1.487247   \n",
       "\n",
       "     mobile_wt   n_cores        pc  px_height  px_width       ram      sc_h  \\\n",
       "0     1.535535 -0.580671  0.976026  -0.926990  0.391912  1.229373  0.001158   \n",
       "1     1.478120  0.293833  0.319433   0.274729 -0.871028  1.614643 -1.388231   \n",
       "2     1.334582 -0.580671 -0.993754   1.485693  0.287236  0.236313  1.158982   \n",
       "3    -1.249091  1.605590  1.632619  -0.767532  1.165604  1.612804 -0.461972   \n",
       "4    -0.904602  0.731085  1.304323   0.281662 -0.977979 -0.336535  0.695852   \n",
       "5     1.679072  1.605590 -0.173012  -0.134318 -0.684431  1.256958 -0.461972   \n",
       "6     0.473358 -1.017923 -1.157902   1.515736  0.305440  1.594414  0.464287   \n",
       "7    -0.818479 -1.455175 -1.322051   1.582755  1.456877 -0.592156 -1.156666   \n",
       "8    -1.105554  0.293833  1.468471  -0.164361 -0.827792  1.237648 -0.230407   \n",
       "9     0.903970 -0.580671  1.632619  -1.329104 -0.525141 -1.368214 -1.388231   \n",
       "..         ...       ...       ...        ...       ...       ...       ...   \n",
       "990   0.645603 -1.455175  0.155284  -0.880770 -0.700360  0.553541 -1.156666   \n",
       "991   0.990092 -0.580671  1.632619  -1.317549 -0.161051  1.121791  0.927417   \n",
       "992  -1.162969 -1.017923 -1.650347   0.905632  1.042724  0.389870 -0.461972   \n",
       "993   0.731725  1.605590  1.140174  -0.166672  0.114293 -1.657856 -1.156666   \n",
       "994  -0.014670 -1.017923 -1.650347  -0.836861 -0.805036 -1.337870 -0.925101   \n",
       "995   0.875263  1.168338  1.140174   0.039007 -0.743596 -0.016549  0.464287   \n",
       "996   1.334582 -0.143419 -1.322051   1.212995  0.892536 -0.189415 -0.925101   \n",
       "997  -1.708411 -1.455175  0.319433  -0.346930 -0.943846 -0.842260 -1.619796   \n",
       "998   0.903970 -1.017923  0.319433  -1.361458 -0.927917  0.340217  0.695852   \n",
       "999   0.014038  0.731085  1.468471  -0.393150 -1.437643  0.633537 -0.693537   \n",
       "\n",
       "         sc_w  talk_time  three_g  touch_screen  wifi  \n",
       "0    0.397363  -1.653355        0             1     0  \n",
       "1   -1.254383  -0.743418        1             0     0  \n",
       "2    1.105254  -0.197456        0             1     1  \n",
       "3   -1.254383  -0.743418        1             1     0  \n",
       "4    0.633326  -0.743418        1             0     1  \n",
       "5    0.397363  -1.471368        1             1     1  \n",
       "6   -0.782455  -0.197456        0             0     0  \n",
       "7   -0.782455   1.258443        0             1     1  \n",
       "8    0.869290  -0.197456        1             1     0  \n",
       "9   -1.254383  -1.107393        1             0     1  \n",
       "..        ...        ...      ...           ...   ...  \n",
       "990 -1.018419  -0.379444        1             1     1  \n",
       "991  0.161399   1.258443        1             1     1  \n",
       "992  0.633326   0.348506        1             0     1  \n",
       "993  0.161399  -0.743418        1             1     1  \n",
       "994 -0.074565   0.166518        1             1     1  \n",
       "995  0.633326   0.712481        1             1     0  \n",
       "996 -1.018419   1.440430        0             1     1  \n",
       "997 -1.254383   0.530493        1             0     0  \n",
       "998  1.341217  -0.925406        0             1     0  \n",
       "999 -0.782455  -1.471368        1             0     1  \n",
       "\n",
       "[1000 rows x 18 columns]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Encoding :\n",
    "Quant_enc = pd.DataFrame(scaler.fit_transform(df_test[list_columns_encoding]), columns=[list_columns_encoding])\n",
    "\n",
    "df_test[list_columns_encoding] = Quant_enc[list_columns_encoding]\n",
    "df_test = df_test.drop(['fc', 'four_g'], axis=1)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "d333d8b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 2, 3, 1, 3, 3, 1, 3, 0, 3, 3, 0, 0, 2, 0, 2, 1, 3, 2, 0, 3,\n",
       "       1, 1, 3, 0, 2, 0, 3, 0, 2, 0, 3, 0, 0, 1, 3, 1, 2, 1, 1, 2, 0, 0,\n",
       "       0, 1, 0, 3, 1, 2, 1, 0, 3, 0, 3, 1, 3, 1, 1, 3, 3, 2, 0, 2, 1, 1,\n",
       "       1, 3, 1, 2, 1, 2, 2, 3, 3, 0, 2, 0, 2, 3, 1, 3, 3, 0, 3, 0, 3, 1,\n",
       "       3, 0, 1, 2, 2, 0, 2, 1, 0, 2, 1, 2, 1, 0, 0, 3, 0, 2, 0, 1, 2, 3,\n",
       "       3, 3, 1, 3, 3, 3, 3, 1, 3, 0, 0, 3, 2, 1, 2, 0, 3, 2, 3, 1, 0, 2,\n",
       "       1, 1, 3, 1, 2, 0, 3, 2, 1, 3, 1, 2, 2, 3, 3, 2, 2, 3, 2, 3, 1, 0,\n",
       "       3, 2, 3, 3, 3, 3, 2, 2, 3, 3, 3, 3, 1, 0, 3, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 2, 0, 0, 0, 1, 2, 2, 2, 1, 0, 0, 0, 0, 0, 3, 1, 0, 2, 2,\n",
       "       3, 3, 1, 2, 3, 2, 3, 2, 2, 1, 0, 0, 1, 2, 0, 2, 3, 3, 0, 2, 0, 3,\n",
       "       2, 3, 3, 1, 0, 1, 0, 3, 0, 1, 0, 2, 2, 1, 2, 1, 3, 0, 3, 1, 2, 0,\n",
       "       0, 2, 1, 3, 3, 3, 1, 1, 3, 0, 0, 2, 3, 3, 1, 3, 1, 1, 3, 2, 1, 2,\n",
       "       3, 3, 3, 1, 0, 1, 2, 3, 2, 1, 3, 2, 0, 3, 0, 0, 2, 0, 0, 3, 2, 3,\n",
       "       3, 2, 1, 3, 3, 2, 3, 2, 2, 1, 2, 0, 2, 3, 1, 0, 0, 3, 0, 3, 0, 1,\n",
       "       2, 0, 2, 3, 1, 3, 2, 2, 0, 2, 0, 0, 0, 1, 3, 2, 0, 0, 0, 3, 2, 0,\n",
       "       2, 3, 1, 2, 3, 2, 3, 1, 3, 3, 2, 2, 2, 3, 3, 0, 3, 0, 3, 1, 3, 1,\n",
       "       3, 3, 0, 1, 0, 3, 1, 3, 1, 3, 0, 0, 0, 0, 2, 0, 0, 2, 1, 1, 2, 2,\n",
       "       2, 0, 1, 0, 0, 3, 2, 0, 3, 1, 2, 2, 1, 2, 3, 1, 1, 2, 2, 1, 2, 0,\n",
       "       1, 1, 0, 3, 2, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 2, 2, 3, 2, 3, 0, 3,\n",
       "       0, 3, 0, 1, 1, 1, 2, 0, 3, 2, 3, 3, 1, 3, 1, 3, 1, 3, 2, 1, 2, 2,\n",
       "       1, 1, 0, 0, 0, 1, 2, 1, 0, 3, 2, 0, 2, 2, 0, 0, 3, 1, 1, 0, 2, 2,\n",
       "       3, 0, 3, 0, 2, 3, 2, 3, 0, 2, 0, 2, 2, 0, 1, 1, 0, 0, 1, 1, 1, 3,\n",
       "       3, 3, 2, 3, 1, 2, 2, 2, 3, 3, 2, 0, 2, 1, 2, 2, 1, 0, 2, 2, 0, 0,\n",
       "       0, 3, 1, 1, 2, 2, 2, 0, 3, 0, 2, 2, 0, 3, 0, 2, 3, 0, 1, 1, 3, 3,\n",
       "       1, 1, 2, 3, 2, 0, 2, 1, 2, 0, 3, 3, 1, 2, 2, 2, 3, 0, 1, 2, 3, 1,\n",
       "       3, 2, 3, 1, 1, 1, 0, 3, 1, 0, 3, 2, 3, 2, 0, 3, 3, 3, 2, 3, 3, 1,\n",
       "       2, 1, 2, 3, 3, 1, 0, 1, 1, 1, 2, 1, 0, 0, 2, 2, 3, 2, 0, 2, 1, 3,\n",
       "       3, 0, 1, 3, 1, 2, 1, 1, 0, 0, 2, 1, 0, 1, 1, 2, 2, 0, 2, 2, 1, 0,\n",
       "       3, 0, 0, 3, 2, 0, 0, 0, 0, 0, 3, 0, 3, 1, 3, 2, 1, 3, 3, 0, 2, 0,\n",
       "       3, 2, 2, 2, 0, 3, 0, 2, 0, 2, 0, 0, 1, 1, 1, 2, 1, 3, 1, 3, 2, 2,\n",
       "       1, 3, 2, 0, 2, 2, 0, 3, 3, 0, 2, 1, 1, 2, 0, 3, 2, 0, 3, 2, 3, 0,\n",
       "       0, 3, 0, 2, 2, 3, 2, 2, 2, 2, 1, 1, 3, 0, 1, 1, 1, 2, 1, 0, 0, 1,\n",
       "       0, 0, 3, 1, 1, 2, 0, 0, 1, 1, 3, 0, 3, 2, 3, 0, 0, 1, 2, 2, 1, 0,\n",
       "       1, 1, 0, 1, 1, 0, 0, 3, 3, 0, 3, 1, 2, 3, 0, 1, 0, 2, 2, 0, 3, 1,\n",
       "       0, 3, 0, 1, 0, 2, 3, 3, 2, 3, 0, 3, 2, 0, 0, 0, 3, 3, 2, 0, 2, 1,\n",
       "       2, 1, 0, 3, 2, 0, 3, 1, 2, 1, 1, 1, 3, 1, 1, 1, 2, 0, 0, 2, 2, 0,\n",
       "       2, 0, 0, 0, 0, 2, 3, 3, 3, 0, 1, 2, 2, 1, 0, 0, 2, 1, 0, 2, 0, 2,\n",
       "       2, 2, 1, 2, 0, 2, 1, 3, 0, 0, 3, 1, 3, 0, 0, 2, 3, 3, 1, 2, 2, 1,\n",
       "       0, 0, 2, 3, 0, 3, 0, 0, 0, 2, 2, 1, 2, 0, 3, 2, 1, 2, 3, 3, 0, 1,\n",
       "       1, 2, 1, 2, 2, 0, 1, 3, 1, 1, 3, 1, 2, 3, 2, 1, 1, 2, 3, 3, 0, 2,\n",
       "       3, 0, 2, 3, 2, 2, 2, 3, 2, 0, 1, 2, 0, 2, 1, 1, 2, 2, 2, 1, 2, 1,\n",
       "       1, 1, 3, 1, 0, 1, 2, 3, 1, 0, 0, 2, 2, 2, 3, 0, 3, 3, 2, 1, 3, 0,\n",
       "       1, 3, 1, 2, 1, 1, 3, 2, 0, 3, 0, 2, 3, 0, 3, 2, 2, 3, 1, 0, 2, 3,\n",
       "       1, 0, 1, 1, 2, 1, 2, 0, 2, 2, 0, 2, 3, 2, 3, 0, 2, 1, 1, 2, 2, 3,\n",
       "       3, 0, 2, 1, 2, 1, 3, 1, 0, 3, 0, 1, 0, 0, 3, 2, 2, 0, 0, 0, 0, 3,\n",
       "       2, 3, 3, 0, 0, 2, 1, 0, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prediction:\n",
    "df_pred = XGBoost_model.predict(df_test)\n",
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "a241b5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class DataFrame in module pandas.core.frame:\n",
      "\n",
      "class DataFrame(pandas.core.generic.NDFrame, pandas.core.arraylike.OpsMixin)\n",
      " |  DataFrame(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, copy: 'bool | None' = None)\n",
      " |  \n",
      " |  Two-dimensional, size-mutable, potentially heterogeneous tabular data.\n",
      " |  \n",
      " |  Data structure also contains labeled axes (rows and columns).\n",
      " |  Arithmetic operations align on both row and column labels. Can be\n",
      " |  thought of as a dict-like container for Series objects. The primary\n",
      " |  pandas data structure.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  data : ndarray (structured or homogeneous), Iterable, dict, or DataFrame\n",
      " |      Dict can contain Series, arrays, constants, dataclass or list-like objects. If\n",
      " |      data is a dict, column order follows insertion-order. If a dict contains Series\n",
      " |      which have an index defined, it is aligned by its index.\n",
      " |  \n",
      " |      .. versionchanged:: 0.25.0\n",
      " |         If data is a list of dicts, column order follows insertion-order.\n",
      " |  \n",
      " |  index : Index or array-like\n",
      " |      Index to use for resulting frame. Will default to RangeIndex if\n",
      " |      no indexing information part of input data and no index provided.\n",
      " |  columns : Index or array-like\n",
      " |      Column labels to use for resulting frame when data does not have them,\n",
      " |      defaulting to RangeIndex(0, 1, 2, ..., n). If data contains column labels,\n",
      " |      will perform column selection instead.\n",
      " |  dtype : dtype, default None\n",
      " |      Data type to force. Only a single dtype is allowed. If None, infer.\n",
      " |  copy : bool or None, default None\n",
      " |      Copy data from inputs.\n",
      " |      For dict data, the default of None behaves like ``copy=True``.  For DataFrame\n",
      " |      or 2d ndarray input, the default of None behaves like ``copy=False``.\n",
      " |  \n",
      " |      .. versionchanged:: 1.3.0\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  DataFrame.from_records : Constructor from tuples, also record arrays.\n",
      " |  DataFrame.from_dict : From dicts of Series, arrays, or dicts.\n",
      " |  read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
      " |  read_table : Read general delimited file into DataFrame.\n",
      " |  read_clipboard : Read text from clipboard into DataFrame.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  Constructing DataFrame from a dictionary.\n",
      " |  \n",
      " |  >>> d = {'col1': [1, 2], 'col2': [3, 4]}\n",
      " |  >>> df = pd.DataFrame(data=d)\n",
      " |  >>> df\n",
      " |     col1  col2\n",
      " |  0     1     3\n",
      " |  1     2     4\n",
      " |  \n",
      " |  Notice that the inferred dtype is int64.\n",
      " |  \n",
      " |  >>> df.dtypes\n",
      " |  col1    int64\n",
      " |  col2    int64\n",
      " |  dtype: object\n",
      " |  \n",
      " |  To enforce a single dtype:\n",
      " |  \n",
      " |  >>> df = pd.DataFrame(data=d, dtype=np.int8)\n",
      " |  >>> df.dtypes\n",
      " |  col1    int8\n",
      " |  col2    int8\n",
      " |  dtype: object\n",
      " |  \n",
      " |  Constructing DataFrame from a dictionary including Series:\n",
      " |  \n",
      " |  >>> d = {'col1': [0, 1, 2, 3], 'col2': pd.Series([2, 3], index=[2, 3])}\n",
      " |  >>> pd.DataFrame(data=d, index=[0, 1, 2, 3])\n",
      " |     col1  col2\n",
      " |  0     0   NaN\n",
      " |  1     1   NaN\n",
      " |  2     2   2.0\n",
      " |  3     3   3.0\n",
      " |  \n",
      " |  Constructing DataFrame from numpy ndarray:\n",
      " |  \n",
      " |  >>> df2 = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]),\n",
      " |  ...                    columns=['a', 'b', 'c'])\n",
      " |  >>> df2\n",
      " |     a  b  c\n",
      " |  0  1  2  3\n",
      " |  1  4  5  6\n",
      " |  2  7  8  9\n",
      " |  \n",
      " |  Constructing DataFrame from a numpy ndarray that has labeled columns:\n",
      " |  \n",
      " |  >>> data = np.array([(1, 2, 3), (4, 5, 6), (7, 8, 9)],\n",
      " |  ...                 dtype=[(\"a\", \"i4\"), (\"b\", \"i4\"), (\"c\", \"i4\")])\n",
      " |  >>> df3 = pd.DataFrame(data, columns=['c', 'a'])\n",
      " |  ...\n",
      " |  >>> df3\n",
      " |     c  a\n",
      " |  0  3  1\n",
      " |  1  6  4\n",
      " |  2  9  7\n",
      " |  \n",
      " |  Constructing DataFrame from dataclass:\n",
      " |  \n",
      " |  >>> from dataclasses import make_dataclass\n",
      " |  >>> Point = make_dataclass(\"Point\", [(\"x\", int), (\"y\", int)])\n",
      " |  >>> pd.DataFrame([Point(0, 0), Point(0, 3), Point(2, 3)])\n",
      " |     x  y\n",
      " |  0  0  0\n",
      " |  1  0  3\n",
      " |  2  2  3\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      DataFrame\n",
      " |      pandas.core.generic.NDFrame\n",
      " |      pandas.core.base.PandasObject\n",
      " |      pandas.core.accessor.DirNamesMixin\n",
      " |      pandas.core.indexing.IndexingMixin\n",
      " |      pandas.core.arraylike.OpsMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __divmod__(self, other) -> 'tuple[DataFrame, DataFrame]'\n",
      " |  \n",
      " |  __getitem__(self, key)\n",
      " |  \n",
      " |  __init__(self, data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, copy: 'bool | None' = None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __len__(self) -> 'int'\n",
      " |      Returns length of info axis, but here we use the index.\n",
      " |  \n",
      " |  __matmul__(self, other: 'AnyArrayLike | DataFrame | Series') -> 'DataFrame | Series'\n",
      " |      Matrix multiplication using binary `@` operator in Python>=3.5.\n",
      " |  \n",
      " |  __rdivmod__(self, other) -> 'tuple[DataFrame, DataFrame]'\n",
      " |  \n",
      " |  __repr__(self) -> 'str'\n",
      " |      Return a string representation for a particular DataFrame.\n",
      " |  \n",
      " |  __rmatmul__(self, other)\n",
      " |      Matrix multiplication using binary `@` operator in Python>=3.5.\n",
      " |  \n",
      " |  __setitem__(self, key, value)\n",
      " |  \n",
      " |  add(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Addition of dataframe and other, element-wise (binary operator `add`).\n",
      " |      \n",
      " |      Equivalent to ``dataframe + other``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `radd`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  agg = aggregate(self, func=None, axis: 'Axis' = 0, *args, **kwargs)\n",
      " |  \n",
      " |  aggregate(self, func=None, axis: 'Axis' = 0, *args, **kwargs)\n",
      " |      Aggregate using one or more operations over the specified axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function, str, list or dict\n",
      " |          Function to use for aggregating the data. If a function, must either\n",
      " |          work when passed a DataFrame or when passed to DataFrame.apply.\n",
      " |      \n",
      " |          Accepted combinations are:\n",
      " |      \n",
      " |          - function\n",
      " |          - string function name\n",
      " |          - list of functions and/or function names, e.g. ``[np.sum, 'mean']``\n",
      " |          - dict of axis labels -> functions, function names or list of such.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |              If 0 or 'index': apply function to each column.\n",
      " |              If 1 or 'columns': apply function to each row.\n",
      " |      *args\n",
      " |          Positional arguments to pass to `func`.\n",
      " |      **kwargs\n",
      " |          Keyword arguments to pass to `func`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar, Series or DataFrame\n",
      " |      \n",
      " |          The return can be:\n",
      " |      \n",
      " |          * scalar : when Series.agg is called with single function\n",
      " |          * Series : when DataFrame.agg is called with a single function\n",
      " |          * DataFrame : when DataFrame.agg is called with several functions\n",
      " |      \n",
      " |          Return scalar, Series or DataFrame.\n",
      " |      \n",
      " |      The aggregation operations are always performed over an axis, either the\n",
      " |      index (default) or the column axis. This behavior is different from\n",
      " |      `numpy` aggregation functions (`mean`, `median`, `prod`, `sum`, `std`,\n",
      " |      `var`), where the default is to compute the aggregation of the flattened\n",
      " |      array, e.g., ``numpy.mean(arr_2d)`` as opposed to\n",
      " |      ``numpy.mean(arr_2d, axis=0)``.\n",
      " |      \n",
      " |      `agg` is an alias for `aggregate`. Use the alias.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.apply : Perform any type of operations.\n",
      " |      DataFrame.transform : Perform transformation type operations.\n",
      " |      core.groupby.GroupBy : Perform operations over groups.\n",
      " |      core.resample.Resampler : Perform operations over resampled bins.\n",
      " |      core.window.Rolling : Perform operations over rolling window.\n",
      " |      core.window.Expanding : Perform operations over expanding window.\n",
      " |      core.window.ExponentialMovingWindow : Perform operation over exponential weighted\n",
      " |          window.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      `agg` is an alias for `aggregate`. Use the alias.\n",
      " |      \n",
      " |      Functions that mutate the passed object can produce unexpected\n",
      " |      behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`\n",
      " |      for more details.\n",
      " |      \n",
      " |      A passed user-defined-function will be passed a Series for evaluation.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[1, 2, 3],\n",
      " |      ...                    [4, 5, 6],\n",
      " |      ...                    [7, 8, 9],\n",
      " |      ...                    [np.nan, np.nan, np.nan]],\n",
      " |      ...                   columns=['A', 'B', 'C'])\n",
      " |      \n",
      " |      Aggregate these functions over the rows.\n",
      " |      \n",
      " |      >>> df.agg(['sum', 'min'])\n",
      " |              A     B     C\n",
      " |      sum  12.0  15.0  18.0\n",
      " |      min   1.0   2.0   3.0\n",
      " |      \n",
      " |      Different aggregations per column.\n",
      " |      \n",
      " |      >>> df.agg({'A' : ['sum', 'min'], 'B' : ['min', 'max']})\n",
      " |              A    B\n",
      " |      sum  12.0  NaN\n",
      " |      min   1.0  2.0\n",
      " |      max   NaN  8.0\n",
      " |      \n",
      " |      Aggregate different functions over the columns and rename the index of the resulting\n",
      " |      DataFrame.\n",
      " |      \n",
      " |      >>> df.agg(x=('A', max), y=('B', 'min'), z=('C', np.mean))\n",
      " |           A    B    C\n",
      " |      x  7.0  NaN  NaN\n",
      " |      y  NaN  2.0  NaN\n",
      " |      z  NaN  NaN  6.0\n",
      " |      \n",
      " |      Aggregate over the columns.\n",
      " |      \n",
      " |      >>> df.agg(\"mean\", axis=\"columns\")\n",
      " |      0    2.0\n",
      " |      1    5.0\n",
      " |      2    8.0\n",
      " |      3    NaN\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  align(self, other, join: 'str' = 'outer', axis: 'Axis | None' = None, level: 'Level | None' = None, copy: 'bool' = True, fill_value=None, method: 'str | None' = None, limit=None, fill_axis: 'Axis' = 0, broadcast_axis: 'Axis | None' = None) -> 'DataFrame'\n",
      " |      Align two objects on their axes with the specified join method.\n",
      " |      \n",
      " |      Join method is specified for each axis Index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame or Series\n",
      " |      join : {'outer', 'inner', 'left', 'right'}, default 'outer'\n",
      " |      axis : allowed axis of the other object, default None\n",
      " |          Align on index (0), columns (1), or both (None).\n",
      " |      level : int or level name, default None\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      copy : bool, default True\n",
      " |          Always returns new objects. If copy=False and no reindexing is\n",
      " |          required then original objects are returned.\n",
      " |      fill_value : scalar, default np.NaN\n",
      " |          Value to use for missing values. Defaults to NaN, but can be any\n",
      " |          \"compatible\" value.\n",
      " |      method : {'backfill', 'bfill', 'pad', 'ffill', None}, default None\n",
      " |          Method to use for filling holes in reindexed Series:\n",
      " |      \n",
      " |          - pad / ffill: propagate last valid observation forward to next valid.\n",
      " |          - backfill / bfill: use NEXT valid observation to fill gap.\n",
      " |      \n",
      " |      limit : int, default None\n",
      " |          If method is specified, this is the maximum number of consecutive\n",
      " |          NaN values to forward/backward fill. In other words, if there is\n",
      " |          a gap with more than this number of consecutive NaNs, it will only\n",
      " |          be partially filled. If method is not specified, this is the\n",
      " |          maximum number of entries along the entire axis where NaNs will be\n",
      " |          filled. Must be greater than 0 if not None.\n",
      " |      fill_axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Filling axis, method and limit.\n",
      " |      broadcast_axis : {0 or 'index', 1 or 'columns'}, default None\n",
      " |          Broadcast values along this axis, if aligning two objects of\n",
      " |          different dimensions.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      (left, right) : (DataFrame, type of other)\n",
      " |          Aligned objects.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(\n",
      " |      ...     [[1, 2, 3, 4], [6, 7, 8, 9]], columns=[\"D\", \"B\", \"E\", \"A\"], index=[1, 2]\n",
      " |      ... )\n",
      " |      >>> other = pd.DataFrame(\n",
      " |      ...     [[10, 20, 30, 40], [60, 70, 80, 90], [600, 700, 800, 900]],\n",
      " |      ...     columns=[\"A\", \"B\", \"C\", \"D\"],\n",
      " |      ...     index=[2, 3, 4],\n",
      " |      ... )\n",
      " |      >>> df\n",
      " |         D  B  E  A\n",
      " |      1  1  2  3  4\n",
      " |      2  6  7  8  9\n",
      " |      >>> other\n",
      " |          A    B    C    D\n",
      " |      2   10   20   30   40\n",
      " |      3   60   70   80   90\n",
      " |      4  600  700  800  900\n",
      " |      \n",
      " |      Align on columns:\n",
      " |      \n",
      " |      >>> left, right = df.align(other, join=\"outer\", axis=1)\n",
      " |      >>> left\n",
      " |         A  B   C  D  E\n",
      " |      1  4  2 NaN  1  3\n",
      " |      2  9  7 NaN  6  8\n",
      " |      >>> right\n",
      " |          A    B    C    D   E\n",
      " |      2   10   20   30   40 NaN\n",
      " |      3   60   70   80   90 NaN\n",
      " |      4  600  700  800  900 NaN\n",
      " |      \n",
      " |      We can also align on the index:\n",
      " |      \n",
      " |      >>> left, right = df.align(other, join=\"outer\", axis=0)\n",
      " |      >>> left\n",
      " |          D    B    E    A\n",
      " |      1  1.0  2.0  3.0  4.0\n",
      " |      2  6.0  7.0  8.0  9.0\n",
      " |      3  NaN  NaN  NaN  NaN\n",
      " |      4  NaN  NaN  NaN  NaN\n",
      " |      >>> right\n",
      " |          A      B      C      D\n",
      " |      1    NaN    NaN    NaN    NaN\n",
      " |      2   10.0   20.0   30.0   40.0\n",
      " |      3   60.0   70.0   80.0   90.0\n",
      " |      4  600.0  700.0  800.0  900.0\n",
      " |      \n",
      " |      Finally, the default `axis=None` will align on both index and columns:\n",
      " |      \n",
      " |      >>> left, right = df.align(other, join=\"outer\", axis=None)\n",
      " |      >>> left\n",
      " |           A    B   C    D    E\n",
      " |      1  4.0  2.0 NaN  1.0  3.0\n",
      " |      2  9.0  7.0 NaN  6.0  8.0\n",
      " |      3  NaN  NaN NaN  NaN  NaN\n",
      " |      4  NaN  NaN NaN  NaN  NaN\n",
      " |      >>> right\n",
      " |             A      B      C      D   E\n",
      " |      1    NaN    NaN    NaN    NaN NaN\n",
      " |      2   10.0   20.0   30.0   40.0 NaN\n",
      " |      3   60.0   70.0   80.0   90.0 NaN\n",
      " |      4  600.0  700.0  800.0  900.0 NaN\n",
      " |  \n",
      " |  all(self, axis=0, bool_only=None, skipna=True, level=None, **kwargs)\n",
      " |      Return whether all elements are True, potentially over an axis.\n",
      " |      \n",
      " |      Returns True unless there at least one element within a series or\n",
      " |      along a Dataframe axis that is False or equivalent (e.g. zero or\n",
      " |      empty).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          Indicate which axis or axes should be reduced.\n",
      " |      \n",
      " |          * 0 / 'index' : reduce the index, return a Series whose index is the\n",
      " |            original column labels.\n",
      " |          * 1 / 'columns' : reduce the columns, return a Series whose index is the\n",
      " |            original index.\n",
      " |          * None : reduce all axes, return a scalar.\n",
      " |      \n",
      " |      bool_only : bool, default None\n",
      " |          Include only boolean columns. If None, will attempt to use everything,\n",
      " |          then use only boolean data. Not implemented for Series.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If the entire row/column is NA and skipna is\n",
      " |          True, then the result will be True, as for an empty row/column.\n",
      " |          If skipna is False, then NA are treated as True, because these are not\n",
      " |          equal to zero.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      **kwargs : any, default None\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          If level is specified, then, DataFrame is returned; otherwise, Series\n",
      " |          is returned.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.all : Return True if all elements are True.\n",
      " |      DataFrame.any : Return True if one (or more) elements are True.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> pd.Series([True, True]).all()\n",
      " |      True\n",
      " |      >>> pd.Series([True, False]).all()\n",
      " |      False\n",
      " |      >>> pd.Series([], dtype=\"float64\").all()\n",
      " |      True\n",
      " |      >>> pd.Series([np.nan]).all()\n",
      " |      True\n",
      " |      >>> pd.Series([np.nan]).all(skipna=False)\n",
      " |      True\n",
      " |      \n",
      " |      **DataFrames**\n",
      " |      \n",
      " |      Create a dataframe from a dictionary.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'col1': [True, True], 'col2': [True, False]})\n",
      " |      >>> df\n",
      " |         col1   col2\n",
      " |      0  True   True\n",
      " |      1  True  False\n",
      " |      \n",
      " |      Default behaviour checks if column-wise values all return True.\n",
      " |      \n",
      " |      >>> df.all()\n",
      " |      col1     True\n",
      " |      col2    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Specify ``axis='columns'`` to check if row-wise values all return True.\n",
      " |      \n",
      " |      >>> df.all(axis='columns')\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Or ``axis=None`` for whether every value is True.\n",
      " |      \n",
      " |      >>> df.all(axis=None)\n",
      " |      False\n",
      " |  \n",
      " |  any(self, axis=0, bool_only=None, skipna=True, level=None, **kwargs)\n",
      " |      Return whether any element is True, potentially over an axis.\n",
      " |      \n",
      " |      Returns False unless there is at least one element within a series or\n",
      " |      along a Dataframe axis that is True or equivalent (e.g. non-zero or\n",
      " |      non-empty).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          Indicate which axis or axes should be reduced.\n",
      " |      \n",
      " |          * 0 / 'index' : reduce the index, return a Series whose index is the\n",
      " |            original column labels.\n",
      " |          * 1 / 'columns' : reduce the columns, return a Series whose index is the\n",
      " |            original index.\n",
      " |          * None : reduce all axes, return a scalar.\n",
      " |      \n",
      " |      bool_only : bool, default None\n",
      " |          Include only boolean columns. If None, will attempt to use everything,\n",
      " |          then use only boolean data. Not implemented for Series.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If the entire row/column is NA and skipna is\n",
      " |          True, then the result will be False, as for an empty row/column.\n",
      " |          If skipna is False, then NA are treated as True, because these are not\n",
      " |          equal to zero.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      **kwargs : any, default None\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          If level is specified, then, DataFrame is returned; otherwise, Series\n",
      " |          is returned.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.any : Numpy version of this method.\n",
      " |      Series.any : Return whether any element is True.\n",
      " |      Series.all : Return whether all elements are True.\n",
      " |      DataFrame.any : Return whether any element is True over requested axis.\n",
      " |      DataFrame.all : Return whether all elements are True over requested axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      For Series input, the output is a scalar indicating whether any element\n",
      " |      is True.\n",
      " |      \n",
      " |      >>> pd.Series([False, False]).any()\n",
      " |      False\n",
      " |      >>> pd.Series([True, False]).any()\n",
      " |      True\n",
      " |      >>> pd.Series([], dtype=\"float64\").any()\n",
      " |      False\n",
      " |      >>> pd.Series([np.nan]).any()\n",
      " |      False\n",
      " |      >>> pd.Series([np.nan]).any(skipna=False)\n",
      " |      True\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      Whether each column contains at least one True element (the default).\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2], \"B\": [0, 2], \"C\": [0, 0]})\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |      0  1  0  0\n",
      " |      1  2  2  0\n",
      " |      \n",
      " |      >>> df.any()\n",
      " |      A     True\n",
      " |      B     True\n",
      " |      C    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Aggregating over the columns.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [True, False], \"B\": [1, 2]})\n",
      " |      >>> df\n",
      " |             A  B\n",
      " |      0   True  1\n",
      " |      1  False  2\n",
      " |      \n",
      " |      >>> df.any(axis='columns')\n",
      " |      0    True\n",
      " |      1    True\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [True, False], \"B\": [1, 0]})\n",
      " |      >>> df\n",
      " |             A  B\n",
      " |      0   True  1\n",
      " |      1  False  0\n",
      " |      \n",
      " |      >>> df.any(axis='columns')\n",
      " |      0    True\n",
      " |      1    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Aggregating over the entire DataFrame with ``axis=None``.\n",
      " |      \n",
      " |      >>> df.any(axis=None)\n",
      " |      True\n",
      " |      \n",
      " |      `any` for an empty DataFrame is an empty Series.\n",
      " |      \n",
      " |      >>> pd.DataFrame([]).any()\n",
      " |      Series([], dtype: bool)\n",
      " |  \n",
      " |  append(self, other, ignore_index: 'bool' = False, verify_integrity: 'bool' = False, sort: 'bool' = False) -> 'DataFrame'\n",
      " |      Append rows of `other` to the end of caller, returning a new object.\n",
      " |      \n",
      " |      .. deprecated:: 1.4.0\n",
      " |          Use :func:`concat` instead. For further details see\n",
      " |          :ref:`whatsnew_140.deprecations.frame_series_append`\n",
      " |      \n",
      " |      Columns in `other` that are not in the caller are added as new columns.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame or Series/dict-like object, or list of these\n",
      " |          The data to append.\n",
      " |      ignore_index : bool, default False\n",
      " |          If True, the resulting axis will be labeled 0, 1, …, n - 1.\n",
      " |      verify_integrity : bool, default False\n",
      " |          If True, raise ValueError on creating index with duplicates.\n",
      " |      sort : bool, default False\n",
      " |          Sort columns if the columns of `self` and `other` are not aligned.\n",
      " |      \n",
      " |          .. versionchanged:: 1.0.0\n",
      " |      \n",
      " |              Changed to not sort by default.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          A new DataFrame consisting of the rows of caller and the rows of `other`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      concat : General function to concatenate DataFrame or Series objects.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If a list of dict/series is passed and the keys are all contained in\n",
      " |      the DataFrame's index, the order of the columns in the resulting\n",
      " |      DataFrame will be unchanged.\n",
      " |      \n",
      " |      Iteratively appending rows to a DataFrame can be more computationally\n",
      " |      intensive than a single concatenate. A better solution is to append\n",
      " |      those rows to a list and then concatenate the list with the original\n",
      " |      DataFrame all at once.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[1, 2], [3, 4]], columns=list('AB'), index=['x', 'y'])\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      x  1  2\n",
      " |      y  3  4\n",
      " |      >>> df2 = pd.DataFrame([[5, 6], [7, 8]], columns=list('AB'), index=['x', 'y'])\n",
      " |      >>> df.append(df2)\n",
      " |         A  B\n",
      " |      x  1  2\n",
      " |      y  3  4\n",
      " |      x  5  6\n",
      " |      y  7  8\n",
      " |      \n",
      " |      With `ignore_index` set to True:\n",
      " |      \n",
      " |      >>> df.append(df2, ignore_index=True)\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      1  3  4\n",
      " |      2  5  6\n",
      " |      3  7  8\n",
      " |      \n",
      " |      The following, while not recommended methods for generating DataFrames,\n",
      " |      show two ways to generate a DataFrame from multiple data sources.\n",
      " |      \n",
      " |      Less efficient:\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(columns=['A'])\n",
      " |      >>> for i in range(5):\n",
      " |      ...     df = df.append({'A': i}, ignore_index=True)\n",
      " |      >>> df\n",
      " |         A\n",
      " |      0  0\n",
      " |      1  1\n",
      " |      2  2\n",
      " |      3  3\n",
      " |      4  4\n",
      " |      \n",
      " |      More efficient:\n",
      " |      \n",
      " |      >>> pd.concat([pd.DataFrame([i], columns=['A']) for i in range(5)],\n",
      " |      ...           ignore_index=True)\n",
      " |         A\n",
      " |      0  0\n",
      " |      1  1\n",
      " |      2  2\n",
      " |      3  3\n",
      " |      4  4\n",
      " |  \n",
      " |  apply(self, func: 'AggFuncType', axis: 'Axis' = 0, raw: 'bool' = False, result_type=None, args=(), **kwargs)\n",
      " |      Apply a function along an axis of the DataFrame.\n",
      " |      \n",
      " |      Objects passed to the function are Series objects whose index is\n",
      " |      either the DataFrame's index (``axis=0``) or the DataFrame's columns\n",
      " |      (``axis=1``). By default (``result_type=None``), the final return type\n",
      " |      is inferred from the return type of the applied function. Otherwise,\n",
      " |      it depends on the `result_type` argument.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function\n",
      " |          Function to apply to each column or row.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Axis along which the function is applied:\n",
      " |      \n",
      " |          * 0 or 'index': apply function to each column.\n",
      " |          * 1 or 'columns': apply function to each row.\n",
      " |      \n",
      " |      raw : bool, default False\n",
      " |          Determines if row or column is passed as a Series or ndarray object:\n",
      " |      \n",
      " |          * ``False`` : passes each row or column as a Series to the\n",
      " |            function.\n",
      " |          * ``True`` : the passed function will receive ndarray objects\n",
      " |            instead.\n",
      " |            If you are just applying a NumPy reduction function this will\n",
      " |            achieve much better performance.\n",
      " |      \n",
      " |      result_type : {'expand', 'reduce', 'broadcast', None}, default None\n",
      " |          These only act when ``axis=1`` (columns):\n",
      " |      \n",
      " |          * 'expand' : list-like results will be turned into columns.\n",
      " |          * 'reduce' : returns a Series if possible rather than expanding\n",
      " |            list-like results. This is the opposite of 'expand'.\n",
      " |          * 'broadcast' : results will be broadcast to the original shape\n",
      " |            of the DataFrame, the original index and columns will be\n",
      " |            retained.\n",
      " |      \n",
      " |          The default behaviour (None) depends on the return value of the\n",
      " |          applied function: list-like results will be returned as a Series\n",
      " |          of those. However if the apply function returns a Series these\n",
      " |          are expanded to columns.\n",
      " |      args : tuple\n",
      " |          Positional arguments to pass to `func` in addition to the\n",
      " |          array/series.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to pass as keywords arguments to\n",
      " |          `func`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Result of applying ``func`` along the given axis of the\n",
      " |          DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.applymap: For elementwise operations.\n",
      " |      DataFrame.aggregate: Only perform aggregating type operations.\n",
      " |      DataFrame.transform: Only perform transforming type operations.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Functions that mutate the passed object can produce unexpected\n",
      " |      behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`\n",
      " |      for more details.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[4, 9]] * 3, columns=['A', 'B'])\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  4  9\n",
      " |      1  4  9\n",
      " |      2  4  9\n",
      " |      \n",
      " |      Using a numpy universal function (in this case the same as\n",
      " |      ``np.sqrt(df)``):\n",
      " |      \n",
      " |      >>> df.apply(np.sqrt)\n",
      " |           A    B\n",
      " |      0  2.0  3.0\n",
      " |      1  2.0  3.0\n",
      " |      2  2.0  3.0\n",
      " |      \n",
      " |      Using a reducing function on either axis\n",
      " |      \n",
      " |      >>> df.apply(np.sum, axis=0)\n",
      " |      A    12\n",
      " |      B    27\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df.apply(np.sum, axis=1)\n",
      " |      0    13\n",
      " |      1    13\n",
      " |      2    13\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Returning a list-like will result in a Series\n",
      " |      \n",
      " |      >>> df.apply(lambda x: [1, 2], axis=1)\n",
      " |      0    [1, 2]\n",
      " |      1    [1, 2]\n",
      " |      2    [1, 2]\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Passing ``result_type='expand'`` will expand list-like results\n",
      " |      to columns of a Dataframe\n",
      " |      \n",
      " |      >>> df.apply(lambda x: [1, 2], axis=1, result_type='expand')\n",
      " |         0  1\n",
      " |      0  1  2\n",
      " |      1  1  2\n",
      " |      2  1  2\n",
      " |      \n",
      " |      Returning a Series inside the function is similar to passing\n",
      " |      ``result_type='expand'``. The resulting column names\n",
      " |      will be the Series index.\n",
      " |      \n",
      " |      >>> df.apply(lambda x: pd.Series([1, 2], index=['foo', 'bar']), axis=1)\n",
      " |         foo  bar\n",
      " |      0    1    2\n",
      " |      1    1    2\n",
      " |      2    1    2\n",
      " |      \n",
      " |      Passing ``result_type='broadcast'`` will ensure the same shape\n",
      " |      result, whether list-like or scalar is returned by the function,\n",
      " |      and broadcast it along the axis. The resulting column names will\n",
      " |      be the originals.\n",
      " |      \n",
      " |      >>> df.apply(lambda x: [1, 2], axis=1, result_type='broadcast')\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      1  1  2\n",
      " |      2  1  2\n",
      " |  \n",
      " |  applymap(self, func: 'PythonFuncType', na_action: 'str | None' = None, **kwargs) -> 'DataFrame'\n",
      " |      Apply a function to a Dataframe elementwise.\n",
      " |      \n",
      " |      This method applies a function that accepts and returns a scalar\n",
      " |      to every element of a DataFrame.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : callable\n",
      " |          Python function, returns a single value from a single value.\n",
      " |      na_action : {None, 'ignore'}, default None\n",
      " |          If ‘ignore’, propagate NaN values, without passing them to func.\n",
      " |      \n",
      " |          .. versionadded:: 1.2\n",
      " |      \n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to pass as keywords arguments to\n",
      " |          `func`.\n",
      " |      \n",
      " |          .. versionadded:: 1.3.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Transformed DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.apply : Apply a function along input axis of DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[1, 2.12], [3.356, 4.567]])\n",
      " |      >>> df\n",
      " |             0      1\n",
      " |      0  1.000  2.120\n",
      " |      1  3.356  4.567\n",
      " |      \n",
      " |      >>> df.applymap(lambda x: len(str(x)))\n",
      " |         0  1\n",
      " |      0  3  4\n",
      " |      1  5  5\n",
      " |      \n",
      " |      Like Series.map, NA values can be ignored:\n",
      " |      \n",
      " |      >>> df_copy = df.copy()\n",
      " |      >>> df_copy.iloc[0, 0] = pd.NA\n",
      " |      >>> df_copy.applymap(lambda x: len(str(x)), na_action='ignore')\n",
      " |            0  1\n",
      " |      0  <NA>  4\n",
      " |      1     5  5\n",
      " |      \n",
      " |      Note that a vectorized version of `func` often exists, which will\n",
      " |      be much faster. You could square each number elementwise.\n",
      " |      \n",
      " |      >>> df.applymap(lambda x: x**2)\n",
      " |                 0          1\n",
      " |      0   1.000000   4.494400\n",
      " |      1  11.262736  20.857489\n",
      " |      \n",
      " |      But it's better to avoid applymap in that case.\n",
      " |      \n",
      " |      >>> df ** 2\n",
      " |                 0          1\n",
      " |      0   1.000000   4.494400\n",
      " |      1  11.262736  20.857489\n",
      " |  \n",
      " |  asfreq(self, freq: 'Frequency', method=None, how: 'str | None' = None, normalize: 'bool' = False, fill_value=None) -> 'DataFrame'\n",
      " |      Convert time series to specified frequency.\n",
      " |      \n",
      " |      Returns the original data conformed to a new index with the specified\n",
      " |      frequency.\n",
      " |      \n",
      " |      If the index of this DataFrame is a :class:`~pandas.PeriodIndex`, the new index\n",
      " |      is the result of transforming the original index with\n",
      " |      :meth:`PeriodIndex.asfreq <pandas.PeriodIndex.asfreq>` (so the original index\n",
      " |      will map one-to-one to the new index).\n",
      " |      \n",
      " |      Otherwise, the new index will be equivalent to ``pd.date_range(start, end,\n",
      " |      freq=freq)`` where ``start`` and ``end`` are, respectively, the first and\n",
      " |      last entries in the original index (see :func:`pandas.date_range`). The\n",
      " |      values corresponding to any timesteps in the new index which were not present\n",
      " |      in the original index will be null (``NaN``), unless a method for filling\n",
      " |      such unknowns is provided (see the ``method`` parameter below).\n",
      " |      \n",
      " |      The :meth:`resample` method is more appropriate if an operation on each group of\n",
      " |      timesteps (such as an aggregate) is necessary to represent the data at the new\n",
      " |      frequency.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : DateOffset or str\n",
      " |          Frequency DateOffset or string.\n",
      " |      method : {'backfill'/'bfill', 'pad'/'ffill'}, default None\n",
      " |          Method to use for filling holes in reindexed Series (note this\n",
      " |          does not fill NaNs that already were present):\n",
      " |      \n",
      " |          * 'pad' / 'ffill': propagate last valid observation forward to next\n",
      " |            valid\n",
      " |          * 'backfill' / 'bfill': use NEXT valid observation to fill.\n",
      " |      how : {'start', 'end'}, default end\n",
      " |          For PeriodIndex only (see PeriodIndex.asfreq).\n",
      " |      normalize : bool, default False\n",
      " |          Whether to reset output index to midnight.\n",
      " |      fill_value : scalar, optional\n",
      " |          Value to use for missing values, applied during upsampling (note\n",
      " |          this does not fill NaNs that already were present).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          DataFrame object reindexed to the specified frequency.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      reindex : Conform DataFrame to new index with optional filling logic.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      To learn more about the frequency strings, please see `this link\n",
      " |      <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Start by creating a series with 4 one minute timestamps.\n",
      " |      \n",
      " |      >>> index = pd.date_range('1/1/2000', periods=4, freq='T')\n",
      " |      >>> series = pd.Series([0.0, None, 2.0, 3.0], index=index)\n",
      " |      >>> df = pd.DataFrame({'s': series})\n",
      " |      >>> df\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |      \n",
      " |      Upsample the series into 30 second bins.\n",
      " |      \n",
      " |      >>> df.asfreq(freq='30S')\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:00:30    NaN\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:01:30    NaN\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:02:30    NaN\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |      \n",
      " |      Upsample again, providing a ``fill value``.\n",
      " |      \n",
      " |      >>> df.asfreq(freq='30S', fill_value=9.0)\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:00:30    9.0\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:01:30    9.0\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:02:30    9.0\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |      \n",
      " |      Upsample again, providing a ``method``.\n",
      " |      \n",
      " |      >>> df.asfreq(freq='30S', method='bfill')\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:00:30    NaN\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:01:30    2.0\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:02:30    3.0\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |  \n",
      " |  assign(self, **kwargs) -> 'DataFrame'\n",
      " |      Assign new columns to a DataFrame.\n",
      " |      \n",
      " |      Returns a new object with all original columns in addition to new ones.\n",
      " |      Existing columns that are re-assigned will be overwritten.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **kwargs : dict of {str: callable or Series}\n",
      " |          The column names are keywords. If the values are\n",
      " |          callable, they are computed on the DataFrame and\n",
      " |          assigned to the new columns. The callable must not\n",
      " |          change input DataFrame (though pandas doesn't check it).\n",
      " |          If the values are not callable, (e.g. a Series, scalar, or array),\n",
      " |          they are simply assigned.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          A new DataFrame with the new columns in addition to\n",
      " |          all the existing columns.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Assigning multiple columns within the same ``assign`` is possible.\n",
      " |      Later items in '\\*\\*kwargs' may refer to newly created or modified\n",
      " |      columns in 'df'; items are computed and assigned into 'df' in order.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'temp_c': [17.0, 25.0]},\n",
      " |      ...                   index=['Portland', 'Berkeley'])\n",
      " |      >>> df\n",
      " |                temp_c\n",
      " |      Portland    17.0\n",
      " |      Berkeley    25.0\n",
      " |      \n",
      " |      Where the value is a callable, evaluated on `df`:\n",
      " |      \n",
      " |      >>> df.assign(temp_f=lambda x: x.temp_c * 9 / 5 + 32)\n",
      " |                temp_c  temp_f\n",
      " |      Portland    17.0    62.6\n",
      " |      Berkeley    25.0    77.0\n",
      " |      \n",
      " |      Alternatively, the same behavior can be achieved by directly\n",
      " |      referencing an existing Series or sequence:\n",
      " |      \n",
      " |      >>> df.assign(temp_f=df['temp_c'] * 9 / 5 + 32)\n",
      " |                temp_c  temp_f\n",
      " |      Portland    17.0    62.6\n",
      " |      Berkeley    25.0    77.0\n",
      " |      \n",
      " |      You can create multiple columns within the same assign where one\n",
      " |      of the columns depends on another one defined within the same assign:\n",
      " |      \n",
      " |      >>> df.assign(temp_f=lambda x: x['temp_c'] * 9 / 5 + 32,\n",
      " |      ...           temp_k=lambda x: (x['temp_f'] +  459.67) * 5 / 9)\n",
      " |                temp_c  temp_f  temp_k\n",
      " |      Portland    17.0    62.6  290.15\n",
      " |      Berkeley    25.0    77.0  298.15\n",
      " |  \n",
      " |  bfill(self: 'DataFrame', axis: 'None | Axis' = None, inplace: 'bool' = False, limit: 'None | int' = None, downcast=None) -> 'DataFrame | None'\n",
      " |      Synonym for :meth:`DataFrame.fillna` with ``method='bfill'``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame or None\n",
      " |          Object with missing values filled or None if ``inplace=True``.\n",
      " |  \n",
      " |  boxplot = boxplot_frame(self, column=None, by=None, ax=None, fontsize=None, rot=0, grid=True, figsize=None, layout=None, return_type=None, backend=None, **kwargs)\n",
      " |      Make a box plot from DataFrame columns.\n",
      " |      \n",
      " |      Make a box-and-whisker plot from DataFrame columns, optionally grouped\n",
      " |      by some other columns. A box plot is a method for graphically depicting\n",
      " |      groups of numerical data through their quartiles.\n",
      " |      The box extends from the Q1 to Q3 quartile values of the data,\n",
      " |      with a line at the median (Q2). The whiskers extend from the edges\n",
      " |      of box to show the range of the data. By default, they extend no more than\n",
      " |      `1.5 * IQR (IQR = Q3 - Q1)` from the edges of the box, ending at the farthest\n",
      " |      data point within that interval. Outliers are plotted as separate dots.\n",
      " |      \n",
      " |      For further details see\n",
      " |      Wikipedia's entry for `boxplot <https://en.wikipedia.org/wiki/Box_plot>`_.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      column : str or list of str, optional\n",
      " |          Column name or list of names, or vector.\n",
      " |          Can be any valid input to :meth:`pandas.DataFrame.groupby`.\n",
      " |      by : str or array-like, optional\n",
      " |          Column in the DataFrame to :meth:`pandas.DataFrame.groupby`.\n",
      " |          One box-plot will be done per value of columns in `by`.\n",
      " |      ax : object of class matplotlib.axes.Axes, optional\n",
      " |          The matplotlib axes to be used by boxplot.\n",
      " |      fontsize : float or str\n",
      " |          Tick label font size in points or as a string (e.g., `large`).\n",
      " |      rot : int or float, default 0\n",
      " |          The rotation angle of labels (in degrees)\n",
      " |          with respect to the screen coordinate system.\n",
      " |      grid : bool, default True\n",
      " |          Setting this to True will show the grid.\n",
      " |      figsize : A tuple (width, height) in inches\n",
      " |          The size of the figure to create in matplotlib.\n",
      " |      layout : tuple (rows, columns), optional\n",
      " |          For example, (3, 5) will display the subplots\n",
      " |          using 3 columns and 5 rows, starting from the top-left.\n",
      " |      return_type : {'axes', 'dict', 'both'} or None, default 'axes'\n",
      " |          The kind of object to return. The default is ``axes``.\n",
      " |      \n",
      " |          * 'axes' returns the matplotlib axes the boxplot is drawn on.\n",
      " |          * 'dict' returns a dictionary whose values are the matplotlib\n",
      " |            Lines of the boxplot.\n",
      " |          * 'both' returns a namedtuple with the axes and dict.\n",
      " |          * when grouping with ``by``, a Series mapping columns to\n",
      " |            ``return_type`` is returned.\n",
      " |      \n",
      " |            If ``return_type`` is `None`, a NumPy array\n",
      " |            of axes with the same shape as ``layout`` is returned.\n",
      " |      backend : str, default None\n",
      " |          Backend to use instead of the backend specified in the option\n",
      " |          ``plotting.backend``. For instance, 'matplotlib'. Alternatively, to\n",
      " |          specify the ``plotting.backend`` for the whole session, set\n",
      " |          ``pd.options.plotting.backend``.\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      **kwargs\n",
      " |          All other plotting keyword arguments to be passed to\n",
      " |          :func:`matplotlib.pyplot.boxplot`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result\n",
      " |          See Notes.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.plot.hist: Make a histogram.\n",
      " |      matplotlib.pyplot.boxplot : Matplotlib equivalent plot.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The return type depends on the `return_type` parameter:\n",
      " |      \n",
      " |      * 'axes' : object of class matplotlib.axes.Axes\n",
      " |      * 'dict' : dict of matplotlib.lines.Line2D objects\n",
      " |      * 'both' : a namedtuple with structure (ax, lines)\n",
      " |      \n",
      " |      For data grouped with ``by``, return a Series of the above or a numpy\n",
      " |      array:\n",
      " |      \n",
      " |      * :class:`~pandas.Series`\n",
      " |      * :class:`~numpy.array` (for ``return_type = None``)\n",
      " |      \n",
      " |      Use ``return_type='dict'`` when you want to tweak the appearance\n",
      " |      of the lines after plotting. In this case a dict containing the Lines\n",
      " |      making up the boxes, caps, fliers, medians, and whiskers is returned.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Boxplots can be created for every column in the dataframe\n",
      " |      by ``df.boxplot()`` or indicating the columns to be used:\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> np.random.seed(1234)\n",
      " |          >>> df = pd.DataFrame(np.random.randn(10, 4),\n",
      " |          ...                   columns=['Col1', 'Col2', 'Col3', 'Col4'])\n",
      " |          >>> boxplot = df.boxplot(column=['Col1', 'Col2', 'Col3'])  # doctest: +SKIP\n",
      " |      \n",
      " |      Boxplots of variables distributions grouped by the values of a third\n",
      " |      variable can be created using the option ``by``. For instance:\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> df = pd.DataFrame(np.random.randn(10, 2),\n",
      " |          ...                   columns=['Col1', 'Col2'])\n",
      " |          >>> df['X'] = pd.Series(['A', 'A', 'A', 'A', 'A',\n",
      " |          ...                      'B', 'B', 'B', 'B', 'B'])\n",
      " |          >>> boxplot = df.boxplot(by='X')\n",
      " |      \n",
      " |      A list of strings (i.e. ``['X', 'Y']``) can be passed to boxplot\n",
      " |      in order to group the data by combination of the variables in the x-axis:\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> df = pd.DataFrame(np.random.randn(10, 3),\n",
      " |          ...                   columns=['Col1', 'Col2', 'Col3'])\n",
      " |          >>> df['X'] = pd.Series(['A', 'A', 'A', 'A', 'A',\n",
      " |          ...                      'B', 'B', 'B', 'B', 'B'])\n",
      " |          >>> df['Y'] = pd.Series(['A', 'B', 'A', 'B', 'A',\n",
      " |          ...                      'B', 'A', 'B', 'A', 'B'])\n",
      " |          >>> boxplot = df.boxplot(column=['Col1', 'Col2'], by=['X', 'Y'])\n",
      " |      \n",
      " |      The layout of boxplot can be adjusted giving a tuple to ``layout``:\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> boxplot = df.boxplot(column=['Col1', 'Col2'], by='X',\n",
      " |          ...                      layout=(2, 1))\n",
      " |      \n",
      " |      Additional formatting can be done to the boxplot, like suppressing the grid\n",
      " |      (``grid=False``), rotating the labels in the x-axis (i.e. ``rot=45``)\n",
      " |      or changing the fontsize (i.e. ``fontsize=15``):\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> boxplot = df.boxplot(grid=False, rot=45, fontsize=15)  # doctest: +SKIP\n",
      " |      \n",
      " |      The parameter ``return_type`` can be used to select the type of element\n",
      " |      returned by `boxplot`.  When ``return_type='axes'`` is selected,\n",
      " |      the matplotlib axes on which the boxplot is drawn are returned:\n",
      " |      \n",
      " |          >>> boxplot = df.boxplot(column=['Col1', 'Col2'], return_type='axes')\n",
      " |          >>> type(boxplot)\n",
      " |          <class 'matplotlib.axes._subplots.AxesSubplot'>\n",
      " |      \n",
      " |      When grouping with ``by``, a Series mapping columns to ``return_type``\n",
      " |      is returned:\n",
      " |      \n",
      " |          >>> boxplot = df.boxplot(column=['Col1', 'Col2'], by='X',\n",
      " |          ...                      return_type='axes')\n",
      " |          >>> type(boxplot)\n",
      " |          <class 'pandas.core.series.Series'>\n",
      " |      \n",
      " |      If ``return_type`` is `None`, a NumPy array of axes with the same shape\n",
      " |      as ``layout`` is returned:\n",
      " |      \n",
      " |          >>> boxplot = df.boxplot(column=['Col1', 'Col2'], by='X',\n",
      " |          ...                      return_type=None)\n",
      " |          >>> type(boxplot)\n",
      " |          <class 'numpy.ndarray'>\n",
      " |  \n",
      " |  clip(self: 'DataFrame', lower=None, upper=None, axis: 'Axis | None' = None, inplace: 'bool' = False, *args, **kwargs) -> 'DataFrame | None'\n",
      " |      Trim values at input threshold(s).\n",
      " |      \n",
      " |      Assigns values outside boundary to boundary values. Thresholds\n",
      " |      can be singular values or array like, and in the latter case\n",
      " |      the clipping is performed element-wise in the specified axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      lower : float or array-like, default None\n",
      " |          Minimum threshold value. All values below this\n",
      " |          threshold will be set to it. A missing\n",
      " |          threshold (e.g `NA`) will not clip the value.\n",
      " |      upper : float or array-like, default None\n",
      " |          Maximum threshold value. All values above this\n",
      " |          threshold will be set to it. A missing\n",
      " |          threshold (e.g `NA`) will not clip the value.\n",
      " |      axis : int or str axis name, optional\n",
      " |          Align object with lower and upper along the given axis.\n",
      " |      inplace : bool, default False\n",
      " |          Whether to perform the operation in place on the data.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywords have no effect but might be accepted\n",
      " |          for compatibility with numpy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame or None\n",
      " |          Same type as calling object with the values outside the\n",
      " |          clip boundaries replaced or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.clip : Trim values at input threshold in series.\n",
      " |      DataFrame.clip : Trim values at input threshold in dataframe.\n",
      " |      numpy.clip : Clip (limit) the values in an array.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> data = {'col_0': [9, -3, 0, -1, 5], 'col_1': [-2, -7, 6, 8, -5]}\n",
      " |      >>> df = pd.DataFrame(data)\n",
      " |      >>> df\n",
      " |         col_0  col_1\n",
      " |      0      9     -2\n",
      " |      1     -3     -7\n",
      " |      2      0      6\n",
      " |      3     -1      8\n",
      " |      4      5     -5\n",
      " |      \n",
      " |      Clips per column using lower and upper thresholds:\n",
      " |      \n",
      " |      >>> df.clip(-4, 6)\n",
      " |         col_0  col_1\n",
      " |      0      6     -2\n",
      " |      1     -3     -4\n",
      " |      2      0      6\n",
      " |      3     -1      6\n",
      " |      4      5     -4\n",
      " |      \n",
      " |      Clips using specific lower and upper thresholds per column element:\n",
      " |      \n",
      " |      >>> t = pd.Series([2, -4, -1, 6, 3])\n",
      " |      >>> t\n",
      " |      0    2\n",
      " |      1   -4\n",
      " |      2   -1\n",
      " |      3    6\n",
      " |      4    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df.clip(t, t + 4, axis=0)\n",
      " |         col_0  col_1\n",
      " |      0      6      2\n",
      " |      1     -3     -4\n",
      " |      2      0      3\n",
      " |      3      6      8\n",
      " |      4      5      3\n",
      " |      \n",
      " |      Clips using specific lower threshold per column element, with missing values:\n",
      " |      \n",
      " |      >>> t = pd.Series([2, -4, np.NaN, 6, 3])\n",
      " |      >>> t\n",
      " |      0    2.0\n",
      " |      1   -4.0\n",
      " |      2    NaN\n",
      " |      3    6.0\n",
      " |      4    3.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> df.clip(t, axis=0)\n",
      " |      col_0  col_1\n",
      " |      0      9      2\n",
      " |      1     -3     -4\n",
      " |      2      0      6\n",
      " |      3      6      8\n",
      " |      4      5      3\n",
      " |  \n",
      " |  combine(self, other: 'DataFrame', func, fill_value=None, overwrite: 'bool' = True) -> 'DataFrame'\n",
      " |      Perform column-wise combine with another DataFrame.\n",
      " |      \n",
      " |      Combines a DataFrame with `other` DataFrame using `func`\n",
      " |      to element-wise combine columns. The row and column indexes of the\n",
      " |      resulting DataFrame will be the union of the two.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame\n",
      " |          The DataFrame to merge column-wise.\n",
      " |      func : function\n",
      " |          Function that takes two series as inputs and return a Series or a\n",
      " |          scalar. Used to merge the two dataframes column by columns.\n",
      " |      fill_value : scalar value, default None\n",
      " |          The value to fill NaNs with prior to passing any column to the\n",
      " |          merge func.\n",
      " |      overwrite : bool, default True\n",
      " |          If True, columns in `self` that do not exist in `other` will be\n",
      " |          overwritten with NaNs.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Combination of the provided DataFrames.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.combine_first : Combine two DataFrame objects and default to\n",
      " |          non-null values in frame calling the method.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Combine using a simple function that chooses the smaller column.\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame({'A': [0, 0], 'B': [4, 4]})\n",
      " |      >>> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})\n",
      " |      >>> take_smaller = lambda s1, s2: s1 if s1.sum() < s2.sum() else s2\n",
      " |      >>> df1.combine(df2, take_smaller)\n",
      " |         A  B\n",
      " |      0  0  3\n",
      " |      1  0  3\n",
      " |      \n",
      " |      Example using a true element-wise combine function.\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame({'A': [5, 0], 'B': [2, 4]})\n",
      " |      >>> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})\n",
      " |      >>> df1.combine(df2, np.minimum)\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      1  0  3\n",
      " |      \n",
      " |      Using `fill_value` fills Nones prior to passing the column to the\n",
      " |      merge function.\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame({'A': [0, 0], 'B': [None, 4]})\n",
      " |      >>> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})\n",
      " |      >>> df1.combine(df2, take_smaller, fill_value=-5)\n",
      " |         A    B\n",
      " |      0  0 -5.0\n",
      " |      1  0  4.0\n",
      " |      \n",
      " |      However, if the same element in both dataframes is None, that None\n",
      " |      is preserved\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame({'A': [0, 0], 'B': [None, 4]})\n",
      " |      >>> df2 = pd.DataFrame({'A': [1, 1], 'B': [None, 3]})\n",
      " |      >>> df1.combine(df2, take_smaller, fill_value=-5)\n",
      " |          A    B\n",
      " |      0  0 -5.0\n",
      " |      1  0  3.0\n",
      " |      \n",
      " |      Example that demonstrates the use of `overwrite` and behavior when\n",
      " |      the axis differ between the dataframes.\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame({'A': [0, 0], 'B': [4, 4]})\n",
      " |      >>> df2 = pd.DataFrame({'B': [3, 3], 'C': [-10, 1], }, index=[1, 2])\n",
      " |      >>> df1.combine(df2, take_smaller)\n",
      " |           A    B     C\n",
      " |      0  NaN  NaN   NaN\n",
      " |      1  NaN  3.0 -10.0\n",
      " |      2  NaN  3.0   1.0\n",
      " |      \n",
      " |      >>> df1.combine(df2, take_smaller, overwrite=False)\n",
      " |           A    B     C\n",
      " |      0  0.0  NaN   NaN\n",
      " |      1  0.0  3.0 -10.0\n",
      " |      2  NaN  3.0   1.0\n",
      " |      \n",
      " |      Demonstrating the preference of the passed in dataframe.\n",
      " |      \n",
      " |      >>> df2 = pd.DataFrame({'B': [3, 3], 'C': [1, 1], }, index=[1, 2])\n",
      " |      >>> df2.combine(df1, take_smaller)\n",
      " |         A    B   C\n",
      " |      0  0.0  NaN NaN\n",
      " |      1  0.0  3.0 NaN\n",
      " |      2  NaN  3.0 NaN\n",
      " |      \n",
      " |      >>> df2.combine(df1, take_smaller, overwrite=False)\n",
      " |           A    B   C\n",
      " |      0  0.0  NaN NaN\n",
      " |      1  0.0  3.0 1.0\n",
      " |      2  NaN  3.0 1.0\n",
      " |  \n",
      " |  combine_first(self, other: 'DataFrame') -> 'DataFrame'\n",
      " |      Update null elements with value in the same location in `other`.\n",
      " |      \n",
      " |      Combine two DataFrame objects by filling null values in one DataFrame\n",
      " |      with non-null values from other DataFrame. The row and column indexes\n",
      " |      of the resulting DataFrame will be the union of the two.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame\n",
      " |          Provided DataFrame to use to fill null values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The result of combining the provided DataFrame with the other object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.combine : Perform series-wise operation on two DataFrames\n",
      " |          using a given function.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df1 = pd.DataFrame({'A': [None, 0], 'B': [None, 4]})\n",
      " |      >>> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})\n",
      " |      >>> df1.combine_first(df2)\n",
      " |           A    B\n",
      " |      0  1.0  3.0\n",
      " |      1  0.0  4.0\n",
      " |      \n",
      " |      Null values still persist if the location of that null value\n",
      " |      does not exist in `other`\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame({'A': [None, 0], 'B': [4, None]})\n",
      " |      >>> df2 = pd.DataFrame({'B': [3, 3], 'C': [1, 1]}, index=[1, 2])\n",
      " |      >>> df1.combine_first(df2)\n",
      " |           A    B    C\n",
      " |      0  NaN  4.0  NaN\n",
      " |      1  0.0  3.0  1.0\n",
      " |      2  NaN  3.0  1.0\n",
      " |  \n",
      " |  compare(self, other: 'DataFrame', align_axis: 'Axis' = 1, keep_shape: 'bool' = False, keep_equal: 'bool' = False) -> 'DataFrame'\n",
      " |      Compare to another DataFrame and show the differences.\n",
      " |      \n",
      " |      .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame\n",
      " |          Object to compare with.\n",
      " |      \n",
      " |      align_axis : {0 or 'index', 1 or 'columns'}, default 1\n",
      " |          Determine which axis to align the comparison on.\n",
      " |      \n",
      " |          * 0, or 'index' : Resulting differences are stacked vertically\n",
      " |              with rows drawn alternately from self and other.\n",
      " |          * 1, or 'columns' : Resulting differences are aligned horizontally\n",
      " |              with columns drawn alternately from self and other.\n",
      " |      \n",
      " |      keep_shape : bool, default False\n",
      " |          If true, all rows and columns are kept.\n",
      " |          Otherwise, only the ones with different values are kept.\n",
      " |      \n",
      " |      keep_equal : bool, default False\n",
      " |          If true, the result keeps values that are equal.\n",
      " |          Otherwise, equal values are shown as NaNs.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          DataFrame that shows the differences stacked side by side.\n",
      " |      \n",
      " |          The resulting index will be a MultiIndex with 'self' and 'other'\n",
      " |          stacked alternately at the inner level.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          When the two DataFrames don't have identical labels or shape.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.compare : Compare with another Series and show differences.\n",
      " |      DataFrame.equals : Test whether two objects contain the same elements.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Matching NaNs will not appear as a difference.\n",
      " |      \n",
      " |      Can only compare identically-labeled\n",
      " |      (i.e. same shape, identical row and column labels) DataFrames\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(\n",
      " |      ...     {\n",
      " |      ...         \"col1\": [\"a\", \"a\", \"b\", \"b\", \"a\"],\n",
      " |      ...         \"col2\": [1.0, 2.0, 3.0, np.nan, 5.0],\n",
      " |      ...         \"col3\": [1.0, 2.0, 3.0, 4.0, 5.0]\n",
      " |      ...     },\n",
      " |      ...     columns=[\"col1\", \"col2\", \"col3\"],\n",
      " |      ... )\n",
      " |      >>> df\n",
      " |        col1  col2  col3\n",
      " |      0    a   1.0   1.0\n",
      " |      1    a   2.0   2.0\n",
      " |      2    b   3.0   3.0\n",
      " |      3    b   NaN   4.0\n",
      " |      4    a   5.0   5.0\n",
      " |      \n",
      " |      >>> df2 = df.copy()\n",
      " |      >>> df2.loc[0, 'col1'] = 'c'\n",
      " |      >>> df2.loc[2, 'col3'] = 4.0\n",
      " |      >>> df2\n",
      " |        col1  col2  col3\n",
      " |      0    c   1.0   1.0\n",
      " |      1    a   2.0   2.0\n",
      " |      2    b   3.0   4.0\n",
      " |      3    b   NaN   4.0\n",
      " |      4    a   5.0   5.0\n",
      " |      \n",
      " |      Align the differences on columns\n",
      " |      \n",
      " |      >>> df.compare(df2)\n",
      " |        col1       col3\n",
      " |        self other self other\n",
      " |      0    a     c  NaN   NaN\n",
      " |      2  NaN   NaN  3.0   4.0\n",
      " |      \n",
      " |      Stack the differences on rows\n",
      " |      \n",
      " |      >>> df.compare(df2, align_axis=0)\n",
      " |              col1  col3\n",
      " |      0 self     a   NaN\n",
      " |        other    c   NaN\n",
      " |      2 self   NaN   3.0\n",
      " |        other  NaN   4.0\n",
      " |      \n",
      " |      Keep the equal values\n",
      " |      \n",
      " |      >>> df.compare(df2, keep_equal=True)\n",
      " |        col1       col3\n",
      " |        self other self other\n",
      " |      0    a     c  1.0   1.0\n",
      " |      2    b     b  3.0   4.0\n",
      " |      \n",
      " |      Keep all original rows and columns\n",
      " |      \n",
      " |      >>> df.compare(df2, keep_shape=True)\n",
      " |        col1       col2       col3\n",
      " |        self other self other self other\n",
      " |      0    a     c  NaN   NaN  NaN   NaN\n",
      " |      1  NaN   NaN  NaN   NaN  NaN   NaN\n",
      " |      2  NaN   NaN  NaN   NaN  3.0   4.0\n",
      " |      3  NaN   NaN  NaN   NaN  NaN   NaN\n",
      " |      4  NaN   NaN  NaN   NaN  NaN   NaN\n",
      " |      \n",
      " |      Keep all original rows and columns and also all original values\n",
      " |      \n",
      " |      >>> df.compare(df2, keep_shape=True, keep_equal=True)\n",
      " |        col1       col2       col3\n",
      " |        self other self other self other\n",
      " |      0    a     c  1.0   1.0  1.0   1.0\n",
      " |      1    a     a  2.0   2.0  2.0   2.0\n",
      " |      2    b     b  3.0   3.0  3.0   4.0\n",
      " |      3    b     b  NaN   NaN  4.0   4.0\n",
      " |      4    a     a  5.0   5.0  5.0   5.0\n",
      " |  \n",
      " |  corr(self, method: 'str | Callable[[np.ndarray, np.ndarray], float]' = 'pearson', min_periods: 'int' = 1) -> 'DataFrame'\n",
      " |      Compute pairwise correlation of columns, excluding NA/null values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : {'pearson', 'kendall', 'spearman'} or callable\n",
      " |          Method of correlation:\n",
      " |      \n",
      " |          * pearson : standard correlation coefficient\n",
      " |          * kendall : Kendall Tau correlation coefficient\n",
      " |          * spearman : Spearman rank correlation\n",
      " |          * callable: callable with input two 1d ndarrays\n",
      " |              and returning a float. Note that the returned matrix from corr\n",
      " |              will have 1 along the diagonals and will be symmetric\n",
      " |              regardless of the callable's behavior.\n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations required per pair of columns\n",
      " |          to have a valid result. Currently only available for Pearson\n",
      " |          and Spearman correlation.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Correlation matrix.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.corrwith : Compute pairwise correlation with another\n",
      " |          DataFrame or Series.\n",
      " |      Series.corr : Compute the correlation between two Series.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> def histogram_intersection(a, b):\n",
      " |      ...     v = np.minimum(a, b).sum().round(decimals=1)\n",
      " |      ...     return v\n",
      " |      >>> df = pd.DataFrame([(.2, .3), (.0, .6), (.6, .0), (.2, .1)],\n",
      " |      ...                   columns=['dogs', 'cats'])\n",
      " |      >>> df.corr(method=histogram_intersection)\n",
      " |            dogs  cats\n",
      " |      dogs   1.0   0.3\n",
      " |      cats   0.3   1.0\n",
      " |  \n",
      " |  corrwith(self, other, axis: 'Axis' = 0, drop=False, method='pearson') -> 'Series'\n",
      " |      Compute pairwise correlation.\n",
      " |      \n",
      " |      Pairwise correlation is computed between rows or columns of\n",
      " |      DataFrame with rows or columns of Series or DataFrame. DataFrames\n",
      " |      are first aligned along both axes before computing the\n",
      " |      correlations.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame, Series\n",
      " |          Object with which to compute correlations.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to use. 0 or 'index' to compute column-wise, 1 or 'columns' for\n",
      " |          row-wise.\n",
      " |      drop : bool, default False\n",
      " |          Drop missing indices from result.\n",
      " |      method : {'pearson', 'kendall', 'spearman'} or callable\n",
      " |          Method of correlation:\n",
      " |      \n",
      " |          * pearson : standard correlation coefficient\n",
      " |          * kendall : Kendall Tau correlation coefficient\n",
      " |          * spearman : Spearman rank correlation\n",
      " |          * callable: callable with input two 1d ndarrays\n",
      " |              and returning a float.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Pairwise correlations.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.corr : Compute pairwise correlation of columns.\n",
      " |  \n",
      " |  count(self, axis: 'Axis' = 0, level: 'Level | None' = None, numeric_only: 'bool' = False)\n",
      " |      Count non-NA cells for each column or row.\n",
      " |      \n",
      " |      The values `None`, `NaN`, `NaT`, and optionally `numpy.inf` (depending\n",
      " |      on `pandas.options.mode.use_inf_as_na`) are considered NA.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          If 0 or 'index' counts are generated for each column.\n",
      " |          If 1 or 'columns' counts are generated for each row.\n",
      " |      level : int or str, optional\n",
      " |          If the axis is a `MultiIndex` (hierarchical), count along a\n",
      " |          particular `level`, collapsing into a `DataFrame`.\n",
      " |          A `str` specifies the level name.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only `float`, `int` or `boolean` data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          For each column/row the number of non-NA/null entries.\n",
      " |          If `level` is specified returns a `DataFrame`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.count: Number of non-NA elements in a Series.\n",
      " |      DataFrame.value_counts: Count unique combinations of columns.\n",
      " |      DataFrame.shape: Number of DataFrame rows and columns (including NA\n",
      " |          elements).\n",
      " |      DataFrame.isna: Boolean same-sized DataFrame showing places of NA\n",
      " |          elements.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Constructing DataFrame from a dictionary:\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"Person\":\n",
      " |      ...                    [\"John\", \"Myla\", \"Lewis\", \"John\", \"Myla\"],\n",
      " |      ...                    \"Age\": [24., np.nan, 21., 33, 26],\n",
      " |      ...                    \"Single\": [False, True, True, True, False]})\n",
      " |      >>> df\n",
      " |         Person   Age  Single\n",
      " |      0    John  24.0   False\n",
      " |      1    Myla   NaN    True\n",
      " |      2   Lewis  21.0    True\n",
      " |      3    John  33.0    True\n",
      " |      4    Myla  26.0   False\n",
      " |      \n",
      " |      Notice the uncounted NA values:\n",
      " |      \n",
      " |      >>> df.count()\n",
      " |      Person    5\n",
      " |      Age       4\n",
      " |      Single    5\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Counts for each **row**:\n",
      " |      \n",
      " |      >>> df.count(axis='columns')\n",
      " |      0    3\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    3\n",
      " |      4    3\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  cov(self, min_periods: 'int | None' = None, ddof: 'int | None' = 1) -> 'DataFrame'\n",
      " |      Compute pairwise covariance of columns, excluding NA/null values.\n",
      " |      \n",
      " |      Compute the pairwise covariance among the series of a DataFrame.\n",
      " |      The returned data frame is the `covariance matrix\n",
      " |      <https://en.wikipedia.org/wiki/Covariance_matrix>`__ of the columns\n",
      " |      of the DataFrame.\n",
      " |      \n",
      " |      Both NA and null values are automatically excluded from the\n",
      " |      calculation. (See the note below about bias from missing values.)\n",
      " |      A threshold can be set for the minimum number of\n",
      " |      observations for each value created. Comparisons with observations\n",
      " |      below this threshold will be returned as ``NaN``.\n",
      " |      \n",
      " |      This method is generally used for the analysis of time series data to\n",
      " |      understand the relationship between different measures\n",
      " |      across time.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations required per pair of columns\n",
      " |          to have a valid result.\n",
      " |      \n",
      " |      ddof : int, default 1\n",
      " |          Delta degrees of freedom.  The divisor used in calculations\n",
      " |          is ``N - ddof``, where ``N`` represents the number of elements.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The covariance matrix of the series of the DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.cov : Compute covariance with another Series.\n",
      " |      core.window.ExponentialMovingWindow.cov: Exponential weighted sample covariance.\n",
      " |      core.window.Expanding.cov : Expanding sample covariance.\n",
      " |      core.window.Rolling.cov : Rolling sample covariance.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Returns the covariance matrix of the DataFrame's time series.\n",
      " |      The covariance is normalized by N-ddof.\n",
      " |      \n",
      " |      For DataFrames that have Series that are missing data (assuming that\n",
      " |      data is `missing at random\n",
      " |      <https://en.wikipedia.org/wiki/Missing_data#Missing_at_random>`__)\n",
      " |      the returned covariance matrix will be an unbiased estimate\n",
      " |      of the variance and covariance between the member Series.\n",
      " |      \n",
      " |      However, for many applications this estimate may not be acceptable\n",
      " |      because the estimate covariance matrix is not guaranteed to be positive\n",
      " |      semi-definite. This could lead to estimate correlations having\n",
      " |      absolute values which are greater than one, and/or a non-invertible\n",
      " |      covariance matrix. See `Estimation of covariance matrices\n",
      " |      <https://en.wikipedia.org/w/index.php?title=Estimation_of_covariance_\n",
      " |      matrices>`__ for more details.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([(1, 2), (0, 3), (2, 0), (1, 1)],\n",
      " |      ...                   columns=['dogs', 'cats'])\n",
      " |      >>> df.cov()\n",
      " |                dogs      cats\n",
      " |      dogs  0.666667 -1.000000\n",
      " |      cats -1.000000  1.666667\n",
      " |      \n",
      " |      >>> np.random.seed(42)\n",
      " |      >>> df = pd.DataFrame(np.random.randn(1000, 5),\n",
      " |      ...                   columns=['a', 'b', 'c', 'd', 'e'])\n",
      " |      >>> df.cov()\n",
      " |                a         b         c         d         e\n",
      " |      a  0.998438 -0.020161  0.059277 -0.008943  0.014144\n",
      " |      b -0.020161  1.059352 -0.008543 -0.024738  0.009826\n",
      " |      c  0.059277 -0.008543  1.010670 -0.001486 -0.000271\n",
      " |      d -0.008943 -0.024738 -0.001486  0.921297 -0.013692\n",
      " |      e  0.014144  0.009826 -0.000271 -0.013692  0.977795\n",
      " |      \n",
      " |      **Minimum number of periods**\n",
      " |      \n",
      " |      This method also supports an optional ``min_periods`` keyword\n",
      " |      that specifies the required minimum number of non-NA observations for\n",
      " |      each column pair in order to have a valid result:\n",
      " |      \n",
      " |      >>> np.random.seed(42)\n",
      " |      >>> df = pd.DataFrame(np.random.randn(20, 3),\n",
      " |      ...                   columns=['a', 'b', 'c'])\n",
      " |      >>> df.loc[df.index[:5], 'a'] = np.nan\n",
      " |      >>> df.loc[df.index[5:10], 'b'] = np.nan\n",
      " |      >>> df.cov(min_periods=12)\n",
      " |                a         b         c\n",
      " |      a  0.316741       NaN -0.150812\n",
      " |      b       NaN  1.248003  0.191417\n",
      " |      c -0.150812  0.191417  0.895202\n",
      " |  \n",
      " |  cummax(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative maximum over a DataFrame or Series axis.\n",
      " |      \n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      maximum.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Return cumulative maximum of Series or DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.window.Expanding.max : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      DataFrame.max : Return the maximum over\n",
      " |          DataFrame axis.\n",
      " |      DataFrame.cummax : Return cumulative maximum over DataFrame axis.\n",
      " |      DataFrame.cummin : Return cumulative minimum over DataFrame axis.\n",
      " |      DataFrame.cumsum : Return cumulative sum over DataFrame axis.\n",
      " |      DataFrame.cumprod : Return cumulative product over DataFrame axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      By default, NA values are ignored.\n",
      " |      \n",
      " |      >>> s.cummax()\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3    5.0\n",
      " |      4    5.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |      \n",
      " |      >>> s.cummax(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                    columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      By default, iterates over rows and finds the maximum\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |      \n",
      " |      >>> df.cummax()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  3.0  1.0\n",
      " |      \n",
      " |      To iterate over columns and find the maximum in each row,\n",
      " |      use ``axis=1``\n",
      " |      \n",
      " |      >>> df.cummax(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  2.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  1.0\n",
      " |  \n",
      " |  cummin(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative minimum over a DataFrame or Series axis.\n",
      " |      \n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      minimum.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Return cumulative minimum of Series or DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.window.Expanding.min : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      DataFrame.min : Return the minimum over\n",
      " |          DataFrame axis.\n",
      " |      DataFrame.cummax : Return cumulative maximum over DataFrame axis.\n",
      " |      DataFrame.cummin : Return cumulative minimum over DataFrame axis.\n",
      " |      DataFrame.cumsum : Return cumulative sum over DataFrame axis.\n",
      " |      DataFrame.cumprod : Return cumulative product over DataFrame axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      By default, NA values are ignored.\n",
      " |      \n",
      " |      >>> s.cummin()\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    2.0\n",
      " |      3   -1.0\n",
      " |      4   -1.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |      \n",
      " |      >>> s.cummin(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                    columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      By default, iterates over rows and finds the minimum\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |      \n",
      " |      >>> df.cummin()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  2.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      To iterate over columns and find the minimum in each row,\n",
      " |      use ``axis=1``\n",
      " |      \n",
      " |      >>> df.cummin(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |  \n",
      " |  cumprod(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative product over a DataFrame or Series axis.\n",
      " |      \n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      product.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Return cumulative product of Series or DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.window.Expanding.prod : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      DataFrame.prod : Return the product over\n",
      " |          DataFrame axis.\n",
      " |      DataFrame.cummax : Return cumulative maximum over DataFrame axis.\n",
      " |      DataFrame.cummin : Return cumulative minimum over DataFrame axis.\n",
      " |      DataFrame.cumsum : Return cumulative sum over DataFrame axis.\n",
      " |      DataFrame.cumprod : Return cumulative product over DataFrame axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      By default, NA values are ignored.\n",
      " |      \n",
      " |      >>> s.cumprod()\n",
      " |      0     2.0\n",
      " |      1     NaN\n",
      " |      2    10.0\n",
      " |      3   -10.0\n",
      " |      4    -0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |      \n",
      " |      >>> s.cumprod(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                    columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      By default, iterates over rows and finds the product\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |      \n",
      " |      >>> df.cumprod()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  6.0  NaN\n",
      " |      2  6.0  0.0\n",
      " |      \n",
      " |      To iterate over columns and find the product in each row,\n",
      " |      use ``axis=1``\n",
      " |      \n",
      " |      >>> df.cumprod(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  2.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |  \n",
      " |  cumsum(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative sum over a DataFrame or Series axis.\n",
      " |      \n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      sum.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Return cumulative sum of Series or DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.window.Expanding.sum : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      DataFrame.sum : Return the sum over\n",
      " |          DataFrame axis.\n",
      " |      DataFrame.cummax : Return cumulative maximum over DataFrame axis.\n",
      " |      DataFrame.cummin : Return cumulative minimum over DataFrame axis.\n",
      " |      DataFrame.cumsum : Return cumulative sum over DataFrame axis.\n",
      " |      DataFrame.cumprod : Return cumulative product over DataFrame axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      By default, NA values are ignored.\n",
      " |      \n",
      " |      >>> s.cumsum()\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    7.0\n",
      " |      3    6.0\n",
      " |      4    6.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |      \n",
      " |      >>> s.cumsum(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                    columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      By default, iterates over rows and finds the sum\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |      \n",
      " |      >>> df.cumsum()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  5.0  NaN\n",
      " |      2  6.0  1.0\n",
      " |      \n",
      " |      To iterate over columns and find the sum in each row,\n",
      " |      use ``axis=1``\n",
      " |      \n",
      " |      >>> df.cumsum(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  3.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  1.0\n",
      " |  \n",
      " |  diff(self, periods: 'int' = 1, axis: 'Axis' = 0) -> 'DataFrame'\n",
      " |      First discrete difference of element.\n",
      " |      \n",
      " |      Calculates the difference of a Dataframe element compared with another\n",
      " |      element in the Dataframe (default is element in previous row).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int, default 1\n",
      " |          Periods to shift for calculating difference, accepts negative\n",
      " |          values.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Take difference over rows (0) or columns (1).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Dataframe\n",
      " |          First differences of the Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Dataframe.pct_change: Percent change over given number of periods.\n",
      " |      Dataframe.shift: Shift index by desired number of periods with an\n",
      " |          optional time freq.\n",
      " |      Series.diff: First discrete difference of object.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For boolean dtypes, this uses :meth:`operator.xor` rather than\n",
      " |      :meth:`operator.sub`.\n",
      " |      The result is calculated according to current dtype in Dataframe,\n",
      " |      however dtype of the result is always float64.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Difference with previous row\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'a': [1, 2, 3, 4, 5, 6],\n",
      " |      ...                    'b': [1, 1, 2, 3, 5, 8],\n",
      " |      ...                    'c': [1, 4, 9, 16, 25, 36]})\n",
      " |      >>> df\n",
      " |         a  b   c\n",
      " |      0  1  1   1\n",
      " |      1  2  1   4\n",
      " |      2  3  2   9\n",
      " |      3  4  3  16\n",
      " |      4  5  5  25\n",
      " |      5  6  8  36\n",
      " |      \n",
      " |      >>> df.diff()\n",
      " |           a    b     c\n",
      " |      0  NaN  NaN   NaN\n",
      " |      1  1.0  0.0   3.0\n",
      " |      2  1.0  1.0   5.0\n",
      " |      3  1.0  1.0   7.0\n",
      " |      4  1.0  2.0   9.0\n",
      " |      5  1.0  3.0  11.0\n",
      " |      \n",
      " |      Difference with previous column\n",
      " |      \n",
      " |      >>> df.diff(axis=1)\n",
      " |          a  b   c\n",
      " |      0 NaN  0   0\n",
      " |      1 NaN -1   3\n",
      " |      2 NaN -1   7\n",
      " |      3 NaN -1  13\n",
      " |      4 NaN  0  20\n",
      " |      5 NaN  2  28\n",
      " |      \n",
      " |      Difference with 3rd previous row\n",
      " |      \n",
      " |      >>> df.diff(periods=3)\n",
      " |           a    b     c\n",
      " |      0  NaN  NaN   NaN\n",
      " |      1  NaN  NaN   NaN\n",
      " |      2  NaN  NaN   NaN\n",
      " |      3  3.0  2.0  15.0\n",
      " |      4  3.0  4.0  21.0\n",
      " |      5  3.0  6.0  27.0\n",
      " |      \n",
      " |      Difference with following row\n",
      " |      \n",
      " |      >>> df.diff(periods=-1)\n",
      " |           a    b     c\n",
      " |      0 -1.0  0.0  -3.0\n",
      " |      1 -1.0 -1.0  -5.0\n",
      " |      2 -1.0 -1.0  -7.0\n",
      " |      3 -1.0 -2.0  -9.0\n",
      " |      4 -1.0 -3.0 -11.0\n",
      " |      5  NaN  NaN   NaN\n",
      " |      \n",
      " |      Overflow in input dtype\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'a': [1, 0]}, dtype=np.uint8)\n",
      " |      >>> df.diff()\n",
      " |             a\n",
      " |      0    NaN\n",
      " |      1  255.0\n",
      " |  \n",
      " |  div = truediv(self, other, axis='columns', level=None, fill_value=None)\n",
      " |  \n",
      " |  divide = truediv(self, other, axis='columns', level=None, fill_value=None)\n",
      " |  \n",
      " |  dot(self, other: 'AnyArrayLike | DataFrame') -> 'DataFrame | Series'\n",
      " |      Compute the matrix multiplication between the DataFrame and other.\n",
      " |      \n",
      " |      This method computes the matrix product between the DataFrame and the\n",
      " |      values of an other Series, DataFrame or a numpy array.\n",
      " |      \n",
      " |      It can also be called using ``self @ other`` in Python >= 3.5.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame or array-like\n",
      " |          The other object to compute the matrix product with.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          If other is a Series, return the matrix product between self and\n",
      " |          other as a Series. If other is a DataFrame or a numpy.array, return\n",
      " |          the matrix product of self and other in a DataFrame of a np.array.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.dot: Similar method for Series.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The dimensions of DataFrame and other must be compatible in order to\n",
      " |      compute the matrix multiplication. In addition, the column names of\n",
      " |      DataFrame and the index of other must contain the same values, as they\n",
      " |      will be aligned prior to the multiplication.\n",
      " |      \n",
      " |      The dot method for Series computes the inner product, instead of the\n",
      " |      matrix product here.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Here we multiply a DataFrame with a Series.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[0, 1, -2, -1], [1, 1, 1, 1]])\n",
      " |      >>> s = pd.Series([1, 1, 2, 1])\n",
      " |      >>> df.dot(s)\n",
      " |      0    -4\n",
      " |      1     5\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Here we multiply a DataFrame with another DataFrame.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame([[0, 1], [1, 2], [-1, -1], [2, 0]])\n",
      " |      >>> df.dot(other)\n",
      " |          0   1\n",
      " |      0   1   4\n",
      " |      1   2   2\n",
      " |      \n",
      " |      Note that the dot method give the same result as @\n",
      " |      \n",
      " |      >>> df @ other\n",
      " |          0   1\n",
      " |      0   1   4\n",
      " |      1   2   2\n",
      " |      \n",
      " |      The dot method works also if other is an np.array.\n",
      " |      \n",
      " |      >>> arr = np.array([[0, 1], [1, 2], [-1, -1], [2, 0]])\n",
      " |      >>> df.dot(arr)\n",
      " |          0   1\n",
      " |      0   1   4\n",
      " |      1   2   2\n",
      " |      \n",
      " |      Note how shuffling of the objects does not change the result.\n",
      " |      \n",
      " |      >>> s2 = s.reindex([1, 0, 2, 3])\n",
      " |      >>> df.dot(s2)\n",
      " |      0    -4\n",
      " |      1     5\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  drop(self, labels=None, axis: 'Axis' = 0, index=None, columns=None, level: 'Level | None' = None, inplace: 'bool' = False, errors: 'str' = 'raise')\n",
      " |      Drop specified labels from rows or columns.\n",
      " |      \n",
      " |      Remove rows or columns by specifying label names and corresponding\n",
      " |      axis, or by specifying directly index or column names. When using a\n",
      " |      multi-index, labels on different levels can be removed by specifying\n",
      " |      the level. See the `user guide <advanced.shown_levels>`\n",
      " |      for more information about the now unused levels.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      labels : single label or list-like\n",
      " |          Index or column labels to drop. A tuple will be used as a single\n",
      " |          label and not treated as a list-like.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Whether to drop labels from the index (0 or 'index') or\n",
      " |          columns (1 or 'columns').\n",
      " |      index : single label or list-like\n",
      " |          Alternative to specifying axis (``labels, axis=0``\n",
      " |          is equivalent to ``index=labels``).\n",
      " |      columns : single label or list-like\n",
      " |          Alternative to specifying axis (``labels, axis=1``\n",
      " |          is equivalent to ``columns=labels``).\n",
      " |      level : int or level name, optional\n",
      " |          For MultiIndex, level from which the labels will be removed.\n",
      " |      inplace : bool, default False\n",
      " |          If False, return a copy. Otherwise, do operation\n",
      " |          inplace and return None.\n",
      " |      errors : {'ignore', 'raise'}, default 'raise'\n",
      " |          If 'ignore', suppress error and only existing labels are\n",
      " |          dropped.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          DataFrame without the removed index or column labels or\n",
      " |          None if ``inplace=True``.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError\n",
      " |          If any of the labels is not found in the selected axis.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Label-location based indexer for selection by label.\n",
      " |      DataFrame.dropna : Return DataFrame with labels on given axis omitted\n",
      " |          where (all or any) data are missing.\n",
      " |      DataFrame.drop_duplicates : Return DataFrame with duplicate rows\n",
      " |          removed, optionally only considering certain columns.\n",
      " |      Series.drop : Return Series with specified index labels removed.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(np.arange(12).reshape(3, 4),\n",
      " |      ...                   columns=['A', 'B', 'C', 'D'])\n",
      " |      >>> df\n",
      " |         A  B   C   D\n",
      " |      0  0  1   2   3\n",
      " |      1  4  5   6   7\n",
      " |      2  8  9  10  11\n",
      " |      \n",
      " |      Drop columns\n",
      " |      \n",
      " |      >>> df.drop(['B', 'C'], axis=1)\n",
      " |         A   D\n",
      " |      0  0   3\n",
      " |      1  4   7\n",
      " |      2  8  11\n",
      " |      \n",
      " |      >>> df.drop(columns=['B', 'C'])\n",
      " |         A   D\n",
      " |      0  0   3\n",
      " |      1  4   7\n",
      " |      2  8  11\n",
      " |      \n",
      " |      Drop a row by index\n",
      " |      \n",
      " |      >>> df.drop([0, 1])\n",
      " |         A  B   C   D\n",
      " |      2  8  9  10  11\n",
      " |      \n",
      " |      Drop columns and/or rows of MultiIndex DataFrame\n",
      " |      \n",
      " |      >>> midx = pd.MultiIndex(levels=[['lama', 'cow', 'falcon'],\n",
      " |      ...                              ['speed', 'weight', 'length']],\n",
      " |      ...                      codes=[[0, 0, 0, 1, 1, 1, 2, 2, 2],\n",
      " |      ...                             [0, 1, 2, 0, 1, 2, 0, 1, 2]])\n",
      " |      >>> df = pd.DataFrame(index=midx, columns=['big', 'small'],\n",
      " |      ...                   data=[[45, 30], [200, 100], [1.5, 1], [30, 20],\n",
      " |      ...                         [250, 150], [1.5, 0.8], [320, 250],\n",
      " |      ...                         [1, 0.8], [0.3, 0.2]])\n",
      " |      >>> df\n",
      " |                      big     small\n",
      " |      lama    speed   45.0    30.0\n",
      " |              weight  200.0   100.0\n",
      " |              length  1.5     1.0\n",
      " |      cow     speed   30.0    20.0\n",
      " |              weight  250.0   150.0\n",
      " |              length  1.5     0.8\n",
      " |      falcon  speed   320.0   250.0\n",
      " |              weight  1.0     0.8\n",
      " |              length  0.3     0.2\n",
      " |      \n",
      " |      Drop a specific index combination from the MultiIndex\n",
      " |      DataFrame, i.e., drop the combination ``'falcon'`` and\n",
      " |      ``'weight'``, which deletes only the corresponding row\n",
      " |      \n",
      " |      >>> df.drop(index=('falcon', 'weight'))\n",
      " |                      big     small\n",
      " |      lama    speed   45.0    30.0\n",
      " |              weight  200.0   100.0\n",
      " |              length  1.5     1.0\n",
      " |      cow     speed   30.0    20.0\n",
      " |              weight  250.0   150.0\n",
      " |              length  1.5     0.8\n",
      " |      falcon  speed   320.0   250.0\n",
      " |              length  0.3     0.2\n",
      " |      \n",
      " |      >>> df.drop(index='cow', columns='small')\n",
      " |                      big\n",
      " |      lama    speed   45.0\n",
      " |              weight  200.0\n",
      " |              length  1.5\n",
      " |      falcon  speed   320.0\n",
      " |              weight  1.0\n",
      " |              length  0.3\n",
      " |      \n",
      " |      >>> df.drop(index='length', level=1)\n",
      " |                      big     small\n",
      " |      lama    speed   45.0    30.0\n",
      " |              weight  200.0   100.0\n",
      " |      cow     speed   30.0    20.0\n",
      " |              weight  250.0   150.0\n",
      " |      falcon  speed   320.0   250.0\n",
      " |              weight  1.0     0.8\n",
      " |  \n",
      " |  drop_duplicates(self, subset: 'Hashable | Sequence[Hashable] | None' = None, keep: \"Literal['first'] | Literal['last'] | Literal[False]\" = 'first', inplace: 'bool' = False, ignore_index: 'bool' = False) -> 'DataFrame | None'\n",
      " |      Return DataFrame with duplicate rows removed.\n",
      " |      \n",
      " |      Considering certain columns is optional. Indexes, including time indexes\n",
      " |      are ignored.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      subset : column label or sequence of labels, optional\n",
      " |          Only consider certain columns for identifying duplicates, by\n",
      " |          default use all of the columns.\n",
      " |      keep : {'first', 'last', False}, default 'first'\n",
      " |          Determines which duplicates (if any) to keep.\n",
      " |          - ``first`` : Drop duplicates except for the first occurrence.\n",
      " |          - ``last`` : Drop duplicates except for the last occurrence.\n",
      " |          - False : Drop all duplicates.\n",
      " |      inplace : bool, default False\n",
      " |          Whether to drop duplicates in place or to return a copy.\n",
      " |      ignore_index : bool, default False\n",
      " |          If True, the resulting axis will be labeled 0, 1, …, n - 1.\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          DataFrame with duplicates removed or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.value_counts: Count unique combinations of columns.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Consider dataset containing ramen rating.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'brand': ['Yum Yum', 'Yum Yum', 'Indomie', 'Indomie', 'Indomie'],\n",
      " |      ...     'style': ['cup', 'cup', 'cup', 'pack', 'pack'],\n",
      " |      ...     'rating': [4, 4, 3.5, 15, 5]\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |          brand style  rating\n",
      " |      0  Yum Yum   cup     4.0\n",
      " |      1  Yum Yum   cup     4.0\n",
      " |      2  Indomie   cup     3.5\n",
      " |      3  Indomie  pack    15.0\n",
      " |      4  Indomie  pack     5.0\n",
      " |      \n",
      " |      By default, it removes duplicate rows based on all columns.\n",
      " |      \n",
      " |      >>> df.drop_duplicates()\n",
      " |          brand style  rating\n",
      " |      0  Yum Yum   cup     4.0\n",
      " |      2  Indomie   cup     3.5\n",
      " |      3  Indomie  pack    15.0\n",
      " |      4  Indomie  pack     5.0\n",
      " |      \n",
      " |      To remove duplicates on specific column(s), use ``subset``.\n",
      " |      \n",
      " |      >>> df.drop_duplicates(subset=['brand'])\n",
      " |          brand style  rating\n",
      " |      0  Yum Yum   cup     4.0\n",
      " |      2  Indomie   cup     3.5\n",
      " |      \n",
      " |      To remove duplicates and keep last occurrences, use ``keep``.\n",
      " |      \n",
      " |      >>> df.drop_duplicates(subset=['brand', 'style'], keep='last')\n",
      " |          brand style  rating\n",
      " |      1  Yum Yum   cup     4.0\n",
      " |      2  Indomie   cup     3.5\n",
      " |      4  Indomie  pack     5.0\n",
      " |  \n",
      " |  dropna(self, axis: 'Axis' = 0, how: 'str' = 'any', thresh=None, subset: 'IndexLabel' = None, inplace: 'bool' = False)\n",
      " |      Remove missing values.\n",
      " |      \n",
      " |      See the :ref:`User Guide <missing_data>` for more on which values are\n",
      " |      considered missing, and how to work with missing data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Determine if rows or columns which contain missing values are\n",
      " |          removed.\n",
      " |      \n",
      " |          * 0, or 'index' : Drop rows which contain missing values.\n",
      " |          * 1, or 'columns' : Drop columns which contain missing value.\n",
      " |      \n",
      " |          .. versionchanged:: 1.0.0\n",
      " |      \n",
      " |             Pass tuple or list to drop on multiple axes.\n",
      " |             Only a single axis is allowed.\n",
      " |      \n",
      " |      how : {'any', 'all'}, default 'any'\n",
      " |          Determine if row or column is removed from DataFrame, when we have\n",
      " |          at least one NA or all NA.\n",
      " |      \n",
      " |          * 'any' : If any NA values are present, drop that row or column.\n",
      " |          * 'all' : If all values are NA, drop that row or column.\n",
      " |      \n",
      " |      thresh : int, optional\n",
      " |          Require that many non-NA values.\n",
      " |      subset : column label or sequence of labels, optional\n",
      " |          Labels along other axis to consider, e.g. if you are dropping rows\n",
      " |          these would be a list of columns to include.\n",
      " |      inplace : bool, default False\n",
      " |          If True, do operation inplace and return None.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          DataFrame with NA entries dropped from it or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.isna: Indicate missing values.\n",
      " |      DataFrame.notna : Indicate existing (non-missing) values.\n",
      " |      DataFrame.fillna : Replace missing values.\n",
      " |      Series.dropna : Drop missing values.\n",
      " |      Index.dropna : Drop missing indices.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"name\": ['Alfred', 'Batman', 'Catwoman'],\n",
      " |      ...                    \"toy\": [np.nan, 'Batmobile', 'Bullwhip'],\n",
      " |      ...                    \"born\": [pd.NaT, pd.Timestamp(\"1940-04-25\"),\n",
      " |      ...                             pd.NaT]})\n",
      " |      >>> df\n",
      " |             name        toy       born\n",
      " |      0    Alfred        NaN        NaT\n",
      " |      1    Batman  Batmobile 1940-04-25\n",
      " |      2  Catwoman   Bullwhip        NaT\n",
      " |      \n",
      " |      Drop the rows where at least one element is missing.\n",
      " |      \n",
      " |      >>> df.dropna()\n",
      " |           name        toy       born\n",
      " |      1  Batman  Batmobile 1940-04-25\n",
      " |      \n",
      " |      Drop the columns where at least one element is missing.\n",
      " |      \n",
      " |      >>> df.dropna(axis='columns')\n",
      " |             name\n",
      " |      0    Alfred\n",
      " |      1    Batman\n",
      " |      2  Catwoman\n",
      " |      \n",
      " |      Drop the rows where all elements are missing.\n",
      " |      \n",
      " |      >>> df.dropna(how='all')\n",
      " |             name        toy       born\n",
      " |      0    Alfred        NaN        NaT\n",
      " |      1    Batman  Batmobile 1940-04-25\n",
      " |      2  Catwoman   Bullwhip        NaT\n",
      " |      \n",
      " |      Keep only the rows with at least 2 non-NA values.\n",
      " |      \n",
      " |      >>> df.dropna(thresh=2)\n",
      " |             name        toy       born\n",
      " |      1    Batman  Batmobile 1940-04-25\n",
      " |      2  Catwoman   Bullwhip        NaT\n",
      " |      \n",
      " |      Define in which columns to look for missing values.\n",
      " |      \n",
      " |      >>> df.dropna(subset=['name', 'toy'])\n",
      " |             name        toy       born\n",
      " |      1    Batman  Batmobile 1940-04-25\n",
      " |      2  Catwoman   Bullwhip        NaT\n",
      " |      \n",
      " |      Keep the DataFrame with valid entries in the same variable.\n",
      " |      \n",
      " |      >>> df.dropna(inplace=True)\n",
      " |      >>> df\n",
      " |           name        toy       born\n",
      " |      1  Batman  Batmobile 1940-04-25\n",
      " |  \n",
      " |  duplicated(self, subset: 'Hashable | Sequence[Hashable] | None' = None, keep: \"Literal['first'] | Literal['last'] | Literal[False]\" = 'first') -> 'Series'\n",
      " |      Return boolean Series denoting duplicate rows.\n",
      " |      \n",
      " |      Considering certain columns is optional.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      subset : column label or sequence of labels, optional\n",
      " |          Only consider certain columns for identifying duplicates, by\n",
      " |          default use all of the columns.\n",
      " |      keep : {'first', 'last', False}, default 'first'\n",
      " |          Determines which duplicates (if any) to mark.\n",
      " |      \n",
      " |          - ``first`` : Mark duplicates as ``True`` except for the first occurrence.\n",
      " |          - ``last`` : Mark duplicates as ``True`` except for the last occurrence.\n",
      " |          - False : Mark all duplicates as ``True``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Boolean series for each duplicated rows.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.duplicated : Equivalent method on index.\n",
      " |      Series.duplicated : Equivalent method on Series.\n",
      " |      Series.drop_duplicates : Remove duplicate values from Series.\n",
      " |      DataFrame.drop_duplicates : Remove duplicate values from DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Consider dataset containing ramen rating.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'brand': ['Yum Yum', 'Yum Yum', 'Indomie', 'Indomie', 'Indomie'],\n",
      " |      ...     'style': ['cup', 'cup', 'cup', 'pack', 'pack'],\n",
      " |      ...     'rating': [4, 4, 3.5, 15, 5]\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |          brand style  rating\n",
      " |      0  Yum Yum   cup     4.0\n",
      " |      1  Yum Yum   cup     4.0\n",
      " |      2  Indomie   cup     3.5\n",
      " |      3  Indomie  pack    15.0\n",
      " |      4  Indomie  pack     5.0\n",
      " |      \n",
      " |      By default, for each set of duplicated values, the first occurrence\n",
      " |      is set on False and all others on True.\n",
      " |      \n",
      " |      >>> df.duplicated()\n",
      " |      0    False\n",
      " |      1     True\n",
      " |      2    False\n",
      " |      3    False\n",
      " |      4    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      By using 'last', the last occurrence of each set of duplicated values\n",
      " |      is set on False and all others on True.\n",
      " |      \n",
      " |      >>> df.duplicated(keep='last')\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      2    False\n",
      " |      3    False\n",
      " |      4    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      By setting ``keep`` on False, all duplicates are True.\n",
      " |      \n",
      " |      >>> df.duplicated(keep=False)\n",
      " |      0     True\n",
      " |      1     True\n",
      " |      2    False\n",
      " |      3    False\n",
      " |      4    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      To find duplicates on specific column(s), use ``subset``.\n",
      " |      \n",
      " |      >>> df.duplicated(subset=['brand'])\n",
      " |      0    False\n",
      " |      1     True\n",
      " |      2    False\n",
      " |      3     True\n",
      " |      4     True\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  eq(self, other, axis='columns', level=None)\n",
      " |      Get Equal to of dataframe and other, element-wise (binary operator `eq`).\n",
      " |      \n",
      " |      Among flexible wrappers (`eq`, `ne`, `le`, `lt`, `ge`, `gt`) to comparison\n",
      " |      operators.\n",
      " |      \n",
      " |      Equivalent to `==`, `!=`, `<=`, `<`, `>=`, `>` with support to choose axis\n",
      " |      (rows or columns) and level for comparison.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 'columns'\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns').\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the passed\n",
      " |          MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame of bool\n",
      " |          Result of the comparison.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.eq : Compare DataFrames for equality elementwise.\n",
      " |      DataFrame.ne : Compare DataFrames for inequality elementwise.\n",
      " |      DataFrame.le : Compare DataFrames for less than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.lt : Compare DataFrames for strictly less than\n",
      " |          inequality elementwise.\n",
      " |      DataFrame.ge : Compare DataFrames for greater than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.gt : Compare DataFrames for strictly greater than\n",
      " |          inequality elementwise.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      `NaN` values are considered different (i.e. `NaN` != `NaN`).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'cost': [250, 150, 100],\n",
      " |      ...                    'revenue': [100, 250, 300]},\n",
      " |      ...                   index=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |         cost  revenue\n",
      " |      A   250      100\n",
      " |      B   150      250\n",
      " |      C   100      300\n",
      " |      \n",
      " |      Comparison with a scalar, using either the operator or method:\n",
      " |      \n",
      " |      >>> df == 100\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      >>> df.eq(100)\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      When `other` is a :class:`Series`, the columns of a DataFrame are aligned\n",
      " |      with the index of `other` and broadcast:\n",
      " |      \n",
      " |      >>> df != pd.Series([100, 250], index=[\"cost\", \"revenue\"])\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B   True    False\n",
      " |      C  False     True\n",
      " |      \n",
      " |      Use the method to control the broadcast axis:\n",
      " |      \n",
      " |      >>> df.ne(pd.Series([100, 300], index=[\"A\", \"D\"]), axis='index')\n",
      " |         cost  revenue\n",
      " |      A  True    False\n",
      " |      B  True     True\n",
      " |      C  True     True\n",
      " |      D  True     True\n",
      " |      \n",
      " |      When comparing to an arbitrary sequence, the number of columns must\n",
      " |      match the number elements in `other`:\n",
      " |      \n",
      " |      >>> df == [250, 100]\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B  False    False\n",
      " |      C  False    False\n",
      " |      \n",
      " |      Use the method to control the axis:\n",
      " |      \n",
      " |      >>> df.eq([250, 250, 100], axis='index')\n",
      " |          cost  revenue\n",
      " |      A   True    False\n",
      " |      B  False     True\n",
      " |      C   True    False\n",
      " |      \n",
      " |      Compare to a DataFrame of different shape.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'revenue': [300, 250, 100, 150]},\n",
      " |      ...                      index=['A', 'B', 'C', 'D'])\n",
      " |      >>> other\n",
      " |         revenue\n",
      " |      A      300\n",
      " |      B      250\n",
      " |      C      100\n",
      " |      D      150\n",
      " |      \n",
      " |      >>> df.gt(other)\n",
      " |          cost  revenue\n",
      " |      A  False    False\n",
      " |      B  False    False\n",
      " |      C  False     True\n",
      " |      D  False    False\n",
      " |      \n",
      " |      Compare to a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],\n",
      " |      ...                              'revenue': [100, 250, 300, 200, 175, 225]},\n",
      " |      ...                             index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],\n",
      " |      ...                                    ['A', 'B', 'C', 'A', 'B', 'C']])\n",
      " |      >>> df_multindex\n",
      " |            cost  revenue\n",
      " |      Q1 A   250      100\n",
      " |         B   150      250\n",
      " |         C   100      300\n",
      " |      Q2 A   150      200\n",
      " |         B   300      175\n",
      " |         C   220      225\n",
      " |      \n",
      " |      >>> df.le(df_multindex, level=1)\n",
      " |             cost  revenue\n",
      " |      Q1 A   True     True\n",
      " |         B   True     True\n",
      " |         C   True     True\n",
      " |      Q2 A  False     True\n",
      " |         B   True    False\n",
      " |         C   True    False\n",
      " |  \n",
      " |  eval(self, expr: 'str', inplace: 'bool' = False, **kwargs)\n",
      " |      Evaluate a string describing operations on DataFrame columns.\n",
      " |      \n",
      " |      Operates on columns only, not specific rows or elements.  This allows\n",
      " |      `eval` to run arbitrary code, which can make you vulnerable to code\n",
      " |      injection if you pass user input to this function.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      expr : str\n",
      " |          The expression string to evaluate.\n",
      " |      inplace : bool, default False\n",
      " |          If the expression contains an assignment, whether to perform the\n",
      " |          operation inplace and mutate the existing DataFrame. Otherwise,\n",
      " |          a new DataFrame is returned.\n",
      " |      **kwargs\n",
      " |          See the documentation for :func:`eval` for complete details\n",
      " |          on the keyword arguments accepted by\n",
      " |          :meth:`~pandas.DataFrame.query`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray, scalar, pandas object, or None\n",
      " |          The result of the evaluation or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.query : Evaluates a boolean expression to query the columns\n",
      " |          of a frame.\n",
      " |      DataFrame.assign : Can evaluate an expression or function to create new\n",
      " |          values for a column.\n",
      " |      eval : Evaluate a Python expression as a string using various\n",
      " |          backends.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For more details see the API documentation for :func:`~eval`.\n",
      " |      For detailed examples see :ref:`enhancing performance with eval\n",
      " |      <enhancingperf.eval>`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': range(1, 6), 'B': range(10, 0, -2)})\n",
      " |      >>> df\n",
      " |         A   B\n",
      " |      0  1  10\n",
      " |      1  2   8\n",
      " |      2  3   6\n",
      " |      3  4   4\n",
      " |      4  5   2\n",
      " |      >>> df.eval('A + B')\n",
      " |      0    11\n",
      " |      1    10\n",
      " |      2     9\n",
      " |      3     8\n",
      " |      4     7\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Assignment is allowed though by default the original DataFrame is not\n",
      " |      modified.\n",
      " |      \n",
      " |      >>> df.eval('C = A + B')\n",
      " |         A   B   C\n",
      " |      0  1  10  11\n",
      " |      1  2   8  10\n",
      " |      2  3   6   9\n",
      " |      3  4   4   8\n",
      " |      4  5   2   7\n",
      " |      >>> df\n",
      " |         A   B\n",
      " |      0  1  10\n",
      " |      1  2   8\n",
      " |      2  3   6\n",
      " |      3  4   4\n",
      " |      4  5   2\n",
      " |      \n",
      " |      Use ``inplace=True`` to modify the original DataFrame.\n",
      " |      \n",
      " |      >>> df.eval('C = A + B', inplace=True)\n",
      " |      >>> df\n",
      " |         A   B   C\n",
      " |      0  1  10  11\n",
      " |      1  2   8  10\n",
      " |      2  3   6   9\n",
      " |      3  4   4   8\n",
      " |      4  5   2   7\n",
      " |      \n",
      " |      Multiple columns can be assigned to using multi-line expressions:\n",
      " |      \n",
      " |      >>> df.eval(\n",
      " |      ...     '''\n",
      " |      ... C = A + B\n",
      " |      ... D = A - B\n",
      " |      ... '''\n",
      " |      ... )\n",
      " |         A   B   C  D\n",
      " |      0  1  10  11 -9\n",
      " |      1  2   8  10 -6\n",
      " |      2  3   6   9 -3\n",
      " |      3  4   4   8  0\n",
      " |      4  5   2   7  3\n",
      " |  \n",
      " |  explode(self, column: 'IndexLabel', ignore_index: 'bool' = False) -> 'DataFrame'\n",
      " |      Transform each element of a list-like to a row, replicating index values.\n",
      " |      \n",
      " |      .. versionadded:: 0.25.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      column : IndexLabel\n",
      " |          Column(s) to explode.\n",
      " |          For multiple columns, specify a non-empty list with each element\n",
      " |          be str or tuple, and all specified columns their list-like data\n",
      " |          on same row of the frame must have matching length.\n",
      " |      \n",
      " |          .. versionadded:: 1.3.0\n",
      " |              Multi-column explode\n",
      " |      \n",
      " |      ignore_index : bool, default False\n",
      " |          If True, the resulting index will be labeled 0, 1, …, n - 1.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Exploded lists to rows of the subset columns;\n",
      " |          index will be duplicated for these rows.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError :\n",
      " |          * If columns of the frame are not unique.\n",
      " |          * If specified columns to explode is empty list.\n",
      " |          * If specified columns to explode have not matching count of\n",
      " |            elements rowwise in the frame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.unstack : Pivot a level of the (necessarily hierarchical)\n",
      " |          index labels.\n",
      " |      DataFrame.melt : Unpivot a DataFrame from wide format to long format.\n",
      " |      Series.explode : Explode a DataFrame from list-like columns to long format.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This routine will explode list-likes including lists, tuples, sets,\n",
      " |      Series, and np.ndarray. The result dtype of the subset rows will\n",
      " |      be object. Scalars will be returned unchanged, and empty list-likes will\n",
      " |      result in a np.nan for that row. In addition, the ordering of rows in the\n",
      " |      output will be non-deterministic when exploding sets.\n",
      " |      \n",
      " |      Reference :ref:`the user guide <reshaping.explode>` for more examples.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [[0, 1, 2], 'foo', [], [3, 4]],\n",
      " |      ...                    'B': 1,\n",
      " |      ...                    'C': [['a', 'b', 'c'], np.nan, [], ['d', 'e']]})\n",
      " |      >>> df\n",
      " |                 A  B          C\n",
      " |      0  [0, 1, 2]  1  [a, b, c]\n",
      " |      1        foo  1        NaN\n",
      " |      2         []  1         []\n",
      " |      3     [3, 4]  1     [d, e]\n",
      " |      \n",
      " |      Single-column explode.\n",
      " |      \n",
      " |      >>> df.explode('A')\n",
      " |           A  B          C\n",
      " |      0    0  1  [a, b, c]\n",
      " |      0    1  1  [a, b, c]\n",
      " |      0    2  1  [a, b, c]\n",
      " |      1  foo  1        NaN\n",
      " |      2  NaN  1         []\n",
      " |      3    3  1     [d, e]\n",
      " |      3    4  1     [d, e]\n",
      " |      \n",
      " |      Multi-column explode.\n",
      " |      \n",
      " |      >>> df.explode(list('AC'))\n",
      " |           A  B    C\n",
      " |      0    0  1    a\n",
      " |      0    1  1    b\n",
      " |      0    2  1    c\n",
      " |      1  foo  1  NaN\n",
      " |      2  NaN  1  NaN\n",
      " |      3    3  1    d\n",
      " |      3    4  1    e\n",
      " |  \n",
      " |  ffill(self: 'DataFrame', axis: 'None | Axis' = None, inplace: 'bool' = False, limit: 'None | int' = None, downcast=None) -> 'DataFrame | None'\n",
      " |      Synonym for :meth:`DataFrame.fillna` with ``method='ffill'``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame or None\n",
      " |          Object with missing values filled or None if ``inplace=True``.\n",
      " |  \n",
      " |  fillna(self, value: 'object | ArrayLike | None' = None, method: 'FillnaOptions | None' = None, axis: 'Axis | None' = None, inplace: 'bool' = False, limit=None, downcast=None) -> 'DataFrame | None'\n",
      " |      Fill NA/NaN values using the specified method.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      value : scalar, dict, Series, or DataFrame\n",
      " |          Value to use to fill holes (e.g. 0), alternately a\n",
      " |          dict/Series/DataFrame of values specifying which value to use for\n",
      " |          each index (for a Series) or column (for a DataFrame).  Values not\n",
      " |          in the dict/Series/DataFrame will not be filled. This value cannot\n",
      " |          be a list.\n",
      " |      method : {'backfill', 'bfill', 'pad', 'ffill', None}, default None\n",
      " |          Method to use for filling holes in reindexed Series\n",
      " |          pad / ffill: propagate last valid observation forward to next valid\n",
      " |          backfill / bfill: use next valid observation to fill gap.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Axis along which to fill missing values.\n",
      " |      inplace : bool, default False\n",
      " |          If True, fill in-place. Note: this will modify any\n",
      " |          other views on this object (e.g., a no-copy slice for a column in a\n",
      " |          DataFrame).\n",
      " |      limit : int, default None\n",
      " |          If method is specified, this is the maximum number of consecutive\n",
      " |          NaN values to forward/backward fill. In other words, if there is\n",
      " |          a gap with more than this number of consecutive NaNs, it will only\n",
      " |          be partially filled. If method is not specified, this is the\n",
      " |          maximum number of entries along the entire axis where NaNs will be\n",
      " |          filled. Must be greater than 0 if not None.\n",
      " |      downcast : dict, default is None\n",
      " |          A dict of item->dtype of what to downcast if possible,\n",
      " |          or the string 'infer' which will try to downcast to an appropriate\n",
      " |          equal type (e.g. float64 to int64 if possible).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          Object with missing values filled or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      interpolate : Fill NaN values using interpolation.\n",
      " |      reindex : Conform object to new index.\n",
      " |      asfreq : Convert TimeSeries to specified frequency.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[np.nan, 2, np.nan, 0],\n",
      " |      ...                    [3, 4, np.nan, 1],\n",
      " |      ...                    [np.nan, np.nan, np.nan, np.nan],\n",
      " |      ...                    [np.nan, 3, np.nan, 4]],\n",
      " |      ...                   columns=list(\"ABCD\"))\n",
      " |      >>> df\n",
      " |           A    B   C    D\n",
      " |      0  NaN  2.0 NaN  0.0\n",
      " |      1  3.0  4.0 NaN  1.0\n",
      " |      2  NaN  NaN NaN  NaN\n",
      " |      3  NaN  3.0 NaN  4.0\n",
      " |      \n",
      " |      Replace all NaN elements with 0s.\n",
      " |      \n",
      " |      >>> df.fillna(0)\n",
      " |           A    B    C    D\n",
      " |      0  0.0  2.0  0.0  0.0\n",
      " |      1  3.0  4.0  0.0  1.0\n",
      " |      2  0.0  0.0  0.0  0.0\n",
      " |      3  0.0  3.0  0.0  4.0\n",
      " |      \n",
      " |      We can also propagate non-null values forward or backward.\n",
      " |      \n",
      " |      >>> df.fillna(method=\"ffill\")\n",
      " |           A    B   C    D\n",
      " |      0  NaN  2.0 NaN  0.0\n",
      " |      1  3.0  4.0 NaN  1.0\n",
      " |      2  3.0  4.0 NaN  1.0\n",
      " |      3  3.0  3.0 NaN  4.0\n",
      " |      \n",
      " |      Replace all NaN elements in column 'A', 'B', 'C', and 'D', with 0, 1,\n",
      " |      2, and 3 respectively.\n",
      " |      \n",
      " |      >>> values = {\"A\": 0, \"B\": 1, \"C\": 2, \"D\": 3}\n",
      " |      >>> df.fillna(value=values)\n",
      " |           A    B    C    D\n",
      " |      0  0.0  2.0  2.0  0.0\n",
      " |      1  3.0  4.0  2.0  1.0\n",
      " |      2  0.0  1.0  2.0  3.0\n",
      " |      3  0.0  3.0  2.0  4.0\n",
      " |      \n",
      " |      Only replace the first NaN element.\n",
      " |      \n",
      " |      >>> df.fillna(value=values, limit=1)\n",
      " |           A    B    C    D\n",
      " |      0  0.0  2.0  2.0  0.0\n",
      " |      1  3.0  4.0  NaN  1.0\n",
      " |      2  NaN  1.0  NaN  3.0\n",
      " |      3  NaN  3.0  NaN  4.0\n",
      " |      \n",
      " |      When filling using a DataFrame, replacement happens along\n",
      " |      the same column names and same indices\n",
      " |      \n",
      " |      >>> df2 = pd.DataFrame(np.zeros((4, 4)), columns=list(\"ABCE\"))\n",
      " |      >>> df.fillna(df2)\n",
      " |           A    B    C    D\n",
      " |      0  0.0  2.0  0.0  0.0\n",
      " |      1  3.0  4.0  0.0  1.0\n",
      " |      2  0.0  0.0  0.0  NaN\n",
      " |      3  0.0  3.0  0.0  4.0\n",
      " |      \n",
      " |      Note that column D is not affected since it is not present in df2.\n",
      " |  \n",
      " |  floordiv(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Integer division of dataframe and other, element-wise (binary operator `floordiv`).\n",
      " |      \n",
      " |      Equivalent to ``dataframe // other``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `rfloordiv`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  ge(self, other, axis='columns', level=None)\n",
      " |      Get Greater than or equal to of dataframe and other, element-wise (binary operator `ge`).\n",
      " |      \n",
      " |      Among flexible wrappers (`eq`, `ne`, `le`, `lt`, `ge`, `gt`) to comparison\n",
      " |      operators.\n",
      " |      \n",
      " |      Equivalent to `==`, `!=`, `<=`, `<`, `>=`, `>` with support to choose axis\n",
      " |      (rows or columns) and level for comparison.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 'columns'\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns').\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the passed\n",
      " |          MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame of bool\n",
      " |          Result of the comparison.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.eq : Compare DataFrames for equality elementwise.\n",
      " |      DataFrame.ne : Compare DataFrames for inequality elementwise.\n",
      " |      DataFrame.le : Compare DataFrames for less than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.lt : Compare DataFrames for strictly less than\n",
      " |          inequality elementwise.\n",
      " |      DataFrame.ge : Compare DataFrames for greater than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.gt : Compare DataFrames for strictly greater than\n",
      " |          inequality elementwise.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      `NaN` values are considered different (i.e. `NaN` != `NaN`).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'cost': [250, 150, 100],\n",
      " |      ...                    'revenue': [100, 250, 300]},\n",
      " |      ...                   index=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |         cost  revenue\n",
      " |      A   250      100\n",
      " |      B   150      250\n",
      " |      C   100      300\n",
      " |      \n",
      " |      Comparison with a scalar, using either the operator or method:\n",
      " |      \n",
      " |      >>> df == 100\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      >>> df.eq(100)\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      When `other` is a :class:`Series`, the columns of a DataFrame are aligned\n",
      " |      with the index of `other` and broadcast:\n",
      " |      \n",
      " |      >>> df != pd.Series([100, 250], index=[\"cost\", \"revenue\"])\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B   True    False\n",
      " |      C  False     True\n",
      " |      \n",
      " |      Use the method to control the broadcast axis:\n",
      " |      \n",
      " |      >>> df.ne(pd.Series([100, 300], index=[\"A\", \"D\"]), axis='index')\n",
      " |         cost  revenue\n",
      " |      A  True    False\n",
      " |      B  True     True\n",
      " |      C  True     True\n",
      " |      D  True     True\n",
      " |      \n",
      " |      When comparing to an arbitrary sequence, the number of columns must\n",
      " |      match the number elements in `other`:\n",
      " |      \n",
      " |      >>> df == [250, 100]\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B  False    False\n",
      " |      C  False    False\n",
      " |      \n",
      " |      Use the method to control the axis:\n",
      " |      \n",
      " |      >>> df.eq([250, 250, 100], axis='index')\n",
      " |          cost  revenue\n",
      " |      A   True    False\n",
      " |      B  False     True\n",
      " |      C   True    False\n",
      " |      \n",
      " |      Compare to a DataFrame of different shape.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'revenue': [300, 250, 100, 150]},\n",
      " |      ...                      index=['A', 'B', 'C', 'D'])\n",
      " |      >>> other\n",
      " |         revenue\n",
      " |      A      300\n",
      " |      B      250\n",
      " |      C      100\n",
      " |      D      150\n",
      " |      \n",
      " |      >>> df.gt(other)\n",
      " |          cost  revenue\n",
      " |      A  False    False\n",
      " |      B  False    False\n",
      " |      C  False     True\n",
      " |      D  False    False\n",
      " |      \n",
      " |      Compare to a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],\n",
      " |      ...                              'revenue': [100, 250, 300, 200, 175, 225]},\n",
      " |      ...                             index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],\n",
      " |      ...                                    ['A', 'B', 'C', 'A', 'B', 'C']])\n",
      " |      >>> df_multindex\n",
      " |            cost  revenue\n",
      " |      Q1 A   250      100\n",
      " |         B   150      250\n",
      " |         C   100      300\n",
      " |      Q2 A   150      200\n",
      " |         B   300      175\n",
      " |         C   220      225\n",
      " |      \n",
      " |      >>> df.le(df_multindex, level=1)\n",
      " |             cost  revenue\n",
      " |      Q1 A   True     True\n",
      " |         B   True     True\n",
      " |         C   True     True\n",
      " |      Q2 A  False     True\n",
      " |         B   True    False\n",
      " |         C   True    False\n",
      " |  \n",
      " |  groupby(self, by=None, axis: 'Axis' = 0, level: 'Level | None' = None, as_index: 'bool' = True, sort: 'bool' = True, group_keys: 'bool' = True, squeeze: 'bool | lib.NoDefault' = <no_default>, observed: 'bool' = False, dropna: 'bool' = True) -> 'DataFrameGroupBy'\n",
      " |      Group DataFrame using a mapper or by a Series of columns.\n",
      " |      \n",
      " |      A groupby operation involves some combination of splitting the\n",
      " |      object, applying a function, and combining the results. This can be\n",
      " |      used to group large amounts of data and compute operations on these\n",
      " |      groups.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      by : mapping, function, label, or list of labels\n",
      " |          Used to determine the groups for the groupby.\n",
      " |          If ``by`` is a function, it's called on each value of the object's\n",
      " |          index. If a dict or Series is passed, the Series or dict VALUES\n",
      " |          will be used to determine the groups (the Series' values are first\n",
      " |          aligned; see ``.align()`` method). If a list or ndarray of length\n",
      " |          equal to the selected axis is passed (see the `groupby user guide\n",
      " |          <https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html#splitting-an-object-into-groups>`_),\n",
      " |          the values are used as-is to determine the groups. A label or list\n",
      " |          of labels may be passed to group by the columns in ``self``.\n",
      " |          Notice that a tuple is interpreted as a (single) key.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Split along rows (0) or columns (1).\n",
      " |      level : int, level name, or sequence of such, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), group by a particular\n",
      " |          level or levels.\n",
      " |      as_index : bool, default True\n",
      " |          For aggregated output, return object with group labels as the\n",
      " |          index. Only relevant for DataFrame input. as_index=False is\n",
      " |          effectively \"SQL-style\" grouped output.\n",
      " |      sort : bool, default True\n",
      " |          Sort group keys. Get better performance by turning this off.\n",
      " |          Note this does not influence the order of observations within each\n",
      " |          group. Groupby preserves the order of rows within each group.\n",
      " |      group_keys : bool, default True\n",
      " |          When calling apply, add group keys to index to identify pieces.\n",
      " |      squeeze : bool, default False\n",
      " |          Reduce the dimensionality of the return type if possible,\n",
      " |          otherwise return a consistent type.\n",
      " |      \n",
      " |          .. deprecated:: 1.1.0\n",
      " |      \n",
      " |      observed : bool, default False\n",
      " |          This only applies if any of the groupers are Categoricals.\n",
      " |          If True: only show observed values for categorical groupers.\n",
      " |          If False: show all values for categorical groupers.\n",
      " |      dropna : bool, default True\n",
      " |          If True, and if group keys contain NA values, NA values together\n",
      " |          with row/column will be dropped.\n",
      " |          If False, NA values will also be treated as the key in groups.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrameGroupBy\n",
      " |          Returns a groupby object that contains information about the groups.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      resample : Convenience method for frequency conversion and resampling\n",
      " |          of time series.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See the `user guide\n",
      " |      <https://pandas.pydata.org/pandas-docs/stable/groupby.html>`__ for more\n",
      " |      detailed usage and examples, including splitting an object into groups,\n",
      " |      iterating through groups, selecting a group, aggregation, and more.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'Animal': ['Falcon', 'Falcon',\n",
      " |      ...                               'Parrot', 'Parrot'],\n",
      " |      ...                    'Max Speed': [380., 370., 24., 26.]})\n",
      " |      >>> df\n",
      " |         Animal  Max Speed\n",
      " |      0  Falcon      380.0\n",
      " |      1  Falcon      370.0\n",
      " |      2  Parrot       24.0\n",
      " |      3  Parrot       26.0\n",
      " |      >>> df.groupby(['Animal']).mean()\n",
      " |              Max Speed\n",
      " |      Animal\n",
      " |      Falcon      375.0\n",
      " |      Parrot       25.0\n",
      " |      \n",
      " |      **Hierarchical Indexes**\n",
      " |      \n",
      " |      We can groupby different levels of a hierarchical index\n",
      " |      using the `level` parameter:\n",
      " |      \n",
      " |      >>> arrays = [['Falcon', 'Falcon', 'Parrot', 'Parrot'],\n",
      " |      ...           ['Captive', 'Wild', 'Captive', 'Wild']]\n",
      " |      >>> index = pd.MultiIndex.from_arrays(arrays, names=('Animal', 'Type'))\n",
      " |      >>> df = pd.DataFrame({'Max Speed': [390., 350., 30., 20.]},\n",
      " |      ...                   index=index)\n",
      " |      >>> df\n",
      " |                      Max Speed\n",
      " |      Animal Type\n",
      " |      Falcon Captive      390.0\n",
      " |             Wild         350.0\n",
      " |      Parrot Captive       30.0\n",
      " |             Wild          20.0\n",
      " |      >>> df.groupby(level=0).mean()\n",
      " |              Max Speed\n",
      " |      Animal\n",
      " |      Falcon      370.0\n",
      " |      Parrot       25.0\n",
      " |      >>> df.groupby(level=\"Type\").mean()\n",
      " |               Max Speed\n",
      " |      Type\n",
      " |      Captive      210.0\n",
      " |      Wild         185.0\n",
      " |      \n",
      " |      We can also choose to include NA in group keys or not by setting\n",
      " |      `dropna` parameter, the default setting is `True`.\n",
      " |      \n",
      " |      >>> l = [[1, 2, 3], [1, None, 4], [2, 1, 3], [1, 2, 2]]\n",
      " |      >>> df = pd.DataFrame(l, columns=[\"a\", \"b\", \"c\"])\n",
      " |      \n",
      " |      >>> df.groupby(by=[\"b\"]).sum()\n",
      " |          a   c\n",
      " |      b\n",
      " |      1.0 2   3\n",
      " |      2.0 2   5\n",
      " |      \n",
      " |      >>> df.groupby(by=[\"b\"], dropna=False).sum()\n",
      " |          a   c\n",
      " |      b\n",
      " |      1.0 2   3\n",
      " |      2.0 2   5\n",
      " |      NaN 1   4\n",
      " |      \n",
      " |      >>> l = [[\"a\", 12, 12], [None, 12.3, 33.], [\"b\", 12.3, 123], [\"a\", 1, 1]]\n",
      " |      >>> df = pd.DataFrame(l, columns=[\"a\", \"b\", \"c\"])\n",
      " |      \n",
      " |      >>> df.groupby(by=\"a\").sum()\n",
      " |          b     c\n",
      " |      a\n",
      " |      a   13.0   13.0\n",
      " |      b   12.3  123.0\n",
      " |      \n",
      " |      >>> df.groupby(by=\"a\", dropna=False).sum()\n",
      " |          b     c\n",
      " |      a\n",
      " |      a   13.0   13.0\n",
      " |      b   12.3  123.0\n",
      " |      NaN 12.3   33.0\n",
      " |  \n",
      " |  gt(self, other, axis='columns', level=None)\n",
      " |      Get Greater than of dataframe and other, element-wise (binary operator `gt`).\n",
      " |      \n",
      " |      Among flexible wrappers (`eq`, `ne`, `le`, `lt`, `ge`, `gt`) to comparison\n",
      " |      operators.\n",
      " |      \n",
      " |      Equivalent to `==`, `!=`, `<=`, `<`, `>=`, `>` with support to choose axis\n",
      " |      (rows or columns) and level for comparison.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 'columns'\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns').\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the passed\n",
      " |          MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame of bool\n",
      " |          Result of the comparison.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.eq : Compare DataFrames for equality elementwise.\n",
      " |      DataFrame.ne : Compare DataFrames for inequality elementwise.\n",
      " |      DataFrame.le : Compare DataFrames for less than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.lt : Compare DataFrames for strictly less than\n",
      " |          inequality elementwise.\n",
      " |      DataFrame.ge : Compare DataFrames for greater than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.gt : Compare DataFrames for strictly greater than\n",
      " |          inequality elementwise.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      `NaN` values are considered different (i.e. `NaN` != `NaN`).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'cost': [250, 150, 100],\n",
      " |      ...                    'revenue': [100, 250, 300]},\n",
      " |      ...                   index=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |         cost  revenue\n",
      " |      A   250      100\n",
      " |      B   150      250\n",
      " |      C   100      300\n",
      " |      \n",
      " |      Comparison with a scalar, using either the operator or method:\n",
      " |      \n",
      " |      >>> df == 100\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      >>> df.eq(100)\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      When `other` is a :class:`Series`, the columns of a DataFrame are aligned\n",
      " |      with the index of `other` and broadcast:\n",
      " |      \n",
      " |      >>> df != pd.Series([100, 250], index=[\"cost\", \"revenue\"])\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B   True    False\n",
      " |      C  False     True\n",
      " |      \n",
      " |      Use the method to control the broadcast axis:\n",
      " |      \n",
      " |      >>> df.ne(pd.Series([100, 300], index=[\"A\", \"D\"]), axis='index')\n",
      " |         cost  revenue\n",
      " |      A  True    False\n",
      " |      B  True     True\n",
      " |      C  True     True\n",
      " |      D  True     True\n",
      " |      \n",
      " |      When comparing to an arbitrary sequence, the number of columns must\n",
      " |      match the number elements in `other`:\n",
      " |      \n",
      " |      >>> df == [250, 100]\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B  False    False\n",
      " |      C  False    False\n",
      " |      \n",
      " |      Use the method to control the axis:\n",
      " |      \n",
      " |      >>> df.eq([250, 250, 100], axis='index')\n",
      " |          cost  revenue\n",
      " |      A   True    False\n",
      " |      B  False     True\n",
      " |      C   True    False\n",
      " |      \n",
      " |      Compare to a DataFrame of different shape.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'revenue': [300, 250, 100, 150]},\n",
      " |      ...                      index=['A', 'B', 'C', 'D'])\n",
      " |      >>> other\n",
      " |         revenue\n",
      " |      A      300\n",
      " |      B      250\n",
      " |      C      100\n",
      " |      D      150\n",
      " |      \n",
      " |      >>> df.gt(other)\n",
      " |          cost  revenue\n",
      " |      A  False    False\n",
      " |      B  False    False\n",
      " |      C  False     True\n",
      " |      D  False    False\n",
      " |      \n",
      " |      Compare to a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],\n",
      " |      ...                              'revenue': [100, 250, 300, 200, 175, 225]},\n",
      " |      ...                             index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],\n",
      " |      ...                                    ['A', 'B', 'C', 'A', 'B', 'C']])\n",
      " |      >>> df_multindex\n",
      " |            cost  revenue\n",
      " |      Q1 A   250      100\n",
      " |         B   150      250\n",
      " |         C   100      300\n",
      " |      Q2 A   150      200\n",
      " |         B   300      175\n",
      " |         C   220      225\n",
      " |      \n",
      " |      >>> df.le(df_multindex, level=1)\n",
      " |             cost  revenue\n",
      " |      Q1 A   True     True\n",
      " |         B   True     True\n",
      " |         C   True     True\n",
      " |      Q2 A  False     True\n",
      " |         B   True    False\n",
      " |         C   True    False\n",
      " |  \n",
      " |  hist = hist_frame(data: 'DataFrame', column: 'IndexLabel' = None, by=None, grid: 'bool' = True, xlabelsize: 'int | None' = None, xrot: 'float | None' = None, ylabelsize: 'int | None' = None, yrot: 'float | None' = None, ax=None, sharex: 'bool' = False, sharey: 'bool' = False, figsize: 'tuple[int, int] | None' = None, layout: 'tuple[int, int] | None' = None, bins: 'int | Sequence[int]' = 10, backend: 'str | None' = None, legend: 'bool' = False, **kwargs)\n",
      " |      Make a histogram of the DataFrame's columns.\n",
      " |      \n",
      " |      A `histogram`_ is a representation of the distribution of data.\n",
      " |      This function calls :meth:`matplotlib.pyplot.hist`, on each series in\n",
      " |      the DataFrame, resulting in one histogram per column.\n",
      " |      \n",
      " |      .. _histogram: https://en.wikipedia.org/wiki/Histogram\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : DataFrame\n",
      " |          The pandas object holding the data.\n",
      " |      column : str or sequence, optional\n",
      " |          If passed, will be used to limit data to a subset of columns.\n",
      " |      by : object, optional\n",
      " |          If passed, then used to form histograms for separate groups.\n",
      " |      grid : bool, default True\n",
      " |          Whether to show axis grid lines.\n",
      " |      xlabelsize : int, default None\n",
      " |          If specified changes the x-axis label size.\n",
      " |      xrot : float, default None\n",
      " |          Rotation of x axis labels. For example, a value of 90 displays the\n",
      " |          x labels rotated 90 degrees clockwise.\n",
      " |      ylabelsize : int, default None\n",
      " |          If specified changes the y-axis label size.\n",
      " |      yrot : float, default None\n",
      " |          Rotation of y axis labels. For example, a value of 90 displays the\n",
      " |          y labels rotated 90 degrees clockwise.\n",
      " |      ax : Matplotlib axes object, default None\n",
      " |          The axes to plot the histogram on.\n",
      " |      sharex : bool, default True if ax is None else False\n",
      " |          In case subplots=True, share x axis and set some x axis labels to\n",
      " |          invisible; defaults to True if ax is None otherwise False if an ax\n",
      " |          is passed in.\n",
      " |          Note that passing in both an ax and sharex=True will alter all x axis\n",
      " |          labels for all subplots in a figure.\n",
      " |      sharey : bool, default False\n",
      " |          In case subplots=True, share y axis and set some y axis labels to\n",
      " |          invisible.\n",
      " |      figsize : tuple, optional\n",
      " |          The size in inches of the figure to create. Uses the value in\n",
      " |          `matplotlib.rcParams` by default.\n",
      " |      layout : tuple, optional\n",
      " |          Tuple of (rows, columns) for the layout of the histograms.\n",
      " |      bins : int or sequence, default 10\n",
      " |          Number of histogram bins to be used. If an integer is given, bins + 1\n",
      " |          bin edges are calculated and returned. If bins is a sequence, gives\n",
      " |          bin edges, including left edge of first bin and right edge of last\n",
      " |          bin. In this case, bins is returned unmodified.\n",
      " |      \n",
      " |      backend : str, default None\n",
      " |          Backend to use instead of the backend specified in the option\n",
      " |          ``plotting.backend``. For instance, 'matplotlib'. Alternatively, to\n",
      " |          specify the ``plotting.backend`` for the whole session, set\n",
      " |          ``pd.options.plotting.backend``.\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      legend : bool, default False\n",
      " |          Whether to show the legend.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      **kwargs\n",
      " |          All other plotting keyword arguments to be passed to\n",
      " |          :meth:`matplotlib.pyplot.hist`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      matplotlib.AxesSubplot or numpy.ndarray of them\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      matplotlib.pyplot.hist : Plot a histogram using matplotlib.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      This example draws a histogram based on the length and width of\n",
      " |      some animals, displayed in three bins\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> df = pd.DataFrame({\n",
      " |          ...     'length': [1.5, 0.5, 1.2, 0.9, 3],\n",
      " |          ...     'width': [0.7, 0.2, 0.15, 0.2, 1.1]\n",
      " |          ...     }, index=['pig', 'rabbit', 'duck', 'chicken', 'horse'])\n",
      " |          >>> hist = df.hist(bins=3)\n",
      " |  \n",
      " |  idxmax(self, axis: 'Axis' = 0, skipna: 'bool' = True) -> 'Series'\n",
      " |      Return index of first occurrence of maximum over requested axis.\n",
      " |      \n",
      " |      NA/null values are excluded.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to use. 0 or 'index' for row-wise, 1 or 'columns' for column-wise.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Indexes of maxima along the specified axis.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          * If the row/column is empty\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.idxmax : Return index of the maximum element.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the DataFrame version of ``ndarray.argmax``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Consider a dataset containing food consumption in Argentina.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'consumption': [10.51, 103.11, 55.48],\n",
      " |      ...                    'co2_emissions': [37.2, 19.66, 1712]},\n",
      " |      ...                    index=['Pork', 'Wheat Products', 'Beef'])\n",
      " |      \n",
      " |      >>> df\n",
      " |                      consumption  co2_emissions\n",
      " |      Pork                  10.51         37.20\n",
      " |      Wheat Products       103.11         19.66\n",
      " |      Beef                  55.48       1712.00\n",
      " |      \n",
      " |      By default, it returns the index for the maximum value in each column.\n",
      " |      \n",
      " |      >>> df.idxmax()\n",
      " |      consumption     Wheat Products\n",
      " |      co2_emissions             Beef\n",
      " |      dtype: object\n",
      " |      \n",
      " |      To return the index for the maximum value in each row, use ``axis=\"columns\"``.\n",
      " |      \n",
      " |      >>> df.idxmax(axis=\"columns\")\n",
      " |      Pork              co2_emissions\n",
      " |      Wheat Products     consumption\n",
      " |      Beef              co2_emissions\n",
      " |      dtype: object\n",
      " |  \n",
      " |  idxmin(self, axis: 'Axis' = 0, skipna: 'bool' = True) -> 'Series'\n",
      " |      Return index of first occurrence of minimum over requested axis.\n",
      " |      \n",
      " |      NA/null values are excluded.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to use. 0 or 'index' for row-wise, 1 or 'columns' for column-wise.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Indexes of minima along the specified axis.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          * If the row/column is empty\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.idxmin : Return index of the minimum element.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the DataFrame version of ``ndarray.argmin``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Consider a dataset containing food consumption in Argentina.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'consumption': [10.51, 103.11, 55.48],\n",
      " |      ...                    'co2_emissions': [37.2, 19.66, 1712]},\n",
      " |      ...                    index=['Pork', 'Wheat Products', 'Beef'])\n",
      " |      \n",
      " |      >>> df\n",
      " |                      consumption  co2_emissions\n",
      " |      Pork                  10.51         37.20\n",
      " |      Wheat Products       103.11         19.66\n",
      " |      Beef                  55.48       1712.00\n",
      " |      \n",
      " |      By default, it returns the index for the minimum value in each column.\n",
      " |      \n",
      " |      >>> df.idxmin()\n",
      " |      consumption                Pork\n",
      " |      co2_emissions    Wheat Products\n",
      " |      dtype: object\n",
      " |      \n",
      " |      To return the index for the minimum value in each row, use ``axis=\"columns\"``.\n",
      " |      \n",
      " |      >>> df.idxmin(axis=\"columns\")\n",
      " |      Pork                consumption\n",
      " |      Wheat Products    co2_emissions\n",
      " |      Beef                consumption\n",
      " |      dtype: object\n",
      " |  \n",
      " |  info(self, verbose: 'bool | None' = None, buf: 'WriteBuffer[str] | None' = None, max_cols: 'int | None' = None, memory_usage: 'bool | str | None' = None, show_counts: 'bool | None' = None, null_counts: 'bool | None' = None) -> 'None'\n",
      " |      Print a concise summary of a DataFrame.\n",
      " |      \n",
      " |      This method prints information about a DataFrame including\n",
      " |      the index dtype and columns, non-null values and memory usage.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : DataFrame\n",
      " |          DataFrame to print information about.\n",
      " |      verbose : bool, optional\n",
      " |          Whether to print the full summary. By default, the setting in\n",
      " |          ``pandas.options.display.max_info_columns`` is followed.\n",
      " |      buf : writable buffer, defaults to sys.stdout\n",
      " |          Where to send the output. By default, the output is printed to\n",
      " |          sys.stdout. Pass a writable buffer if you need to further process\n",
      " |          the output.    max_cols : int, optional\n",
      " |          When to switch from the verbose to the truncated output. If the\n",
      " |          DataFrame has more than `max_cols` columns, the truncated output\n",
      " |          is used. By default, the setting in\n",
      " |          ``pandas.options.display.max_info_columns`` is used.\n",
      " |      memory_usage : bool, str, optional\n",
      " |          Specifies whether total memory usage of the DataFrame\n",
      " |          elements (including the index) should be displayed. By default,\n",
      " |          this follows the ``pandas.options.display.memory_usage`` setting.\n",
      " |      \n",
      " |          True always show memory usage. False never shows memory usage.\n",
      " |          A value of 'deep' is equivalent to \"True with deep introspection\".\n",
      " |          Memory usage is shown in human-readable units (base-2\n",
      " |          representation). Without deep introspection a memory estimation is\n",
      " |          made based in column dtype and number of rows assuming values\n",
      " |          consume the same memory amount for corresponding dtypes. With deep\n",
      " |          memory introspection, a real memory usage calculation is performed\n",
      " |          at the cost of computational resources.\n",
      " |      show_counts : bool, optional\n",
      " |          Whether to show the non-null counts. By default, this is shown\n",
      " |          only if the DataFrame is smaller than\n",
      " |          ``pandas.options.display.max_info_rows`` and\n",
      " |          ``pandas.options.display.max_info_columns``. A value of True always\n",
      " |          shows the counts, and False never shows the counts.\n",
      " |      null_counts : bool, optional\n",
      " |          .. deprecated:: 1.2.0\n",
      " |              Use show_counts instead.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      None\n",
      " |          This method prints a summary of a DataFrame and returns None.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.describe: Generate descriptive statistics of DataFrame\n",
      " |          columns.\n",
      " |      DataFrame.memory_usage: Memory usage of DataFrame columns.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> int_values = [1, 2, 3, 4, 5]\n",
      " |      >>> text_values = ['alpha', 'beta', 'gamma', 'delta', 'epsilon']\n",
      " |      >>> float_values = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
      " |      >>> df = pd.DataFrame({\"int_col\": int_values, \"text_col\": text_values,\n",
      " |      ...                   \"float_col\": float_values})\n",
      " |      >>> df\n",
      " |          int_col text_col  float_col\n",
      " |      0        1    alpha       0.00\n",
      " |      1        2     beta       0.25\n",
      " |      2        3    gamma       0.50\n",
      " |      3        4    delta       0.75\n",
      " |      4        5  epsilon       1.00\n",
      " |      \n",
      " |      Prints information of all columns:\n",
      " |      \n",
      " |      >>> df.info(verbose=True)\n",
      " |      <class 'pandas.core.frame.DataFrame'>\n",
      " |      RangeIndex: 5 entries, 0 to 4\n",
      " |      Data columns (total 3 columns):\n",
      " |       #   Column     Non-Null Count  Dtype\n",
      " |      ---  ------     --------------  -----\n",
      " |       0   int_col    5 non-null      int64\n",
      " |       1   text_col   5 non-null      object\n",
      " |       2   float_col  5 non-null      float64\n",
      " |      dtypes: float64(1), int64(1), object(1)\n",
      " |      memory usage: 248.0+ bytes\n",
      " |      \n",
      " |      Prints a summary of columns count and its dtypes but not per column\n",
      " |      information:\n",
      " |      \n",
      " |      >>> df.info(verbose=False)\n",
      " |      <class 'pandas.core.frame.DataFrame'>\n",
      " |      RangeIndex: 5 entries, 0 to 4\n",
      " |      Columns: 3 entries, int_col to float_col\n",
      " |      dtypes: float64(1), int64(1), object(1)\n",
      " |      memory usage: 248.0+ bytes\n",
      " |      \n",
      " |      Pipe output of DataFrame.info to buffer instead of sys.stdout, get\n",
      " |      buffer content and writes to a text file:\n",
      " |      \n",
      " |      >>> import io\n",
      " |      >>> buffer = io.StringIO()\n",
      " |      >>> df.info(buf=buffer)\n",
      " |      >>> s = buffer.getvalue()\n",
      " |      >>> with open(\"df_info.txt\", \"w\",\n",
      " |      ...           encoding=\"utf-8\") as f:  # doctest: +SKIP\n",
      " |      ...     f.write(s)\n",
      " |      260\n",
      " |      \n",
      " |      The `memory_usage` parameter allows deep introspection mode, specially\n",
      " |      useful for big DataFrames and fine-tune memory optimization:\n",
      " |      \n",
      " |      >>> random_strings_array = np.random.choice(['a', 'b', 'c'], 10 ** 6)\n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'column_1': np.random.choice(['a', 'b', 'c'], 10 ** 6),\n",
      " |      ...     'column_2': np.random.choice(['a', 'b', 'c'], 10 ** 6),\n",
      " |      ...     'column_3': np.random.choice(['a', 'b', 'c'], 10 ** 6)\n",
      " |      ... })\n",
      " |      >>> df.info()\n",
      " |      <class 'pandas.core.frame.DataFrame'>\n",
      " |      RangeIndex: 1000000 entries, 0 to 999999\n",
      " |      Data columns (total 3 columns):\n",
      " |       #   Column    Non-Null Count    Dtype\n",
      " |      ---  ------    --------------    -----\n",
      " |       0   column_1  1000000 non-null  object\n",
      " |       1   column_2  1000000 non-null  object\n",
      " |       2   column_3  1000000 non-null  object\n",
      " |      dtypes: object(3)\n",
      " |      memory usage: 22.9+ MB\n",
      " |      \n",
      " |      >>> df.info(memory_usage='deep')\n",
      " |      <class 'pandas.core.frame.DataFrame'>\n",
      " |      RangeIndex: 1000000 entries, 0 to 999999\n",
      " |      Data columns (total 3 columns):\n",
      " |       #   Column    Non-Null Count    Dtype\n",
      " |      ---  ------    --------------    -----\n",
      " |       0   column_1  1000000 non-null  object\n",
      " |       1   column_2  1000000 non-null  object\n",
      " |       2   column_3  1000000 non-null  object\n",
      " |      dtypes: object(3)\n",
      " |      memory usage: 165.9 MB\n",
      " |  \n",
      " |  insert(self, loc: 'int', column: 'Hashable', value: 'Scalar | AnyArrayLike', allow_duplicates: 'bool' = False) -> 'None'\n",
      " |      Insert column into DataFrame at specified location.\n",
      " |      \n",
      " |      Raises a ValueError if `column` is already contained in the DataFrame,\n",
      " |      unless `allow_duplicates` is set to True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      loc : int\n",
      " |          Insertion index. Must verify 0 <= loc <= len(columns).\n",
      " |      column : str, number, or hashable object\n",
      " |          Label of the inserted column.\n",
      " |      value : Scalar, Series, or array-like\n",
      " |      allow_duplicates : bool, optional default False\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.insert : Insert new item by index.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n",
      " |      >>> df\n",
      " |         col1  col2\n",
      " |      0     1     3\n",
      " |      1     2     4\n",
      " |      >>> df.insert(1, \"newcol\", [99, 99])\n",
      " |      >>> df\n",
      " |         col1  newcol  col2\n",
      " |      0     1      99     3\n",
      " |      1     2      99     4\n",
      " |      >>> df.insert(0, \"col1\", [100, 100], allow_duplicates=True)\n",
      " |      >>> df\n",
      " |         col1  col1  newcol  col2\n",
      " |      0   100     1      99     3\n",
      " |      1   100     2      99     4\n",
      " |      \n",
      " |      Notice that pandas uses index alignment in case of `value` from type `Series`:\n",
      " |      \n",
      " |      >>> df.insert(0, \"col0\", pd.Series([5, 6], index=[1, 2]))\n",
      " |      >>> df\n",
      " |         col0  col1  col1  newcol  col2\n",
      " |      0   NaN   100     1      99     3\n",
      " |      1   5.0   100     2      99     4\n",
      " |  \n",
      " |  interpolate(self: 'DataFrame', method: 'str' = 'linear', axis: 'Axis' = 0, limit: 'int | None' = None, inplace: 'bool' = False, limit_direction: 'str | None' = None, limit_area: 'str | None' = None, downcast: 'str | None' = None, **kwargs) -> 'DataFrame | None'\n",
      " |      Fill NaN values using an interpolation method.\n",
      " |      \n",
      " |      Please note that only ``method='linear'`` is supported for\n",
      " |      DataFrame/Series with a MultiIndex.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : str, default 'linear'\n",
      " |          Interpolation technique to use. One of:\n",
      " |      \n",
      " |          * 'linear': Ignore the index and treat the values as equally\n",
      " |            spaced. This is the only method supported on MultiIndexes.\n",
      " |          * 'time': Works on daily and higher resolution data to interpolate\n",
      " |            given length of interval.\n",
      " |          * 'index', 'values': use the actual numerical values of the index.\n",
      " |          * 'pad': Fill in NaNs using existing values.\n",
      " |          * 'nearest', 'zero', 'slinear', 'quadratic', 'cubic', 'spline',\n",
      " |            'barycentric', 'polynomial': Passed to\n",
      " |            `scipy.interpolate.interp1d`. These methods use the numerical\n",
      " |            values of the index.  Both 'polynomial' and 'spline' require that\n",
      " |            you also specify an `order` (int), e.g.\n",
      " |            ``df.interpolate(method='polynomial', order=5)``.\n",
      " |          * 'krogh', 'piecewise_polynomial', 'spline', 'pchip', 'akima',\n",
      " |            'cubicspline': Wrappers around the SciPy interpolation methods of\n",
      " |            similar names. See `Notes`.\n",
      " |          * 'from_derivatives': Refers to\n",
      " |            `scipy.interpolate.BPoly.from_derivatives` which\n",
      " |            replaces 'piecewise_polynomial' interpolation method in\n",
      " |            scipy 0.18.\n",
      " |      \n",
      " |      axis : {{0 or 'index', 1 or 'columns', None}}, default None\n",
      " |          Axis to interpolate along.\n",
      " |      limit : int, optional\n",
      " |          Maximum number of consecutive NaNs to fill. Must be greater than\n",
      " |          0.\n",
      " |      inplace : bool, default False\n",
      " |          Update the data in place if possible.\n",
      " |      limit_direction : {{'forward', 'backward', 'both'}}, Optional\n",
      " |          Consecutive NaNs will be filled in this direction.\n",
      " |      \n",
      " |          If limit is specified:\n",
      " |              * If 'method' is 'pad' or 'ffill', 'limit_direction' must be 'forward'.\n",
      " |              * If 'method' is 'backfill' or 'bfill', 'limit_direction' must be\n",
      " |                'backwards'.\n",
      " |      \n",
      " |          If 'limit' is not specified:\n",
      " |              * If 'method' is 'backfill' or 'bfill', the default is 'backward'\n",
      " |              * else the default is 'forward'\n",
      " |      \n",
      " |          .. versionchanged:: 1.1.0\n",
      " |              raises ValueError if `limit_direction` is 'forward' or 'both' and\n",
      " |                  method is 'backfill' or 'bfill'.\n",
      " |              raises ValueError if `limit_direction` is 'backward' or 'both' and\n",
      " |                  method is 'pad' or 'ffill'.\n",
      " |      \n",
      " |      limit_area : {{`None`, 'inside', 'outside'}}, default None\n",
      " |          If limit is specified, consecutive NaNs will be filled with this\n",
      " |          restriction.\n",
      " |      \n",
      " |          * ``None``: No fill restriction.\n",
      " |          * 'inside': Only fill NaNs surrounded by valid values\n",
      " |            (interpolate).\n",
      " |          * 'outside': Only fill NaNs outside valid values (extrapolate).\n",
      " |      \n",
      " |      downcast : optional, 'infer' or None, defaults to None\n",
      " |          Downcast dtypes if possible.\n",
      " |      ``**kwargs`` : optional\n",
      " |          Keyword arguments to pass on to the interpolating function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame or None\n",
      " |          Returns the same object type as the caller, interpolated at\n",
      " |          some or all ``NaN`` values or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      fillna : Fill missing values using different methods.\n",
      " |      scipy.interpolate.Akima1DInterpolator : Piecewise cubic polynomials\n",
      " |          (Akima interpolator).\n",
      " |      scipy.interpolate.BPoly.from_derivatives : Piecewise polynomial in the\n",
      " |          Bernstein basis.\n",
      " |      scipy.interpolate.interp1d : Interpolate a 1-D function.\n",
      " |      scipy.interpolate.KroghInterpolator : Interpolate polynomial (Krogh\n",
      " |          interpolator).\n",
      " |      scipy.interpolate.PchipInterpolator : PCHIP 1-d monotonic cubic\n",
      " |          interpolation.\n",
      " |      scipy.interpolate.CubicSpline : Cubic spline data interpolator.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The 'krogh', 'piecewise_polynomial', 'spline', 'pchip' and 'akima'\n",
      " |      methods are wrappers around the respective SciPy implementations of\n",
      " |      similar names. These use the actual numerical values of the index.\n",
      " |      For more information on their behavior, see the\n",
      " |      `SciPy documentation\n",
      " |      <https://docs.scipy.org/doc/scipy/reference/interpolate.html#univariate-interpolation>`__\n",
      " |      and `SciPy tutorial\n",
      " |      <https://docs.scipy.org/doc/scipy/reference/tutorial/interpolate.html>`__.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Filling in ``NaN`` in a :class:`~pandas.Series` via linear\n",
      " |      interpolation.\n",
      " |      \n",
      " |      >>> s = pd.Series([0, 1, np.nan, 3])\n",
      " |      >>> s\n",
      " |      0    0.0\n",
      " |      1    1.0\n",
      " |      2    NaN\n",
      " |      3    3.0\n",
      " |      dtype: float64\n",
      " |      >>> s.interpolate()\n",
      " |      0    0.0\n",
      " |      1    1.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Filling in ``NaN`` in a Series by padding, but filling at most two\n",
      " |      consecutive ``NaN`` at a time.\n",
      " |      \n",
      " |      >>> s = pd.Series([np.nan, \"single_one\", np.nan,\n",
      " |      ...                \"fill_two_more\", np.nan, np.nan, np.nan,\n",
      " |      ...                4.71, np.nan])\n",
      " |      >>> s\n",
      " |      0              NaN\n",
      " |      1       single_one\n",
      " |      2              NaN\n",
      " |      3    fill_two_more\n",
      " |      4              NaN\n",
      " |      5              NaN\n",
      " |      6              NaN\n",
      " |      7             4.71\n",
      " |      8              NaN\n",
      " |      dtype: object\n",
      " |      >>> s.interpolate(method='pad', limit=2)\n",
      " |      0              NaN\n",
      " |      1       single_one\n",
      " |      2       single_one\n",
      " |      3    fill_two_more\n",
      " |      4    fill_two_more\n",
      " |      5    fill_two_more\n",
      " |      6              NaN\n",
      " |      7             4.71\n",
      " |      8             4.71\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Filling in ``NaN`` in a Series via polynomial interpolation or splines:\n",
      " |      Both 'polynomial' and 'spline' methods require that you also specify\n",
      " |      an ``order`` (int).\n",
      " |      \n",
      " |      >>> s = pd.Series([0, 2, np.nan, 8])\n",
      " |      >>> s.interpolate(method='polynomial', order=2)\n",
      " |      0    0.000000\n",
      " |      1    2.000000\n",
      " |      2    4.666667\n",
      " |      3    8.000000\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Fill the DataFrame forward (that is, going down) along each column\n",
      " |      using linear interpolation.\n",
      " |      \n",
      " |      Note how the last entry in column 'a' is interpolated differently,\n",
      " |      because there is no entry after it to use for interpolation.\n",
      " |      Note how the first entry in column 'b' remains ``NaN``, because there\n",
      " |      is no entry before it to use for interpolation.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([(0.0, np.nan, -1.0, 1.0),\n",
      " |      ...                    (np.nan, 2.0, np.nan, np.nan),\n",
      " |      ...                    (2.0, 3.0, np.nan, 9.0),\n",
      " |      ...                    (np.nan, 4.0, -4.0, 16.0)],\n",
      " |      ...                   columns=list('abcd'))\n",
      " |      >>> df\n",
      " |           a    b    c     d\n",
      " |      0  0.0  NaN -1.0   1.0\n",
      " |      1  NaN  2.0  NaN   NaN\n",
      " |      2  2.0  3.0  NaN   9.0\n",
      " |      3  NaN  4.0 -4.0  16.0\n",
      " |      >>> df.interpolate(method='linear', limit_direction='forward', axis=0)\n",
      " |           a    b    c     d\n",
      " |      0  0.0  NaN -1.0   1.0\n",
      " |      1  1.0  2.0 -2.0   5.0\n",
      " |      2  2.0  3.0 -3.0   9.0\n",
      " |      3  2.0  4.0 -4.0  16.0\n",
      " |      \n",
      " |      Using polynomial interpolation.\n",
      " |      \n",
      " |      >>> df['d'].interpolate(method='polynomial', order=2)\n",
      " |      0     1.0\n",
      " |      1     4.0\n",
      " |      2     9.0\n",
      " |      3    16.0\n",
      " |      Name: d, dtype: float64\n",
      " |  \n",
      " |  isin(self, values) -> 'DataFrame'\n",
      " |      Whether each element in the DataFrame is contained in values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      values : iterable, Series, DataFrame or dict\n",
      " |          The result will only be true at a location if all the\n",
      " |          labels match. If `values` is a Series, that's the index. If\n",
      " |          `values` is a dict, the keys must be the column names,\n",
      " |          which must match. If `values` is a DataFrame,\n",
      " |          then both the index and column labels must match.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          DataFrame of booleans showing whether each element in the DataFrame\n",
      " |          is contained in values.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.eq: Equality test for DataFrame.\n",
      " |      Series.isin: Equivalent method on Series.\n",
      " |      Series.str.contains: Test if pattern or regex is contained within a\n",
      " |          string of a Series or Index.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'num_legs': [2, 4], 'num_wings': [2, 0]},\n",
      " |      ...                   index=['falcon', 'dog'])\n",
      " |      >>> df\n",
      " |              num_legs  num_wings\n",
      " |      falcon         2          2\n",
      " |      dog            4          0\n",
      " |      \n",
      " |      When ``values`` is a list check whether every value in the DataFrame\n",
      " |      is present in the list (which animals have 0 or 2 legs or wings)\n",
      " |      \n",
      " |      >>> df.isin([0, 2])\n",
      " |              num_legs  num_wings\n",
      " |      falcon      True       True\n",
      " |      dog        False       True\n",
      " |      \n",
      " |      To check if ``values`` is *not* in the DataFrame, use the ``~`` operator:\n",
      " |      \n",
      " |      >>> ~df.isin([0, 2])\n",
      " |              num_legs  num_wings\n",
      " |      falcon     False      False\n",
      " |      dog         True      False\n",
      " |      \n",
      " |      When ``values`` is a dict, we can pass values to check for each\n",
      " |      column separately:\n",
      " |      \n",
      " |      >>> df.isin({'num_wings': [0, 3]})\n",
      " |              num_legs  num_wings\n",
      " |      falcon     False      False\n",
      " |      dog        False       True\n",
      " |      \n",
      " |      When ``values`` is a Series or DataFrame the index and column must\n",
      " |      match. Note that 'falcon' does not match based on the number of legs\n",
      " |      in other.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'num_legs': [8, 3], 'num_wings': [0, 2]},\n",
      " |      ...                      index=['spider', 'falcon'])\n",
      " |      >>> df.isin(other)\n",
      " |              num_legs  num_wings\n",
      " |      falcon     False       True\n",
      " |      dog        False      False\n",
      " |  \n",
      " |  isna(self) -> 'DataFrame'\n",
      " |      Detect missing values.\n",
      " |      \n",
      " |      Return a boolean same-sized object indicating if the values are NA.\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, gets mapped to True\n",
      " |      values.\n",
      " |      Everything else gets mapped to False values. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Mask of bool values for each element in DataFrame that\n",
      " |          indicates whether an element is an NA value.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.isnull : Alias of isna.\n",
      " |      DataFrame.notna : Boolean inverse of isna.\n",
      " |      DataFrame.dropna : Omit axes labels with missing values.\n",
      " |      isna : Top-level isna.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are NA.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(dict(age=[5, 6, np.NaN],\n",
      " |      ...                    born=[pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                          pd.Timestamp('1940-04-25')],\n",
      " |      ...                    name=['Alfred', 'Batman', ''],\n",
      " |      ...                    toy=[None, 'Batmobile', 'Joker']))\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |      \n",
      " |      >>> df.isna()\n",
      " |           age   born   name    toy\n",
      " |      0  False   True  False   True\n",
      " |      1  False  False  False  False\n",
      " |      2   True  False  False  False\n",
      " |      \n",
      " |      Show which entries in a Series are NA.\n",
      " |      \n",
      " |      >>> ser = pd.Series([5, 6, np.NaN])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> ser.isna()\n",
      " |      0    False\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  isnull(self) -> 'DataFrame'\n",
      " |      DataFrame.isnull is an alias for DataFrame.isna.\n",
      " |      \n",
      " |      Detect missing values.\n",
      " |      \n",
      " |      Return a boolean same-sized object indicating if the values are NA.\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, gets mapped to True\n",
      " |      values.\n",
      " |      Everything else gets mapped to False values. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Mask of bool values for each element in DataFrame that\n",
      " |          indicates whether an element is an NA value.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.isnull : Alias of isna.\n",
      " |      DataFrame.notna : Boolean inverse of isna.\n",
      " |      DataFrame.dropna : Omit axes labels with missing values.\n",
      " |      isna : Top-level isna.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are NA.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(dict(age=[5, 6, np.NaN],\n",
      " |      ...                    born=[pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                          pd.Timestamp('1940-04-25')],\n",
      " |      ...                    name=['Alfred', 'Batman', ''],\n",
      " |      ...                    toy=[None, 'Batmobile', 'Joker']))\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |      \n",
      " |      >>> df.isna()\n",
      " |           age   born   name    toy\n",
      " |      0  False   True  False   True\n",
      " |      1  False  False  False  False\n",
      " |      2   True  False  False  False\n",
      " |      \n",
      " |      Show which entries in a Series are NA.\n",
      " |      \n",
      " |      >>> ser = pd.Series([5, 6, np.NaN])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> ser.isna()\n",
      " |      0    False\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  items(self) -> 'Iterable[tuple[Hashable, Series]]'\n",
      " |      Iterate over (column name, Series) pairs.\n",
      " |      \n",
      " |      Iterates over the DataFrame columns, returning a tuple with\n",
      " |      the column name and the content as a Series.\n",
      " |      \n",
      " |      Yields\n",
      " |      ------\n",
      " |      label : object\n",
      " |          The column names for the DataFrame being iterated over.\n",
      " |      content : Series\n",
      " |          The column entries belonging to each label, as a Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.iterrows : Iterate over DataFrame rows as\n",
      " |          (index, Series) pairs.\n",
      " |      DataFrame.itertuples : Iterate over DataFrame rows as namedtuples\n",
      " |          of the values.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'species': ['bear', 'bear', 'marsupial'],\n",
      " |      ...                   'population': [1864, 22000, 80000]},\n",
      " |      ...                   index=['panda', 'polar', 'koala'])\n",
      " |      >>> df\n",
      " |              species   population\n",
      " |      panda   bear      1864\n",
      " |      polar   bear      22000\n",
      " |      koala   marsupial 80000\n",
      " |      >>> for label, content in df.items():\n",
      " |      ...     print(f'label: {label}')\n",
      " |      ...     print(f'content: {content}', sep='\\n')\n",
      " |      ...\n",
      " |      label: species\n",
      " |      content:\n",
      " |      panda         bear\n",
      " |      polar         bear\n",
      " |      koala    marsupial\n",
      " |      Name: species, dtype: object\n",
      " |      label: population\n",
      " |      content:\n",
      " |      panda     1864\n",
      " |      polar    22000\n",
      " |      koala    80000\n",
      " |      Name: population, dtype: int64\n",
      " |  \n",
      " |  iteritems(self) -> 'Iterable[tuple[Hashable, Series]]'\n",
      " |      Iterate over (column name, Series) pairs.\n",
      " |      \n",
      " |      Iterates over the DataFrame columns, returning a tuple with\n",
      " |      the column name and the content as a Series.\n",
      " |      \n",
      " |      Yields\n",
      " |      ------\n",
      " |      label : object\n",
      " |          The column names for the DataFrame being iterated over.\n",
      " |      content : Series\n",
      " |          The column entries belonging to each label, as a Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.iterrows : Iterate over DataFrame rows as\n",
      " |          (index, Series) pairs.\n",
      " |      DataFrame.itertuples : Iterate over DataFrame rows as namedtuples\n",
      " |          of the values.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'species': ['bear', 'bear', 'marsupial'],\n",
      " |      ...                   'population': [1864, 22000, 80000]},\n",
      " |      ...                   index=['panda', 'polar', 'koala'])\n",
      " |      >>> df\n",
      " |              species   population\n",
      " |      panda   bear      1864\n",
      " |      polar   bear      22000\n",
      " |      koala   marsupial 80000\n",
      " |      >>> for label, content in df.items():\n",
      " |      ...     print(f'label: {label}')\n",
      " |      ...     print(f'content: {content}', sep='\\n')\n",
      " |      ...\n",
      " |      label: species\n",
      " |      content:\n",
      " |      panda         bear\n",
      " |      polar         bear\n",
      " |      koala    marsupial\n",
      " |      Name: species, dtype: object\n",
      " |      label: population\n",
      " |      content:\n",
      " |      panda     1864\n",
      " |      polar    22000\n",
      " |      koala    80000\n",
      " |      Name: population, dtype: int64\n",
      " |  \n",
      " |  iterrows(self) -> 'Iterable[tuple[Hashable, Series]]'\n",
      " |      Iterate over DataFrame rows as (index, Series) pairs.\n",
      " |      \n",
      " |      Yields\n",
      " |      ------\n",
      " |      index : label or tuple of label\n",
      " |          The index of the row. A tuple for a `MultiIndex`.\n",
      " |      data : Series\n",
      " |          The data of the row as a Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.itertuples : Iterate over DataFrame rows as namedtuples of the values.\n",
      " |      DataFrame.items : Iterate over (column name, Series) pairs.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      1. Because ``iterrows`` returns a Series for each row,\n",
      " |         it does **not** preserve dtypes across the rows (dtypes are\n",
      " |         preserved across columns for DataFrames). For example,\n",
      " |      \n",
      " |         >>> df = pd.DataFrame([[1, 1.5]], columns=['int', 'float'])\n",
      " |         >>> row = next(df.iterrows())[1]\n",
      " |         >>> row\n",
      " |         int      1.0\n",
      " |         float    1.5\n",
      " |         Name: 0, dtype: float64\n",
      " |         >>> print(row['int'].dtype)\n",
      " |         float64\n",
      " |         >>> print(df['int'].dtype)\n",
      " |         int64\n",
      " |      \n",
      " |         To preserve dtypes while iterating over the rows, it is better\n",
      " |         to use :meth:`itertuples` which returns namedtuples of the values\n",
      " |         and which is generally faster than ``iterrows``.\n",
      " |      \n",
      " |      2. You should **never modify** something you are iterating over.\n",
      " |         This is not guaranteed to work in all cases. Depending on the\n",
      " |         data types, the iterator returns a copy and not a view, and writing\n",
      " |         to it will have no effect.\n",
      " |  \n",
      " |  itertuples(self, index: 'bool' = True, name: 'str | None' = 'Pandas') -> 'Iterable[tuple[Any, ...]]'\n",
      " |      Iterate over DataFrame rows as namedtuples.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : bool, default True\n",
      " |          If True, return the index as the first element of the tuple.\n",
      " |      name : str or None, default \"Pandas\"\n",
      " |          The name of the returned namedtuples or None to return regular\n",
      " |          tuples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      iterator\n",
      " |          An object to iterate over namedtuples for each row in the\n",
      " |          DataFrame with the first field possibly being the index and\n",
      " |          following fields being the column values.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.iterrows : Iterate over DataFrame rows as (index, Series)\n",
      " |          pairs.\n",
      " |      DataFrame.items : Iterate over (column name, Series) pairs.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The column names will be renamed to positional names if they are\n",
      " |      invalid Python identifiers, repeated, or start with an underscore.\n",
      " |      On python versions < 3.7 regular tuples are returned for DataFrames\n",
      " |      with a large number of columns (>254).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'num_legs': [4, 2], 'num_wings': [0, 2]},\n",
      " |      ...                   index=['dog', 'hawk'])\n",
      " |      >>> df\n",
      " |            num_legs  num_wings\n",
      " |      dog          4          0\n",
      " |      hawk         2          2\n",
      " |      >>> for row in df.itertuples():\n",
      " |      ...     print(row)\n",
      " |      ...\n",
      " |      Pandas(Index='dog', num_legs=4, num_wings=0)\n",
      " |      Pandas(Index='hawk', num_legs=2, num_wings=2)\n",
      " |      \n",
      " |      By setting the `index` parameter to False we can remove the index\n",
      " |      as the first element of the tuple:\n",
      " |      \n",
      " |      >>> for row in df.itertuples(index=False):\n",
      " |      ...     print(row)\n",
      " |      ...\n",
      " |      Pandas(num_legs=4, num_wings=0)\n",
      " |      Pandas(num_legs=2, num_wings=2)\n",
      " |      \n",
      " |      With the `name` parameter set we set a custom name for the yielded\n",
      " |      namedtuples:\n",
      " |      \n",
      " |      >>> for row in df.itertuples(name='Animal'):\n",
      " |      ...     print(row)\n",
      " |      ...\n",
      " |      Animal(Index='dog', num_legs=4, num_wings=0)\n",
      " |      Animal(Index='hawk', num_legs=2, num_wings=2)\n",
      " |  \n",
      " |  join(self, other: 'DataFrame | Series', on: 'IndexLabel | None' = None, how: 'str' = 'left', lsuffix: 'str' = '', rsuffix: 'str' = '', sort: 'bool' = False) -> 'DataFrame'\n",
      " |      Join columns of another DataFrame.\n",
      " |      \n",
      " |      Join columns with `other` DataFrame either on index or on a key\n",
      " |      column. Efficiently join multiple DataFrame objects by index at once by\n",
      " |      passing a list.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame, Series, or list of DataFrame\n",
      " |          Index should be similar to one of the columns in this one. If a\n",
      " |          Series is passed, its name attribute must be set, and that will be\n",
      " |          used as the column name in the resulting joined DataFrame.\n",
      " |      on : str, list of str, or array-like, optional\n",
      " |          Column or index level name(s) in the caller to join on the index\n",
      " |          in `other`, otherwise joins index-on-index. If multiple\n",
      " |          values given, the `other` DataFrame must have a MultiIndex. Can\n",
      " |          pass an array as the join key if it is not already contained in\n",
      " |          the calling DataFrame. Like an Excel VLOOKUP operation.\n",
      " |      how : {'left', 'right', 'outer', 'inner'}, default 'left'\n",
      " |          How to handle the operation of the two objects.\n",
      " |      \n",
      " |          * left: use calling frame's index (or column if on is specified)\n",
      " |          * right: use `other`'s index.\n",
      " |          * outer: form union of calling frame's index (or column if on is\n",
      " |            specified) with `other`'s index, and sort it.\n",
      " |            lexicographically.\n",
      " |          * inner: form intersection of calling frame's index (or column if\n",
      " |            on is specified) with `other`'s index, preserving the order\n",
      " |            of the calling's one.\n",
      " |          * cross: creates the cartesian product from both frames, preserves the order\n",
      " |            of the left keys.\n",
      " |      \n",
      " |            .. versionadded:: 1.2.0\n",
      " |      \n",
      " |      lsuffix : str, default ''\n",
      " |          Suffix to use from left frame's overlapping columns.\n",
      " |      rsuffix : str, default ''\n",
      " |          Suffix to use from right frame's overlapping columns.\n",
      " |      sort : bool, default False\n",
      " |          Order result DataFrame lexicographically by the join key. If False,\n",
      " |          the order of the join key depends on the join type (how keyword).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          A dataframe containing columns from both the caller and `other`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.merge : For column(s)-on-column(s) operations.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Parameters `on`, `lsuffix`, and `rsuffix` are not supported when\n",
      " |      passing a list of `DataFrame` objects.\n",
      " |      \n",
      " |      Support for specifying index levels as the `on` parameter was added\n",
      " |      in version 0.23.0.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3', 'K4', 'K5'],\n",
      " |      ...                    'A': ['A0', 'A1', 'A2', 'A3', 'A4', 'A5']})\n",
      " |      \n",
      " |      >>> df\n",
      " |        key   A\n",
      " |      0  K0  A0\n",
      " |      1  K1  A1\n",
      " |      2  K2  A2\n",
      " |      3  K3  A3\n",
      " |      4  K4  A4\n",
      " |      5  K5  A5\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'key': ['K0', 'K1', 'K2'],\n",
      " |      ...                       'B': ['B0', 'B1', 'B2']})\n",
      " |      \n",
      " |      >>> other\n",
      " |        key   B\n",
      " |      0  K0  B0\n",
      " |      1  K1  B1\n",
      " |      2  K2  B2\n",
      " |      \n",
      " |      Join DataFrames using their indexes.\n",
      " |      \n",
      " |      >>> df.join(other, lsuffix='_caller', rsuffix='_other')\n",
      " |        key_caller   A key_other    B\n",
      " |      0         K0  A0        K0   B0\n",
      " |      1         K1  A1        K1   B1\n",
      " |      2         K2  A2        K2   B2\n",
      " |      3         K3  A3       NaN  NaN\n",
      " |      4         K4  A4       NaN  NaN\n",
      " |      5         K5  A5       NaN  NaN\n",
      " |      \n",
      " |      If we want to join using the key columns, we need to set key to be\n",
      " |      the index in both `df` and `other`. The joined DataFrame will have\n",
      " |      key as its index.\n",
      " |      \n",
      " |      >>> df.set_index('key').join(other.set_index('key'))\n",
      " |            A    B\n",
      " |      key\n",
      " |      K0   A0   B0\n",
      " |      K1   A1   B1\n",
      " |      K2   A2   B2\n",
      " |      K3   A3  NaN\n",
      " |      K4   A4  NaN\n",
      " |      K5   A5  NaN\n",
      " |      \n",
      " |      Another option to join using the key columns is to use the `on`\n",
      " |      parameter. DataFrame.join always uses `other`'s index but we can use\n",
      " |      any column in `df`. This method preserves the original DataFrame's\n",
      " |      index in the result.\n",
      " |      \n",
      " |      >>> df.join(other.set_index('key'), on='key')\n",
      " |        key   A    B\n",
      " |      0  K0  A0   B0\n",
      " |      1  K1  A1   B1\n",
      " |      2  K2  A2   B2\n",
      " |      3  K3  A3  NaN\n",
      " |      4  K4  A4  NaN\n",
      " |      5  K5  A5  NaN\n",
      " |      \n",
      " |      Using non-unique key values shows how they are matched.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'key': ['K0', 'K1', 'K1', 'K3', 'K0', 'K1'],\n",
      " |      ...                    'A': ['A0', 'A1', 'A2', 'A3', 'A4', 'A5']})\n",
      " |      \n",
      " |      >>> df\n",
      " |        key   A\n",
      " |      0  K0  A0\n",
      " |      1  K1  A1\n",
      " |      2  K1  A2\n",
      " |      3  K3  A3\n",
      " |      4  K0  A4\n",
      " |      5  K1  A5\n",
      " |      \n",
      " |      >>> df.join(other.set_index('key'), on='key')\n",
      " |        key   A    B\n",
      " |      0  K0  A0   B0\n",
      " |      1  K1  A1   B1\n",
      " |      2  K1  A2   B1\n",
      " |      3  K3  A3  NaN\n",
      " |      4  K0  A4   B0\n",
      " |      5  K1  A5   B1\n",
      " |  \n",
      " |  kurt(self, axis: 'Axis | None | lib.NoDefault' = <no_default>, skipna=True, level=None, numeric_only=None, **kwargs)\n",
      " |      Return unbiased kurtosis over requested axis.\n",
      " |      \n",
      " |      Kurtosis obtained using Fisher's definition of\n",
      " |      kurtosis (kurtosis of normal == 0.0). Normalized by N-1.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  kurtosis = kurt(self, axis: 'Axis | None | lib.NoDefault' = <no_default>, skipna=True, level=None, numeric_only=None, **kwargs)\n",
      " |  \n",
      " |  le(self, other, axis='columns', level=None)\n",
      " |      Get Less than or equal to of dataframe and other, element-wise (binary operator `le`).\n",
      " |      \n",
      " |      Among flexible wrappers (`eq`, `ne`, `le`, `lt`, `ge`, `gt`) to comparison\n",
      " |      operators.\n",
      " |      \n",
      " |      Equivalent to `==`, `!=`, `<=`, `<`, `>=`, `>` with support to choose axis\n",
      " |      (rows or columns) and level for comparison.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 'columns'\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns').\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the passed\n",
      " |          MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame of bool\n",
      " |          Result of the comparison.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.eq : Compare DataFrames for equality elementwise.\n",
      " |      DataFrame.ne : Compare DataFrames for inequality elementwise.\n",
      " |      DataFrame.le : Compare DataFrames for less than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.lt : Compare DataFrames for strictly less than\n",
      " |          inequality elementwise.\n",
      " |      DataFrame.ge : Compare DataFrames for greater than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.gt : Compare DataFrames for strictly greater than\n",
      " |          inequality elementwise.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      `NaN` values are considered different (i.e. `NaN` != `NaN`).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'cost': [250, 150, 100],\n",
      " |      ...                    'revenue': [100, 250, 300]},\n",
      " |      ...                   index=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |         cost  revenue\n",
      " |      A   250      100\n",
      " |      B   150      250\n",
      " |      C   100      300\n",
      " |      \n",
      " |      Comparison with a scalar, using either the operator or method:\n",
      " |      \n",
      " |      >>> df == 100\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      >>> df.eq(100)\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      When `other` is a :class:`Series`, the columns of a DataFrame are aligned\n",
      " |      with the index of `other` and broadcast:\n",
      " |      \n",
      " |      >>> df != pd.Series([100, 250], index=[\"cost\", \"revenue\"])\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B   True    False\n",
      " |      C  False     True\n",
      " |      \n",
      " |      Use the method to control the broadcast axis:\n",
      " |      \n",
      " |      >>> df.ne(pd.Series([100, 300], index=[\"A\", \"D\"]), axis='index')\n",
      " |         cost  revenue\n",
      " |      A  True    False\n",
      " |      B  True     True\n",
      " |      C  True     True\n",
      " |      D  True     True\n",
      " |      \n",
      " |      When comparing to an arbitrary sequence, the number of columns must\n",
      " |      match the number elements in `other`:\n",
      " |      \n",
      " |      >>> df == [250, 100]\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B  False    False\n",
      " |      C  False    False\n",
      " |      \n",
      " |      Use the method to control the axis:\n",
      " |      \n",
      " |      >>> df.eq([250, 250, 100], axis='index')\n",
      " |          cost  revenue\n",
      " |      A   True    False\n",
      " |      B  False     True\n",
      " |      C   True    False\n",
      " |      \n",
      " |      Compare to a DataFrame of different shape.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'revenue': [300, 250, 100, 150]},\n",
      " |      ...                      index=['A', 'B', 'C', 'D'])\n",
      " |      >>> other\n",
      " |         revenue\n",
      " |      A      300\n",
      " |      B      250\n",
      " |      C      100\n",
      " |      D      150\n",
      " |      \n",
      " |      >>> df.gt(other)\n",
      " |          cost  revenue\n",
      " |      A  False    False\n",
      " |      B  False    False\n",
      " |      C  False     True\n",
      " |      D  False    False\n",
      " |      \n",
      " |      Compare to a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],\n",
      " |      ...                              'revenue': [100, 250, 300, 200, 175, 225]},\n",
      " |      ...                             index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],\n",
      " |      ...                                    ['A', 'B', 'C', 'A', 'B', 'C']])\n",
      " |      >>> df_multindex\n",
      " |            cost  revenue\n",
      " |      Q1 A   250      100\n",
      " |         B   150      250\n",
      " |         C   100      300\n",
      " |      Q2 A   150      200\n",
      " |         B   300      175\n",
      " |         C   220      225\n",
      " |      \n",
      " |      >>> df.le(df_multindex, level=1)\n",
      " |             cost  revenue\n",
      " |      Q1 A   True     True\n",
      " |         B   True     True\n",
      " |         C   True     True\n",
      " |      Q2 A  False     True\n",
      " |         B   True    False\n",
      " |         C   True    False\n",
      " |  \n",
      " |  lookup(self, row_labels: 'Sequence[IndexLabel]', col_labels: 'Sequence[IndexLabel]') -> 'np.ndarray'\n",
      " |      Label-based \"fancy indexing\" function for DataFrame.\n",
      " |      Given equal-length arrays of row and column labels, return an\n",
      " |      array of the values corresponding to each (row, col) pair.\n",
      " |      \n",
      " |      .. deprecated:: 1.2.0\n",
      " |          DataFrame.lookup is deprecated,\n",
      " |          use DataFrame.melt and DataFrame.loc instead.\n",
      " |          For further details see\n",
      " |          :ref:`Looking up values by index/column labels <indexing.lookup>`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      row_labels : sequence\n",
      " |          The row labels to use for lookup.\n",
      " |      col_labels : sequence\n",
      " |          The column labels to use for lookup.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray\n",
      " |          The found values.\n",
      " |  \n",
      " |  lt(self, other, axis='columns', level=None)\n",
      " |      Get Less than of dataframe and other, element-wise (binary operator `lt`).\n",
      " |      \n",
      " |      Among flexible wrappers (`eq`, `ne`, `le`, `lt`, `ge`, `gt`) to comparison\n",
      " |      operators.\n",
      " |      \n",
      " |      Equivalent to `==`, `!=`, `<=`, `<`, `>=`, `>` with support to choose axis\n",
      " |      (rows or columns) and level for comparison.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 'columns'\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns').\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the passed\n",
      " |          MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame of bool\n",
      " |          Result of the comparison.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.eq : Compare DataFrames for equality elementwise.\n",
      " |      DataFrame.ne : Compare DataFrames for inequality elementwise.\n",
      " |      DataFrame.le : Compare DataFrames for less than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.lt : Compare DataFrames for strictly less than\n",
      " |          inequality elementwise.\n",
      " |      DataFrame.ge : Compare DataFrames for greater than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.gt : Compare DataFrames for strictly greater than\n",
      " |          inequality elementwise.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      `NaN` values are considered different (i.e. `NaN` != `NaN`).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'cost': [250, 150, 100],\n",
      " |      ...                    'revenue': [100, 250, 300]},\n",
      " |      ...                   index=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |         cost  revenue\n",
      " |      A   250      100\n",
      " |      B   150      250\n",
      " |      C   100      300\n",
      " |      \n",
      " |      Comparison with a scalar, using either the operator or method:\n",
      " |      \n",
      " |      >>> df == 100\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      >>> df.eq(100)\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      When `other` is a :class:`Series`, the columns of a DataFrame are aligned\n",
      " |      with the index of `other` and broadcast:\n",
      " |      \n",
      " |      >>> df != pd.Series([100, 250], index=[\"cost\", \"revenue\"])\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B   True    False\n",
      " |      C  False     True\n",
      " |      \n",
      " |      Use the method to control the broadcast axis:\n",
      " |      \n",
      " |      >>> df.ne(pd.Series([100, 300], index=[\"A\", \"D\"]), axis='index')\n",
      " |         cost  revenue\n",
      " |      A  True    False\n",
      " |      B  True     True\n",
      " |      C  True     True\n",
      " |      D  True     True\n",
      " |      \n",
      " |      When comparing to an arbitrary sequence, the number of columns must\n",
      " |      match the number elements in `other`:\n",
      " |      \n",
      " |      >>> df == [250, 100]\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B  False    False\n",
      " |      C  False    False\n",
      " |      \n",
      " |      Use the method to control the axis:\n",
      " |      \n",
      " |      >>> df.eq([250, 250, 100], axis='index')\n",
      " |          cost  revenue\n",
      " |      A   True    False\n",
      " |      B  False     True\n",
      " |      C   True    False\n",
      " |      \n",
      " |      Compare to a DataFrame of different shape.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'revenue': [300, 250, 100, 150]},\n",
      " |      ...                      index=['A', 'B', 'C', 'D'])\n",
      " |      >>> other\n",
      " |         revenue\n",
      " |      A      300\n",
      " |      B      250\n",
      " |      C      100\n",
      " |      D      150\n",
      " |      \n",
      " |      >>> df.gt(other)\n",
      " |          cost  revenue\n",
      " |      A  False    False\n",
      " |      B  False    False\n",
      " |      C  False     True\n",
      " |      D  False    False\n",
      " |      \n",
      " |      Compare to a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],\n",
      " |      ...                              'revenue': [100, 250, 300, 200, 175, 225]},\n",
      " |      ...                             index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],\n",
      " |      ...                                    ['A', 'B', 'C', 'A', 'B', 'C']])\n",
      " |      >>> df_multindex\n",
      " |            cost  revenue\n",
      " |      Q1 A   250      100\n",
      " |         B   150      250\n",
      " |         C   100      300\n",
      " |      Q2 A   150      200\n",
      " |         B   300      175\n",
      " |         C   220      225\n",
      " |      \n",
      " |      >>> df.le(df_multindex, level=1)\n",
      " |             cost  revenue\n",
      " |      Q1 A   True     True\n",
      " |         B   True     True\n",
      " |         C   True     True\n",
      " |      Q2 A  False     True\n",
      " |         B   True    False\n",
      " |         C   True    False\n",
      " |  \n",
      " |  mad(self, axis=None, skipna=True, level=None)\n",
      " |      Return the mean absolute deviation of the values over the requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  mask(self, cond, other=nan, inplace=False, axis=None, level=None, errors='raise', try_cast=<no_default>)\n",
      " |      Replace values where the condition is True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      cond : bool Series/DataFrame, array-like, or callable\n",
      " |          Where `cond` is False, keep the original value. Where\n",
      " |          True, replace with corresponding value from `other`.\n",
      " |          If `cond` is callable, it is computed on the Series/DataFrame and\n",
      " |          should return boolean Series/DataFrame or array. The callable must\n",
      " |          not change input Series/DataFrame (though pandas doesn't check it).\n",
      " |      other : scalar, Series/DataFrame, or callable\n",
      " |          Entries where `cond` is True are replaced with\n",
      " |          corresponding value from `other`.\n",
      " |          If other is callable, it is computed on the Series/DataFrame and\n",
      " |          should return scalar or Series/DataFrame. The callable must not\n",
      " |          change input Series/DataFrame (though pandas doesn't check it).\n",
      " |      inplace : bool, default False\n",
      " |          Whether to perform the operation in place on the data.\n",
      " |      axis : int, default None\n",
      " |          Alignment axis if needed.\n",
      " |      level : int, default None\n",
      " |          Alignment level if needed.\n",
      " |      errors : str, {'raise', 'ignore'}, default 'raise'\n",
      " |          Note that currently this parameter won't affect\n",
      " |          the results and will always coerce to a suitable dtype.\n",
      " |      \n",
      " |          - 'raise' : allow exceptions to be raised.\n",
      " |          - 'ignore' : suppress exceptions. On error return original object.\n",
      " |      \n",
      " |      try_cast : bool, default None\n",
      " |          Try to cast the result back to the input type (if possible).\n",
      " |      \n",
      " |          .. deprecated:: 1.3.0\n",
      " |              Manually cast back if necessary.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Same type as caller or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      :func:`DataFrame.where` : Return an object of same shape as\n",
      " |          self.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The mask method is an application of the if-then idiom. For each\n",
      " |      element in the calling DataFrame, if ``cond`` is ``False`` the\n",
      " |      element is used; otherwise the corresponding element from the DataFrame\n",
      " |      ``other`` is used.\n",
      " |      \n",
      " |      The signature for :func:`DataFrame.where` differs from\n",
      " |      :func:`numpy.where`. Roughly ``df1.where(m, df2)`` is equivalent to\n",
      " |      ``np.where(m, df1, df2)``.\n",
      " |      \n",
      " |      For further details and examples see the ``mask`` documentation in\n",
      " |      :ref:`indexing <indexing.where_mask>`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(range(5))\n",
      " |      >>> s.where(s > 0)\n",
      " |      0    NaN\n",
      " |      1    1.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      4    4.0\n",
      " |      dtype: float64\n",
      " |      >>> s.mask(s > 0)\n",
      " |      0    0.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.where(s > 1, 10)\n",
      " |      0    10\n",
      " |      1    10\n",
      " |      2    2\n",
      " |      3    3\n",
      " |      4    4\n",
      " |      dtype: int64\n",
      " |      >>> s.mask(s > 1, 10)\n",
      " |      0     0\n",
      " |      1     1\n",
      " |      2    10\n",
      " |      3    10\n",
      " |      4    10\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  0  1\n",
      " |      1  2  3\n",
      " |      2  4  5\n",
      " |      3  6  7\n",
      " |      4  8  9\n",
      " |      >>> m = df % 3 == 0\n",
      " |      >>> df.where(m, -df)\n",
      " |         A  B\n",
      " |      0  0 -1\n",
      " |      1 -2  3\n",
      " |      2 -4 -5\n",
      " |      3  6 -7\n",
      " |      4 -8  9\n",
      " |      >>> df.where(m, -df) == np.where(m, df, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |      >>> df.where(m, -df) == df.mask(~m, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |  \n",
      " |  max(self, axis: 'int | None | lib.NoDefault' = <no_default>, skipna=True, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the maximum of the values over the requested axis.\n",
      " |      \n",
      " |      If you want the *index* of the maximum, use ``idxmax``. This is the equivalent of the ``numpy.ndarray`` method ``argmax``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sum : Return the sum.\n",
      " |      Series.min : Return the minimum.\n",
      " |      Series.max : Return the maximum.\n",
      " |      Series.idxmin : Return the index of the minimum.\n",
      " |      Series.idxmax : Return the index of the maximum.\n",
      " |      DataFrame.sum : Return the sum over the requested axis.\n",
      " |      DataFrame.min : Return the minimum over the requested axis.\n",
      " |      DataFrame.max : Return the maximum over the requested axis.\n",
      " |      DataFrame.idxmin : Return the index of the minimum over the requested axis.\n",
      " |      DataFrame.idxmax : Return the index of the maximum over the requested axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.MultiIndex.from_arrays([\n",
      " |      ...     ['warm', 'warm', 'cold', 'cold'],\n",
      " |      ...     ['dog', 'falcon', 'fish', 'spider']],\n",
      " |      ...     names=['blooded', 'animal'])\n",
      " |      >>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)\n",
      " |      >>> s\n",
      " |      blooded  animal\n",
      " |      warm     dog       4\n",
      " |               falcon    2\n",
      " |      cold     fish      0\n",
      " |               spider    8\n",
      " |      Name: legs, dtype: int64\n",
      " |      \n",
      " |      >>> s.max()\n",
      " |      8\n",
      " |  \n",
      " |  mean(self, axis: 'int | None | lib.NoDefault' = <no_default>, skipna=True, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the mean of the values over the requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  median(self, axis: 'int | None | lib.NoDefault' = <no_default>, skipna=True, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the median of the values over the requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  melt(self, id_vars=None, value_vars=None, var_name=None, value_name='value', col_level: 'Level | None' = None, ignore_index: 'bool' = True) -> 'DataFrame'\n",
      " |      Unpivot a DataFrame from wide to long format, optionally leaving identifiers set.\n",
      " |      \n",
      " |      This function is useful to massage a DataFrame into a format where one\n",
      " |      or more columns are identifier variables (`id_vars`), while all other\n",
      " |      columns, considered measured variables (`value_vars`), are \"unpivoted\" to\n",
      " |      the row axis, leaving just two non-identifier columns, 'variable' and\n",
      " |      'value'.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      id_vars : tuple, list, or ndarray, optional\n",
      " |          Column(s) to use as identifier variables.\n",
      " |      value_vars : tuple, list, or ndarray, optional\n",
      " |          Column(s) to unpivot. If not specified, uses all columns that\n",
      " |          are not set as `id_vars`.\n",
      " |      var_name : scalar\n",
      " |          Name to use for the 'variable' column. If None it uses\n",
      " |          ``frame.columns.name`` or 'variable'.\n",
      " |      value_name : scalar, default 'value'\n",
      " |          Name to use for the 'value' column.\n",
      " |      col_level : int or str, optional\n",
      " |          If columns are a MultiIndex then use this level to melt.\n",
      " |      ignore_index : bool, default True\n",
      " |          If True, original index is ignored. If False, the original index is retained.\n",
      " |          Index labels will be repeated as necessary.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Unpivoted DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      melt : Identical method.\n",
      " |      pivot_table : Create a spreadsheet-style pivot table as a DataFrame.\n",
      " |      DataFrame.pivot : Return reshaped DataFrame organized\n",
      " |          by given index / column values.\n",
      " |      DataFrame.explode : Explode a DataFrame from list-like\n",
      " |              columns to long format.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Reference :ref:`the user guide <reshaping.melt>` for more examples.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': {0: 'a', 1: 'b', 2: 'c'},\n",
      " |      ...                    'B': {0: 1, 1: 3, 2: 5},\n",
      " |      ...                    'C': {0: 2, 1: 4, 2: 6}})\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |      0  a  1  2\n",
      " |      1  b  3  4\n",
      " |      2  c  5  6\n",
      " |      \n",
      " |      >>> df.melt(id_vars=['A'], value_vars=['B'])\n",
      " |         A variable  value\n",
      " |      0  a        B      1\n",
      " |      1  b        B      3\n",
      " |      2  c        B      5\n",
      " |      \n",
      " |      >>> df.melt(id_vars=['A'], value_vars=['B', 'C'])\n",
      " |         A variable  value\n",
      " |      0  a        B      1\n",
      " |      1  b        B      3\n",
      " |      2  c        B      5\n",
      " |      3  a        C      2\n",
      " |      4  b        C      4\n",
      " |      5  c        C      6\n",
      " |      \n",
      " |      The names of 'variable' and 'value' columns can be customized:\n",
      " |      \n",
      " |      >>> df.melt(id_vars=['A'], value_vars=['B'],\n",
      " |      ...         var_name='myVarname', value_name='myValname')\n",
      " |         A myVarname  myValname\n",
      " |      0  a         B          1\n",
      " |      1  b         B          3\n",
      " |      2  c         B          5\n",
      " |      \n",
      " |      Original index values can be kept around:\n",
      " |      \n",
      " |      >>> df.melt(id_vars=['A'], value_vars=['B', 'C'], ignore_index=False)\n",
      " |         A variable  value\n",
      " |      0  a        B      1\n",
      " |      1  b        B      3\n",
      " |      2  c        B      5\n",
      " |      0  a        C      2\n",
      " |      1  b        C      4\n",
      " |      2  c        C      6\n",
      " |      \n",
      " |      If you have multi-index columns:\n",
      " |      \n",
      " |      >>> df.columns = [list('ABC'), list('DEF')]\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |         D  E  F\n",
      " |      0  a  1  2\n",
      " |      1  b  3  4\n",
      " |      2  c  5  6\n",
      " |      \n",
      " |      >>> df.melt(col_level=0, id_vars=['A'], value_vars=['B'])\n",
      " |         A variable  value\n",
      " |      0  a        B      1\n",
      " |      1  b        B      3\n",
      " |      2  c        B      5\n",
      " |      \n",
      " |      >>> df.melt(id_vars=[('A', 'D')], value_vars=[('B', 'E')])\n",
      " |        (A, D) variable_0 variable_1  value\n",
      " |      0      a          B          E      1\n",
      " |      1      b          B          E      3\n",
      " |      2      c          B          E      5\n",
      " |  \n",
      " |  memory_usage(self, index: 'bool' = True, deep: 'bool' = False) -> 'Series'\n",
      " |      Return the memory usage of each column in bytes.\n",
      " |      \n",
      " |      The memory usage can optionally include the contribution of\n",
      " |      the index and elements of `object` dtype.\n",
      " |      \n",
      " |      This value is displayed in `DataFrame.info` by default. This can be\n",
      " |      suppressed by setting ``pandas.options.display.memory_usage`` to False.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : bool, default True\n",
      " |          Specifies whether to include the memory usage of the DataFrame's\n",
      " |          index in returned Series. If ``index=True``, the memory usage of\n",
      " |          the index is the first item in the output.\n",
      " |      deep : bool, default False\n",
      " |          If True, introspect the data deeply by interrogating\n",
      " |          `object` dtypes for system-level memory consumption, and include\n",
      " |          it in the returned values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          A Series whose index is the original column names and whose values\n",
      " |          is the memory usage of each column in bytes.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ndarray.nbytes : Total bytes consumed by the elements of an\n",
      " |          ndarray.\n",
      " |      Series.memory_usage : Bytes consumed by a Series.\n",
      " |      Categorical : Memory-efficient array for string values with\n",
      " |          many repeated values.\n",
      " |      DataFrame.info : Concise summary of a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> dtypes = ['int64', 'float64', 'complex128', 'object', 'bool']\n",
      " |      >>> data = dict([(t, np.ones(shape=5000, dtype=int).astype(t))\n",
      " |      ...              for t in dtypes])\n",
      " |      >>> df = pd.DataFrame(data)\n",
      " |      >>> df.head()\n",
      " |         int64  float64            complex128  object  bool\n",
      " |      0      1      1.0              1.0+0.0j       1  True\n",
      " |      1      1      1.0              1.0+0.0j       1  True\n",
      " |      2      1      1.0              1.0+0.0j       1  True\n",
      " |      3      1      1.0              1.0+0.0j       1  True\n",
      " |      4      1      1.0              1.0+0.0j       1  True\n",
      " |      \n",
      " |      >>> df.memory_usage()\n",
      " |      Index           128\n",
      " |      int64         40000\n",
      " |      float64       40000\n",
      " |      complex128    80000\n",
      " |      object        40000\n",
      " |      bool           5000\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df.memory_usage(index=False)\n",
      " |      int64         40000\n",
      " |      float64       40000\n",
      " |      complex128    80000\n",
      " |      object        40000\n",
      " |      bool           5000\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      The memory footprint of `object` dtype columns is ignored by default:\n",
      " |      \n",
      " |      >>> df.memory_usage(deep=True)\n",
      " |      Index            128\n",
      " |      int64          40000\n",
      " |      float64        40000\n",
      " |      complex128     80000\n",
      " |      object        180000\n",
      " |      bool            5000\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Use a Categorical for efficient storage of an object-dtype column with\n",
      " |      many repeated values.\n",
      " |      \n",
      " |      >>> df['object'].astype('category').memory_usage(deep=True)\n",
      " |      5244\n",
      " |  \n",
      " |  merge(self, right: 'DataFrame | Series', how: 'str' = 'inner', on: 'IndexLabel | None' = None, left_on: 'IndexLabel | None' = None, right_on: 'IndexLabel | None' = None, left_index: 'bool' = False, right_index: 'bool' = False, sort: 'bool' = False, suffixes: 'Suffixes' = ('_x', '_y'), copy: 'bool' = True, indicator: 'bool' = False, validate: 'str | None' = None) -> 'DataFrame'\n",
      " |      Merge DataFrame or named Series objects with a database-style join.\n",
      " |      \n",
      " |      A named Series object is treated as a DataFrame with a single named column.\n",
      " |      \n",
      " |      The join is done on columns or indexes. If joining columns on\n",
      " |      columns, the DataFrame indexes *will be ignored*. Otherwise if joining indexes\n",
      " |      on indexes or indexes on a column or columns, the index will be passed on.\n",
      " |      When performing a cross merge, no column specifications to merge on are\n",
      " |      allowed.\n",
      " |      \n",
      " |      .. warning::\n",
      " |      \n",
      " |          If both key columns contain rows where the key is a null value, those\n",
      " |          rows will be matched against each other. This is different from usual SQL\n",
      " |          join behaviour and can lead to unexpected results.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      right : DataFrame or named Series\n",
      " |          Object to merge with.\n",
      " |      how : {'left', 'right', 'outer', 'inner', 'cross'}, default 'inner'\n",
      " |          Type of merge to be performed.\n",
      " |      \n",
      " |          * left: use only keys from left frame, similar to a SQL left outer join;\n",
      " |            preserve key order.\n",
      " |          * right: use only keys from right frame, similar to a SQL right outer join;\n",
      " |            preserve key order.\n",
      " |          * outer: use union of keys from both frames, similar to a SQL full outer\n",
      " |            join; sort keys lexicographically.\n",
      " |          * inner: use intersection of keys from both frames, similar to a SQL inner\n",
      " |            join; preserve the order of the left keys.\n",
      " |          * cross: creates the cartesian product from both frames, preserves the order\n",
      " |            of the left keys.\n",
      " |      \n",
      " |            .. versionadded:: 1.2.0\n",
      " |      \n",
      " |      on : label or list\n",
      " |          Column or index level names to join on. These must be found in both\n",
      " |          DataFrames. If `on` is None and not merging on indexes then this defaults\n",
      " |          to the intersection of the columns in both DataFrames.\n",
      " |      left_on : label or list, or array-like\n",
      " |          Column or index level names to join on in the left DataFrame. Can also\n",
      " |          be an array or list of arrays of the length of the left DataFrame.\n",
      " |          These arrays are treated as if they are columns.\n",
      " |      right_on : label or list, or array-like\n",
      " |          Column or index level names to join on in the right DataFrame. Can also\n",
      " |          be an array or list of arrays of the length of the right DataFrame.\n",
      " |          These arrays are treated as if they are columns.\n",
      " |      left_index : bool, default False\n",
      " |          Use the index from the left DataFrame as the join key(s). If it is a\n",
      " |          MultiIndex, the number of keys in the other DataFrame (either the index\n",
      " |          or a number of columns) must match the number of levels.\n",
      " |      right_index : bool, default False\n",
      " |          Use the index from the right DataFrame as the join key. Same caveats as\n",
      " |          left_index.\n",
      " |      sort : bool, default False\n",
      " |          Sort the join keys lexicographically in the result DataFrame. If False,\n",
      " |          the order of the join keys depends on the join type (how keyword).\n",
      " |      suffixes : list-like, default is (\"_x\", \"_y\")\n",
      " |          A length-2 sequence where each element is optionally a string\n",
      " |          indicating the suffix to add to overlapping column names in\n",
      " |          `left` and `right` respectively. Pass a value of `None` instead\n",
      " |          of a string to indicate that the column name from `left` or\n",
      " |          `right` should be left as-is, with no suffix. At least one of the\n",
      " |          values must not be None.\n",
      " |      copy : bool, default True\n",
      " |          If False, avoid copy if possible.\n",
      " |      indicator : bool or str, default False\n",
      " |          If True, adds a column to the output DataFrame called \"_merge\" with\n",
      " |          information on the source of each row. The column can be given a different\n",
      " |          name by providing a string argument. The column will have a Categorical\n",
      " |          type with the value of \"left_only\" for observations whose merge key only\n",
      " |          appears in the left DataFrame, \"right_only\" for observations\n",
      " |          whose merge key only appears in the right DataFrame, and \"both\"\n",
      " |          if the observation's merge key is found in both DataFrames.\n",
      " |      \n",
      " |      validate : str, optional\n",
      " |          If specified, checks if merge is of specified type.\n",
      " |      \n",
      " |          * \"one_to_one\" or \"1:1\": check if merge keys are unique in both\n",
      " |            left and right datasets.\n",
      " |          * \"one_to_many\" or \"1:m\": check if merge keys are unique in left\n",
      " |            dataset.\n",
      " |          * \"many_to_one\" or \"m:1\": check if merge keys are unique in right\n",
      " |            dataset.\n",
      " |          * \"many_to_many\" or \"m:m\": allowed, but does not result in checks.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          A DataFrame of the two merged objects.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      merge_ordered : Merge with optional filling/interpolation.\n",
      " |      merge_asof : Merge on nearest keys.\n",
      " |      DataFrame.join : Similar method using indices.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Support for specifying index levels as the `on`, `left_on`, and\n",
      " |      `right_on` parameters was added in version 0.23.0\n",
      " |      Support for merging named Series objects was added in version 0.24.0\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df1 = pd.DataFrame({'lkey': ['foo', 'bar', 'baz', 'foo'],\n",
      " |      ...                     'value': [1, 2, 3, 5]})\n",
      " |      >>> df2 = pd.DataFrame({'rkey': ['foo', 'bar', 'baz', 'foo'],\n",
      " |      ...                     'value': [5, 6, 7, 8]})\n",
      " |      >>> df1\n",
      " |          lkey value\n",
      " |      0   foo      1\n",
      " |      1   bar      2\n",
      " |      2   baz      3\n",
      " |      3   foo      5\n",
      " |      >>> df2\n",
      " |          rkey value\n",
      " |      0   foo      5\n",
      " |      1   bar      6\n",
      " |      2   baz      7\n",
      " |      3   foo      8\n",
      " |      \n",
      " |      Merge df1 and df2 on the lkey and rkey columns. The value columns have\n",
      " |      the default suffixes, _x and _y, appended.\n",
      " |      \n",
      " |      >>> df1.merge(df2, left_on='lkey', right_on='rkey')\n",
      " |        lkey  value_x rkey  value_y\n",
      " |      0  foo        1  foo        5\n",
      " |      1  foo        1  foo        8\n",
      " |      2  foo        5  foo        5\n",
      " |      3  foo        5  foo        8\n",
      " |      4  bar        2  bar        6\n",
      " |      5  baz        3  baz        7\n",
      " |      \n",
      " |      Merge DataFrames df1 and df2 with specified left and right suffixes\n",
      " |      appended to any overlapping columns.\n",
      " |      \n",
      " |      >>> df1.merge(df2, left_on='lkey', right_on='rkey',\n",
      " |      ...           suffixes=('_left', '_right'))\n",
      " |        lkey  value_left rkey  value_right\n",
      " |      0  foo           1  foo            5\n",
      " |      1  foo           1  foo            8\n",
      " |      2  foo           5  foo            5\n",
      " |      3  foo           5  foo            8\n",
      " |      4  bar           2  bar            6\n",
      " |      5  baz           3  baz            7\n",
      " |      \n",
      " |      Merge DataFrames df1 and df2, but raise an exception if the DataFrames have\n",
      " |      any overlapping columns.\n",
      " |      \n",
      " |      >>> df1.merge(df2, left_on='lkey', right_on='rkey', suffixes=(False, False))\n",
      " |      Traceback (most recent call last):\n",
      " |      ...\n",
      " |      ValueError: columns overlap but no suffix specified:\n",
      " |          Index(['value'], dtype='object')\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame({'a': ['foo', 'bar'], 'b': [1, 2]})\n",
      " |      >>> df2 = pd.DataFrame({'a': ['foo', 'baz'], 'c': [3, 4]})\n",
      " |      >>> df1\n",
      " |            a  b\n",
      " |      0   foo  1\n",
      " |      1   bar  2\n",
      " |      >>> df2\n",
      " |            a  c\n",
      " |      0   foo  3\n",
      " |      1   baz  4\n",
      " |      \n",
      " |      >>> df1.merge(df2, how='inner', on='a')\n",
      " |            a  b  c\n",
      " |      0   foo  1  3\n",
      " |      \n",
      " |      >>> df1.merge(df2, how='left', on='a')\n",
      " |            a  b  c\n",
      " |      0   foo  1  3.0\n",
      " |      1   bar  2  NaN\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame({'left': ['foo', 'bar']})\n",
      " |      >>> df2 = pd.DataFrame({'right': [7, 8]})\n",
      " |      >>> df1\n",
      " |          left\n",
      " |      0   foo\n",
      " |      1   bar\n",
      " |      >>> df2\n",
      " |          right\n",
      " |      0   7\n",
      " |      1   8\n",
      " |      \n",
      " |      >>> df1.merge(df2, how='cross')\n",
      " |         left  right\n",
      " |      0   foo      7\n",
      " |      1   foo      8\n",
      " |      2   bar      7\n",
      " |      3   bar      8\n",
      " |  \n",
      " |  min(self, axis: 'int | None | lib.NoDefault' = <no_default>, skipna=True, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the minimum of the values over the requested axis.\n",
      " |      \n",
      " |      If you want the *index* of the minimum, use ``idxmin``. This is the equivalent of the ``numpy.ndarray`` method ``argmin``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sum : Return the sum.\n",
      " |      Series.min : Return the minimum.\n",
      " |      Series.max : Return the maximum.\n",
      " |      Series.idxmin : Return the index of the minimum.\n",
      " |      Series.idxmax : Return the index of the maximum.\n",
      " |      DataFrame.sum : Return the sum over the requested axis.\n",
      " |      DataFrame.min : Return the minimum over the requested axis.\n",
      " |      DataFrame.max : Return the maximum over the requested axis.\n",
      " |      DataFrame.idxmin : Return the index of the minimum over the requested axis.\n",
      " |      DataFrame.idxmax : Return the index of the maximum over the requested axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.MultiIndex.from_arrays([\n",
      " |      ...     ['warm', 'warm', 'cold', 'cold'],\n",
      " |      ...     ['dog', 'falcon', 'fish', 'spider']],\n",
      " |      ...     names=['blooded', 'animal'])\n",
      " |      >>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)\n",
      " |      >>> s\n",
      " |      blooded  animal\n",
      " |      warm     dog       4\n",
      " |               falcon    2\n",
      " |      cold     fish      0\n",
      " |               spider    8\n",
      " |      Name: legs, dtype: int64\n",
      " |      \n",
      " |      >>> s.min()\n",
      " |      0\n",
      " |  \n",
      " |  mod(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Modulo of dataframe and other, element-wise (binary operator `mod`).\n",
      " |      \n",
      " |      Equivalent to ``dataframe % other``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `rmod`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  mode(self, axis: 'Axis' = 0, numeric_only: 'bool' = False, dropna: 'bool' = True) -> 'DataFrame'\n",
      " |      Get the mode(s) of each element along the selected axis.\n",
      " |      \n",
      " |      The mode of a set of values is the value that appears most often.\n",
      " |      It can be multiple values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to iterate over while searching for the mode:\n",
      " |      \n",
      " |          * 0 or 'index' : get mode of each column\n",
      " |          * 1 or 'columns' : get mode of each row.\n",
      " |      \n",
      " |      numeric_only : bool, default False\n",
      " |          If True, only apply to numeric columns.\n",
      " |      dropna : bool, default True\n",
      " |          Don't consider counts of NaN/NaT.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The modes of each column or row.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.mode : Return the highest frequency value in a Series.\n",
      " |      Series.value_counts : Return the counts of values in a Series.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('bird', 2, 2),\n",
      " |      ...                    ('mammal', 4, np.nan),\n",
      " |      ...                    ('arthropod', 8, 0),\n",
      " |      ...                    ('bird', 2, np.nan)],\n",
      " |      ...                   index=('falcon', 'horse', 'spider', 'ostrich'),\n",
      " |      ...                   columns=('species', 'legs', 'wings'))\n",
      " |      >>> df\n",
      " |                 species  legs  wings\n",
      " |      falcon        bird     2    2.0\n",
      " |      horse       mammal     4    NaN\n",
      " |      spider   arthropod     8    0.0\n",
      " |      ostrich       bird     2    NaN\n",
      " |      \n",
      " |      By default, missing values are not considered, and the mode of wings\n",
      " |      are both 0 and 2. Because the resulting DataFrame has two rows,\n",
      " |      the second row of ``species`` and ``legs`` contains ``NaN``.\n",
      " |      \n",
      " |      >>> df.mode()\n",
      " |        species  legs  wings\n",
      " |      0    bird   2.0    0.0\n",
      " |      1     NaN   NaN    2.0\n",
      " |      \n",
      " |      Setting ``dropna=False`` ``NaN`` values are considered and they can be\n",
      " |      the mode (like for wings).\n",
      " |      \n",
      " |      >>> df.mode(dropna=False)\n",
      " |        species  legs  wings\n",
      " |      0    bird     2    NaN\n",
      " |      \n",
      " |      Setting ``numeric_only=True``, only the mode of numeric columns is\n",
      " |      computed, and columns of other types are ignored.\n",
      " |      \n",
      " |      >>> df.mode(numeric_only=True)\n",
      " |         legs  wings\n",
      " |      0   2.0    0.0\n",
      " |      1   NaN    2.0\n",
      " |      \n",
      " |      To compute the mode over columns and not rows, use the axis parameter:\n",
      " |      \n",
      " |      >>> df.mode(axis='columns', numeric_only=True)\n",
      " |                 0    1\n",
      " |      falcon   2.0  NaN\n",
      " |      horse    4.0  NaN\n",
      " |      spider   0.0  8.0\n",
      " |      ostrich  2.0  NaN\n",
      " |  \n",
      " |  mul(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Multiplication of dataframe and other, element-wise (binary operator `mul`).\n",
      " |      \n",
      " |      Equivalent to ``dataframe * other``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `rmul`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  multiply = mul(self, other, axis='columns', level=None, fill_value=None)\n",
      " |  \n",
      " |  ne(self, other, axis='columns', level=None)\n",
      " |      Get Not equal to of dataframe and other, element-wise (binary operator `ne`).\n",
      " |      \n",
      " |      Among flexible wrappers (`eq`, `ne`, `le`, `lt`, `ge`, `gt`) to comparison\n",
      " |      operators.\n",
      " |      \n",
      " |      Equivalent to `==`, `!=`, `<=`, `<`, `>=`, `>` with support to choose axis\n",
      " |      (rows or columns) and level for comparison.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 'columns'\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns').\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the passed\n",
      " |          MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame of bool\n",
      " |          Result of the comparison.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.eq : Compare DataFrames for equality elementwise.\n",
      " |      DataFrame.ne : Compare DataFrames for inequality elementwise.\n",
      " |      DataFrame.le : Compare DataFrames for less than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.lt : Compare DataFrames for strictly less than\n",
      " |          inequality elementwise.\n",
      " |      DataFrame.ge : Compare DataFrames for greater than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.gt : Compare DataFrames for strictly greater than\n",
      " |          inequality elementwise.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      `NaN` values are considered different (i.e. `NaN` != `NaN`).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'cost': [250, 150, 100],\n",
      " |      ...                    'revenue': [100, 250, 300]},\n",
      " |      ...                   index=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |         cost  revenue\n",
      " |      A   250      100\n",
      " |      B   150      250\n",
      " |      C   100      300\n",
      " |      \n",
      " |      Comparison with a scalar, using either the operator or method:\n",
      " |      \n",
      " |      >>> df == 100\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      >>> df.eq(100)\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      When `other` is a :class:`Series`, the columns of a DataFrame are aligned\n",
      " |      with the index of `other` and broadcast:\n",
      " |      \n",
      " |      >>> df != pd.Series([100, 250], index=[\"cost\", \"revenue\"])\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B   True    False\n",
      " |      C  False     True\n",
      " |      \n",
      " |      Use the method to control the broadcast axis:\n",
      " |      \n",
      " |      >>> df.ne(pd.Series([100, 300], index=[\"A\", \"D\"]), axis='index')\n",
      " |         cost  revenue\n",
      " |      A  True    False\n",
      " |      B  True     True\n",
      " |      C  True     True\n",
      " |      D  True     True\n",
      " |      \n",
      " |      When comparing to an arbitrary sequence, the number of columns must\n",
      " |      match the number elements in `other`:\n",
      " |      \n",
      " |      >>> df == [250, 100]\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B  False    False\n",
      " |      C  False    False\n",
      " |      \n",
      " |      Use the method to control the axis:\n",
      " |      \n",
      " |      >>> df.eq([250, 250, 100], axis='index')\n",
      " |          cost  revenue\n",
      " |      A   True    False\n",
      " |      B  False     True\n",
      " |      C   True    False\n",
      " |      \n",
      " |      Compare to a DataFrame of different shape.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'revenue': [300, 250, 100, 150]},\n",
      " |      ...                      index=['A', 'B', 'C', 'D'])\n",
      " |      >>> other\n",
      " |         revenue\n",
      " |      A      300\n",
      " |      B      250\n",
      " |      C      100\n",
      " |      D      150\n",
      " |      \n",
      " |      >>> df.gt(other)\n",
      " |          cost  revenue\n",
      " |      A  False    False\n",
      " |      B  False    False\n",
      " |      C  False     True\n",
      " |      D  False    False\n",
      " |      \n",
      " |      Compare to a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],\n",
      " |      ...                              'revenue': [100, 250, 300, 200, 175, 225]},\n",
      " |      ...                             index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],\n",
      " |      ...                                    ['A', 'B', 'C', 'A', 'B', 'C']])\n",
      " |      >>> df_multindex\n",
      " |            cost  revenue\n",
      " |      Q1 A   250      100\n",
      " |         B   150      250\n",
      " |         C   100      300\n",
      " |      Q2 A   150      200\n",
      " |         B   300      175\n",
      " |         C   220      225\n",
      " |      \n",
      " |      >>> df.le(df_multindex, level=1)\n",
      " |             cost  revenue\n",
      " |      Q1 A   True     True\n",
      " |         B   True     True\n",
      " |         C   True     True\n",
      " |      Q2 A  False     True\n",
      " |         B   True    False\n",
      " |         C   True    False\n",
      " |  \n",
      " |  nlargest(self, n: 'int', columns: 'IndexLabel', keep: 'str' = 'first') -> 'DataFrame'\n",
      " |      Return the first `n` rows ordered by `columns` in descending order.\n",
      " |      \n",
      " |      Return the first `n` rows with the largest values in `columns`, in\n",
      " |      descending order. The columns that are not specified are returned as\n",
      " |      well, but not used for ordering.\n",
      " |      \n",
      " |      This method is equivalent to\n",
      " |      ``df.sort_values(columns, ascending=False).head(n)``, but more\n",
      " |      performant.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int\n",
      " |          Number of rows to return.\n",
      " |      columns : label or list of labels\n",
      " |          Column label(s) to order by.\n",
      " |      keep : {'first', 'last', 'all'}, default 'first'\n",
      " |          Where there are duplicate values:\n",
      " |      \n",
      " |          - ``first`` : prioritize the first occurrence(s)\n",
      " |          - ``last`` : prioritize the last occurrence(s)\n",
      " |          - ``all`` : do not drop any duplicates, even it means\n",
      " |            selecting more than `n` items.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The first `n` rows ordered by the given columns in descending\n",
      " |          order.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.nsmallest : Return the first `n` rows ordered by `columns` in\n",
      " |          ascending order.\n",
      " |      DataFrame.sort_values : Sort DataFrame by the values.\n",
      " |      DataFrame.head : Return the first `n` rows without re-ordering.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This function cannot be used with all column types. For example, when\n",
      " |      specifying columns with `object` or `category` dtypes, ``TypeError`` is\n",
      " |      raised.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'population': [59000000, 65000000, 434000,\n",
      " |      ...                                   434000, 434000, 337000, 11300,\n",
      " |      ...                                   11300, 11300],\n",
      " |      ...                    'GDP': [1937894, 2583560 , 12011, 4520, 12128,\n",
      " |      ...                            17036, 182, 38, 311],\n",
      " |      ...                    'alpha-2': [\"IT\", \"FR\", \"MT\", \"MV\", \"BN\",\n",
      " |      ...                                \"IS\", \"NR\", \"TV\", \"AI\"]},\n",
      " |      ...                   index=[\"Italy\", \"France\", \"Malta\",\n",
      " |      ...                          \"Maldives\", \"Brunei\", \"Iceland\",\n",
      " |      ...                          \"Nauru\", \"Tuvalu\", \"Anguilla\"])\n",
      " |      >>> df\n",
      " |                population      GDP alpha-2\n",
      " |      Italy       59000000  1937894      IT\n",
      " |      France      65000000  2583560      FR\n",
      " |      Malta         434000    12011      MT\n",
      " |      Maldives      434000     4520      MV\n",
      " |      Brunei        434000    12128      BN\n",
      " |      Iceland       337000    17036      IS\n",
      " |      Nauru          11300      182      NR\n",
      " |      Tuvalu         11300       38      TV\n",
      " |      Anguilla       11300      311      AI\n",
      " |      \n",
      " |      In the following example, we will use ``nlargest`` to select the three\n",
      " |      rows having the largest values in column \"population\".\n",
      " |      \n",
      " |      >>> df.nlargest(3, 'population')\n",
      " |              population      GDP alpha-2\n",
      " |      France    65000000  2583560      FR\n",
      " |      Italy     59000000  1937894      IT\n",
      " |      Malta       434000    12011      MT\n",
      " |      \n",
      " |      When using ``keep='last'``, ties are resolved in reverse order:\n",
      " |      \n",
      " |      >>> df.nlargest(3, 'population', keep='last')\n",
      " |              population      GDP alpha-2\n",
      " |      France    65000000  2583560      FR\n",
      " |      Italy     59000000  1937894      IT\n",
      " |      Brunei      434000    12128      BN\n",
      " |      \n",
      " |      When using ``keep='all'``, all duplicate items are maintained:\n",
      " |      \n",
      " |      >>> df.nlargest(3, 'population', keep='all')\n",
      " |                population      GDP alpha-2\n",
      " |      France      65000000  2583560      FR\n",
      " |      Italy       59000000  1937894      IT\n",
      " |      Malta         434000    12011      MT\n",
      " |      Maldives      434000     4520      MV\n",
      " |      Brunei        434000    12128      BN\n",
      " |      \n",
      " |      To order by the largest values in column \"population\" and then \"GDP\",\n",
      " |      we can specify multiple columns like in the next example.\n",
      " |      \n",
      " |      >>> df.nlargest(3, ['population', 'GDP'])\n",
      " |              population      GDP alpha-2\n",
      " |      France    65000000  2583560      FR\n",
      " |      Italy     59000000  1937894      IT\n",
      " |      Brunei      434000    12128      BN\n",
      " |  \n",
      " |  notna(self) -> 'DataFrame'\n",
      " |      Detect existing (non-missing) values.\n",
      " |      \n",
      " |      Return a boolean same-sized object indicating if the values are not NA.\n",
      " |      Non-missing values get mapped to True. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, get mapped to False\n",
      " |      values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Mask of bool values for each element in DataFrame that\n",
      " |          indicates whether an element is not an NA value.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.notnull : Alias of notna.\n",
      " |      DataFrame.isna : Boolean inverse of notna.\n",
      " |      DataFrame.dropna : Omit axes labels with missing values.\n",
      " |      notna : Top-level notna.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are not NA.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(dict(age=[5, 6, np.NaN],\n",
      " |      ...                    born=[pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                          pd.Timestamp('1940-04-25')],\n",
      " |      ...                    name=['Alfred', 'Batman', ''],\n",
      " |      ...                    toy=[None, 'Batmobile', 'Joker']))\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |      \n",
      " |      >>> df.notna()\n",
      " |           age   born  name    toy\n",
      " |      0   True  False  True  False\n",
      " |      1   True   True  True   True\n",
      " |      2  False   True  True   True\n",
      " |      \n",
      " |      Show which entries in a Series are not NA.\n",
      " |      \n",
      " |      >>> ser = pd.Series([5, 6, np.NaN])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> ser.notna()\n",
      " |      0     True\n",
      " |      1     True\n",
      " |      2    False\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  notnull(self) -> 'DataFrame'\n",
      " |      DataFrame.notnull is an alias for DataFrame.notna.\n",
      " |      \n",
      " |      Detect existing (non-missing) values.\n",
      " |      \n",
      " |      Return a boolean same-sized object indicating if the values are not NA.\n",
      " |      Non-missing values get mapped to True. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, get mapped to False\n",
      " |      values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Mask of bool values for each element in DataFrame that\n",
      " |          indicates whether an element is not an NA value.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.notnull : Alias of notna.\n",
      " |      DataFrame.isna : Boolean inverse of notna.\n",
      " |      DataFrame.dropna : Omit axes labels with missing values.\n",
      " |      notna : Top-level notna.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are not NA.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(dict(age=[5, 6, np.NaN],\n",
      " |      ...                    born=[pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                          pd.Timestamp('1940-04-25')],\n",
      " |      ...                    name=['Alfred', 'Batman', ''],\n",
      " |      ...                    toy=[None, 'Batmobile', 'Joker']))\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |      \n",
      " |      >>> df.notna()\n",
      " |           age   born  name    toy\n",
      " |      0   True  False  True  False\n",
      " |      1   True   True  True   True\n",
      " |      2  False   True  True   True\n",
      " |      \n",
      " |      Show which entries in a Series are not NA.\n",
      " |      \n",
      " |      >>> ser = pd.Series([5, 6, np.NaN])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> ser.notna()\n",
      " |      0     True\n",
      " |      1     True\n",
      " |      2    False\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  nsmallest(self, n: 'int', columns: 'IndexLabel', keep: 'str' = 'first') -> 'DataFrame'\n",
      " |      Return the first `n` rows ordered by `columns` in ascending order.\n",
      " |      \n",
      " |      Return the first `n` rows with the smallest values in `columns`, in\n",
      " |      ascending order. The columns that are not specified are returned as\n",
      " |      well, but not used for ordering.\n",
      " |      \n",
      " |      This method is equivalent to\n",
      " |      ``df.sort_values(columns, ascending=True).head(n)``, but more\n",
      " |      performant.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int\n",
      " |          Number of items to retrieve.\n",
      " |      columns : list or str\n",
      " |          Column name or names to order by.\n",
      " |      keep : {'first', 'last', 'all'}, default 'first'\n",
      " |          Where there are duplicate values:\n",
      " |      \n",
      " |          - ``first`` : take the first occurrence.\n",
      " |          - ``last`` : take the last occurrence.\n",
      " |          - ``all`` : do not drop any duplicates, even it means\n",
      " |            selecting more than `n` items.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.nlargest : Return the first `n` rows ordered by `columns` in\n",
      " |          descending order.\n",
      " |      DataFrame.sort_values : Sort DataFrame by the values.\n",
      " |      DataFrame.head : Return the first `n` rows without re-ordering.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'population': [59000000, 65000000, 434000,\n",
      " |      ...                                   434000, 434000, 337000, 337000,\n",
      " |      ...                                   11300, 11300],\n",
      " |      ...                    'GDP': [1937894, 2583560 , 12011, 4520, 12128,\n",
      " |      ...                            17036, 182, 38, 311],\n",
      " |      ...                    'alpha-2': [\"IT\", \"FR\", \"MT\", \"MV\", \"BN\",\n",
      " |      ...                                \"IS\", \"NR\", \"TV\", \"AI\"]},\n",
      " |      ...                   index=[\"Italy\", \"France\", \"Malta\",\n",
      " |      ...                          \"Maldives\", \"Brunei\", \"Iceland\",\n",
      " |      ...                          \"Nauru\", \"Tuvalu\", \"Anguilla\"])\n",
      " |      >>> df\n",
      " |                population      GDP alpha-2\n",
      " |      Italy       59000000  1937894      IT\n",
      " |      France      65000000  2583560      FR\n",
      " |      Malta         434000    12011      MT\n",
      " |      Maldives      434000     4520      MV\n",
      " |      Brunei        434000    12128      BN\n",
      " |      Iceland       337000    17036      IS\n",
      " |      Nauru         337000      182      NR\n",
      " |      Tuvalu         11300       38      TV\n",
      " |      Anguilla       11300      311      AI\n",
      " |      \n",
      " |      In the following example, we will use ``nsmallest`` to select the\n",
      " |      three rows having the smallest values in column \"population\".\n",
      " |      \n",
      " |      >>> df.nsmallest(3, 'population')\n",
      " |                population    GDP alpha-2\n",
      " |      Tuvalu         11300     38      TV\n",
      " |      Anguilla       11300    311      AI\n",
      " |      Iceland       337000  17036      IS\n",
      " |      \n",
      " |      When using ``keep='last'``, ties are resolved in reverse order:\n",
      " |      \n",
      " |      >>> df.nsmallest(3, 'population', keep='last')\n",
      " |                population  GDP alpha-2\n",
      " |      Anguilla       11300  311      AI\n",
      " |      Tuvalu         11300   38      TV\n",
      " |      Nauru         337000  182      NR\n",
      " |      \n",
      " |      When using ``keep='all'``, all duplicate items are maintained:\n",
      " |      \n",
      " |      >>> df.nsmallest(3, 'population', keep='all')\n",
      " |                population    GDP alpha-2\n",
      " |      Tuvalu         11300     38      TV\n",
      " |      Anguilla       11300    311      AI\n",
      " |      Iceland       337000  17036      IS\n",
      " |      Nauru         337000    182      NR\n",
      " |      \n",
      " |      To order by the smallest values in column \"population\" and then \"GDP\", we can\n",
      " |      specify multiple columns like in the next example.\n",
      " |      \n",
      " |      >>> df.nsmallest(3, ['population', 'GDP'])\n",
      " |                population  GDP alpha-2\n",
      " |      Tuvalu         11300   38      TV\n",
      " |      Anguilla       11300  311      AI\n",
      " |      Nauru         337000  182      NR\n",
      " |  \n",
      " |  nunique(self, axis: 'Axis' = 0, dropna: 'bool' = True) -> 'Series'\n",
      " |      Count number of distinct elements in specified axis.\n",
      " |      \n",
      " |      Return Series with number of distinct elements. Can ignore NaN\n",
      " |      values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to use. 0 or 'index' for row-wise, 1 or 'columns' for\n",
      " |          column-wise.\n",
      " |      dropna : bool, default True\n",
      " |          Don't include NaN in the counts.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.nunique: Method nunique for Series.\n",
      " |      DataFrame.count: Count non-NA cells for each column or row.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [4, 5, 6], 'B': [4, 1, 1]})\n",
      " |      >>> df.nunique()\n",
      " |      A    3\n",
      " |      B    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df.nunique(axis=1)\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    2\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  pivot(self, index=None, columns=None, values=None) -> 'DataFrame'\n",
      " |      Return reshaped DataFrame organized by given index / column values.\n",
      " |      \n",
      " |      Reshape data (produce a \"pivot\" table) based on column values. Uses\n",
      " |      unique values from specified `index` / `columns` to form axes of the\n",
      " |      resulting DataFrame. This function does not support data\n",
      " |      aggregation, multiple values will result in a MultiIndex in the\n",
      " |      columns. See the :ref:`User Guide <reshaping>` for more on reshaping.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : str or object or a list of str, optional\n",
      " |          Column to use to make new frame's index. If None, uses\n",
      " |          existing index.\n",
      " |      \n",
      " |          .. versionchanged:: 1.1.0\n",
      " |             Also accept list of index names.\n",
      " |      \n",
      " |      columns : str or object or a list of str\n",
      " |          Column to use to make new frame's columns.\n",
      " |      \n",
      " |          .. versionchanged:: 1.1.0\n",
      " |             Also accept list of columns names.\n",
      " |      \n",
      " |      values : str, object or a list of the previous, optional\n",
      " |          Column(s) to use for populating new frame's values. If not\n",
      " |          specified, all remaining columns will be used and the result will\n",
      " |          have hierarchically indexed columns.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Returns reshaped DataFrame.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError:\n",
      " |          When there are any `index`, `columns` combinations with multiple\n",
      " |          values. `DataFrame.pivot_table` when you need to aggregate.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.pivot_table : Generalization of pivot that can handle\n",
      " |          duplicate values for one index/column pair.\n",
      " |      DataFrame.unstack : Pivot based on the index values instead of a\n",
      " |          column.\n",
      " |      wide_to_long : Wide panel to long format. Less flexible but more\n",
      " |          user-friendly than melt.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For finer-tuned control, see hierarchical indexing documentation along\n",
      " |      with the related stack/unstack methods.\n",
      " |      \n",
      " |      Reference :ref:`the user guide <reshaping.pivot>` for more examples.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'foo': ['one', 'one', 'one', 'two', 'two',\n",
      " |      ...                            'two'],\n",
      " |      ...                    'bar': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
      " |      ...                    'baz': [1, 2, 3, 4, 5, 6],\n",
      " |      ...                    'zoo': ['x', 'y', 'z', 'q', 'w', 't']})\n",
      " |      >>> df\n",
      " |          foo   bar  baz  zoo\n",
      " |      0   one   A    1    x\n",
      " |      1   one   B    2    y\n",
      " |      2   one   C    3    z\n",
      " |      3   two   A    4    q\n",
      " |      4   two   B    5    w\n",
      " |      5   two   C    6    t\n",
      " |      \n",
      " |      >>> df.pivot(index='foo', columns='bar', values='baz')\n",
      " |      bar  A   B   C\n",
      " |      foo\n",
      " |      one  1   2   3\n",
      " |      two  4   5   6\n",
      " |      \n",
      " |      >>> df.pivot(index='foo', columns='bar')['baz']\n",
      " |      bar  A   B   C\n",
      " |      foo\n",
      " |      one  1   2   3\n",
      " |      two  4   5   6\n",
      " |      \n",
      " |      >>> df.pivot(index='foo', columns='bar', values=['baz', 'zoo'])\n",
      " |            baz       zoo\n",
      " |      bar   A  B  C   A  B  C\n",
      " |      foo\n",
      " |      one   1  2  3   x  y  z\n",
      " |      two   4  5  6   q  w  t\n",
      " |      \n",
      " |      You could also assign a list of column names or a list of index names.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...        \"lev1\": [1, 1, 1, 2, 2, 2],\n",
      " |      ...        \"lev2\": [1, 1, 2, 1, 1, 2],\n",
      " |      ...        \"lev3\": [1, 2, 1, 2, 1, 2],\n",
      " |      ...        \"lev4\": [1, 2, 3, 4, 5, 6],\n",
      " |      ...        \"values\": [0, 1, 2, 3, 4, 5]})\n",
      " |      >>> df\n",
      " |          lev1 lev2 lev3 lev4 values\n",
      " |      0   1    1    1    1    0\n",
      " |      1   1    1    2    2    1\n",
      " |      2   1    2    1    3    2\n",
      " |      3   2    1    2    4    3\n",
      " |      4   2    1    1    5    4\n",
      " |      5   2    2    2    6    5\n",
      " |      \n",
      " |      >>> df.pivot(index=\"lev1\", columns=[\"lev2\", \"lev3\"],values=\"values\")\n",
      " |      lev2    1         2\n",
      " |      lev3    1    2    1    2\n",
      " |      lev1\n",
      " |      1     0.0  1.0  2.0  NaN\n",
      " |      2     4.0  3.0  NaN  5.0\n",
      " |      \n",
      " |      >>> df.pivot(index=[\"lev1\", \"lev2\"], columns=[\"lev3\"],values=\"values\")\n",
      " |            lev3    1    2\n",
      " |      lev1  lev2\n",
      " |         1     1  0.0  1.0\n",
      " |               2  2.0  NaN\n",
      " |         2     1  4.0  3.0\n",
      " |               2  NaN  5.0\n",
      " |      \n",
      " |      A ValueError is raised if there are any duplicates.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"foo\": ['one', 'one', 'two', 'two'],\n",
      " |      ...                    \"bar\": ['A', 'A', 'B', 'C'],\n",
      " |      ...                    \"baz\": [1, 2, 3, 4]})\n",
      " |      >>> df\n",
      " |         foo bar  baz\n",
      " |      0  one   A    1\n",
      " |      1  one   A    2\n",
      " |      2  two   B    3\n",
      " |      3  two   C    4\n",
      " |      \n",
      " |      Notice that the first two rows are the same for our `index`\n",
      " |      and `columns` arguments.\n",
      " |      \n",
      " |      >>> df.pivot(index='foo', columns='bar', values='baz')\n",
      " |      Traceback (most recent call last):\n",
      " |         ...\n",
      " |      ValueError: Index contains duplicate entries, cannot reshape\n",
      " |  \n",
      " |  pivot_table(self, values=None, index=None, columns=None, aggfunc='mean', fill_value=None, margins=False, dropna=True, margins_name='All', observed=False, sort=True) -> 'DataFrame'\n",
      " |      Create a spreadsheet-style pivot table as a DataFrame.\n",
      " |      \n",
      " |      The levels in the pivot table will be stored in MultiIndex objects\n",
      " |      (hierarchical indexes) on the index and columns of the result DataFrame.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      values : column to aggregate, optional\n",
      " |      index : column, Grouper, array, or list of the previous\n",
      " |          If an array is passed, it must be the same length as the data. The\n",
      " |          list can contain any of the other types (except list).\n",
      " |          Keys to group by on the pivot table index.  If an array is passed,\n",
      " |          it is being used as the same manner as column values.\n",
      " |      columns : column, Grouper, array, or list of the previous\n",
      " |          If an array is passed, it must be the same length as the data. The\n",
      " |          list can contain any of the other types (except list).\n",
      " |          Keys to group by on the pivot table column.  If an array is passed,\n",
      " |          it is being used as the same manner as column values.\n",
      " |      aggfunc : function, list of functions, dict, default numpy.mean\n",
      " |          If list of functions passed, the resulting pivot table will have\n",
      " |          hierarchical columns whose top level are the function names\n",
      " |          (inferred from the function objects themselves)\n",
      " |          If dict is passed, the key is column to aggregate and value\n",
      " |          is function or list of functions.\n",
      " |      fill_value : scalar, default None\n",
      " |          Value to replace missing values with (in the resulting pivot table,\n",
      " |          after aggregation).\n",
      " |      margins : bool, default False\n",
      " |          Add all row / columns (e.g. for subtotal / grand totals).\n",
      " |      dropna : bool, default True\n",
      " |          Do not include columns whose entries are all NaN.\n",
      " |      margins_name : str, default 'All'\n",
      " |          Name of the row / column that will contain the totals\n",
      " |          when margins is True.\n",
      " |      observed : bool, default False\n",
      " |          This only applies if any of the groupers are Categoricals.\n",
      " |          If True: only show observed values for categorical groupers.\n",
      " |          If False: show all values for categorical groupers.\n",
      " |      \n",
      " |          .. versionchanged:: 0.25.0\n",
      " |      \n",
      " |      sort : bool, default True\n",
      " |          Specifies if the result should be sorted.\n",
      " |      \n",
      " |          .. versionadded:: 1.3.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          An Excel style pivot table.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.pivot : Pivot without aggregation that can handle\n",
      " |          non-numeric data.\n",
      " |      DataFrame.melt: Unpivot a DataFrame from wide to long format,\n",
      " |          optionally leaving identifiers set.\n",
      " |      wide_to_long : Wide panel to long format. Less flexible but more\n",
      " |          user-friendly than melt.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Reference :ref:`the user guide <reshaping.pivot>` for more examples.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"A\": [\"foo\", \"foo\", \"foo\", \"foo\", \"foo\",\n",
      " |      ...                          \"bar\", \"bar\", \"bar\", \"bar\"],\n",
      " |      ...                    \"B\": [\"one\", \"one\", \"one\", \"two\", \"two\",\n",
      " |      ...                          \"one\", \"one\", \"two\", \"two\"],\n",
      " |      ...                    \"C\": [\"small\", \"large\", \"large\", \"small\",\n",
      " |      ...                          \"small\", \"large\", \"small\", \"small\",\n",
      " |      ...                          \"large\"],\n",
      " |      ...                    \"D\": [1, 2, 2, 3, 3, 4, 5, 6, 7],\n",
      " |      ...                    \"E\": [2, 4, 5, 5, 6, 6, 8, 9, 9]})\n",
      " |      >>> df\n",
      " |           A    B      C  D  E\n",
      " |      0  foo  one  small  1  2\n",
      " |      1  foo  one  large  2  4\n",
      " |      2  foo  one  large  2  5\n",
      " |      3  foo  two  small  3  5\n",
      " |      4  foo  two  small  3  6\n",
      " |      5  bar  one  large  4  6\n",
      " |      6  bar  one  small  5  8\n",
      " |      7  bar  two  small  6  9\n",
      " |      8  bar  two  large  7  9\n",
      " |      \n",
      " |      This first example aggregates values by taking the sum.\n",
      " |      \n",
      " |      >>> table = pd.pivot_table(df, values='D', index=['A', 'B'],\n",
      " |      ...                     columns=['C'], aggfunc=np.sum)\n",
      " |      >>> table\n",
      " |      C        large  small\n",
      " |      A   B\n",
      " |      bar one    4.0    5.0\n",
      " |          two    7.0    6.0\n",
      " |      foo one    4.0    1.0\n",
      " |          two    NaN    6.0\n",
      " |      \n",
      " |      We can also fill missing values using the `fill_value` parameter.\n",
      " |      \n",
      " |      >>> table = pd.pivot_table(df, values='D', index=['A', 'B'],\n",
      " |      ...                     columns=['C'], aggfunc=np.sum, fill_value=0)\n",
      " |      >>> table\n",
      " |      C        large  small\n",
      " |      A   B\n",
      " |      bar one      4      5\n",
      " |          two      7      6\n",
      " |      foo one      4      1\n",
      " |          two      0      6\n",
      " |      \n",
      " |      The next example aggregates by taking the mean across multiple columns.\n",
      " |      \n",
      " |      >>> table = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],\n",
      " |      ...                     aggfunc={'D': np.mean,\n",
      " |      ...                              'E': np.mean})\n",
      " |      >>> table\n",
      " |                      D         E\n",
      " |      A   C\n",
      " |      bar large  5.500000  7.500000\n",
      " |          small  5.500000  8.500000\n",
      " |      foo large  2.000000  4.500000\n",
      " |          small  2.333333  4.333333\n",
      " |      \n",
      " |      We can also calculate multiple types of aggregations for any given\n",
      " |      value column.\n",
      " |      \n",
      " |      >>> table = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],\n",
      " |      ...                     aggfunc={'D': np.mean,\n",
      " |      ...                              'E': [min, max, np.mean]})\n",
      " |      >>> table\n",
      " |                        D   E\n",
      " |                     mean max      mean  min\n",
      " |      A   C\n",
      " |      bar large  5.500000   9  7.500000    6\n",
      " |          small  5.500000   9  8.500000    8\n",
      " |      foo large  2.000000   5  4.500000    4\n",
      " |          small  2.333333   6  4.333333    2\n",
      " |  \n",
      " |  pop(self, item: 'Hashable') -> 'Series'\n",
      " |      Return item and drop from frame. Raise KeyError if not found.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      item : label\n",
      " |          Label of column to be popped.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('falcon', 'bird', 389.0),\n",
      " |      ...                    ('parrot', 'bird', 24.0),\n",
      " |      ...                    ('lion', 'mammal', 80.5),\n",
      " |      ...                    ('monkey', 'mammal', np.nan)],\n",
      " |      ...                   columns=('name', 'class', 'max_speed'))\n",
      " |      >>> df\n",
      " |           name   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      1  parrot    bird       24.0\n",
      " |      2    lion  mammal       80.5\n",
      " |      3  monkey  mammal        NaN\n",
      " |      \n",
      " |      >>> df.pop('class')\n",
      " |      0      bird\n",
      " |      1      bird\n",
      " |      2    mammal\n",
      " |      3    mammal\n",
      " |      Name: class, dtype: object\n",
      " |      \n",
      " |      >>> df\n",
      " |           name  max_speed\n",
      " |      0  falcon      389.0\n",
      " |      1  parrot       24.0\n",
      " |      2    lion       80.5\n",
      " |      3  monkey        NaN\n",
      " |  \n",
      " |  pow(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Exponential power of dataframe and other, element-wise (binary operator `pow`).\n",
      " |      \n",
      " |      Equivalent to ``dataframe ** other``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `rpow`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  prod(self, axis=None, skipna=True, level=None, numeric_only=None, min_count=0, **kwargs)\n",
      " |      Return the product of the values over the requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      min_count : int, default 0\n",
      " |          The required number of valid values to perform the operation. If fewer than\n",
      " |          ``min_count`` non-NA values are present the result will be NA.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sum : Return the sum.\n",
      " |      Series.min : Return the minimum.\n",
      " |      Series.max : Return the maximum.\n",
      " |      Series.idxmin : Return the index of the minimum.\n",
      " |      Series.idxmax : Return the index of the maximum.\n",
      " |      DataFrame.sum : Return the sum over the requested axis.\n",
      " |      DataFrame.min : Return the minimum over the requested axis.\n",
      " |      DataFrame.max : Return the maximum over the requested axis.\n",
      " |      DataFrame.idxmin : Return the index of the minimum over the requested axis.\n",
      " |      DataFrame.idxmax : Return the index of the maximum over the requested axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      By default, the product of an empty or all-NA Series is ``1``\n",
      " |      \n",
      " |      >>> pd.Series([], dtype=\"float64\").prod()\n",
      " |      1.0\n",
      " |      \n",
      " |      This can be controlled with the ``min_count`` parameter\n",
      " |      \n",
      " |      >>> pd.Series([], dtype=\"float64\").prod(min_count=1)\n",
      " |      nan\n",
      " |      \n",
      " |      Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and\n",
      " |      empty series identically.\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).prod()\n",
      " |      1.0\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).prod(min_count=1)\n",
      " |      nan\n",
      " |  \n",
      " |  product = prod(self, axis=None, skipna=True, level=None, numeric_only=None, min_count=0, **kwargs)\n",
      " |  \n",
      " |  quantile(self, q=0.5, axis: 'Axis' = 0, numeric_only: 'bool' = True, interpolation: 'str' = 'linear')\n",
      " |      Return values at the given quantile over requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      q : float or array-like, default 0.5 (50% quantile)\n",
      " |          Value between 0 <= q <= 1, the quantile(s) to compute.\n",
      " |      axis : {0, 1, 'index', 'columns'}, default 0\n",
      " |          Equals 0 or 'index' for row-wise, 1 or 'columns' for column-wise.\n",
      " |      numeric_only : bool, default True\n",
      " |          If False, the quantile of datetime and timedelta data will be\n",
      " |          computed as well.\n",
      " |      interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}\n",
      " |          This optional parameter specifies the interpolation method to use,\n",
      " |          when the desired quantile lies between two data points `i` and `j`:\n",
      " |      \n",
      " |          * linear: `i + (j - i) * fraction`, where `fraction` is the\n",
      " |            fractional part of the index surrounded by `i` and `j`.\n",
      " |          * lower: `i`.\n",
      " |          * higher: `j`.\n",
      " |          * nearest: `i` or `j` whichever is nearest.\n",
      " |          * midpoint: (`i` + `j`) / 2.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |      \n",
      " |          If ``q`` is an array, a DataFrame will be returned where the\n",
      " |            index is ``q``, the columns are the columns of self, and the\n",
      " |            values are the quantiles.\n",
      " |          If ``q`` is a float, a Series will be returned where the\n",
      " |            index is the columns of self and the values are the quantiles.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.window.Rolling.quantile: Rolling quantile.\n",
      " |      numpy.percentile: Numpy function to compute the percentile.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(np.array([[1, 1], [2, 10], [3, 100], [4, 100]]),\n",
      " |      ...                   columns=['a', 'b'])\n",
      " |      >>> df.quantile(.1)\n",
      " |      a    1.3\n",
      " |      b    3.7\n",
      " |      Name: 0.1, dtype: float64\n",
      " |      >>> df.quantile([.1, .5])\n",
      " |             a     b\n",
      " |      0.1  1.3   3.7\n",
      " |      0.5  2.5  55.0\n",
      " |      \n",
      " |      Specifying `numeric_only=False` will also compute the quantile of\n",
      " |      datetime and timedelta data.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 2],\n",
      " |      ...                    'B': [pd.Timestamp('2010'),\n",
      " |      ...                          pd.Timestamp('2011')],\n",
      " |      ...                    'C': [pd.Timedelta('1 days'),\n",
      " |      ...                          pd.Timedelta('2 days')]})\n",
      " |      >>> df.quantile(0.5, numeric_only=False)\n",
      " |      A                    1.5\n",
      " |      B    2010-07-02 12:00:00\n",
      " |      C        1 days 12:00:00\n",
      " |      Name: 0.5, dtype: object\n",
      " |  \n",
      " |  query(self, expr: 'str', inplace: 'bool' = False, **kwargs)\n",
      " |      Query the columns of a DataFrame with a boolean expression.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      expr : str\n",
      " |          The query string to evaluate.\n",
      " |      \n",
      " |          You can refer to variables\n",
      " |          in the environment by prefixing them with an '@' character like\n",
      " |          ``@a + b``.\n",
      " |      \n",
      " |          You can refer to column names that are not valid Python variable names\n",
      " |          by surrounding them in backticks. Thus, column names containing spaces\n",
      " |          or punctuations (besides underscores) or starting with digits must be\n",
      " |          surrounded by backticks. (For example, a column named \"Area (cm^2)\" would\n",
      " |          be referenced as ```Area (cm^2)```). Column names which are Python keywords\n",
      " |          (like \"list\", \"for\", \"import\", etc) cannot be used.\n",
      " |      \n",
      " |          For example, if one of your columns is called ``a a`` and you want\n",
      " |          to sum it with ``b``, your query should be ```a a` + b``.\n",
      " |      \n",
      " |          .. versionadded:: 0.25.0\n",
      " |              Backtick quoting introduced.\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |              Expanding functionality of backtick quoting for more than only spaces.\n",
      " |      \n",
      " |      inplace : bool\n",
      " |          Whether the query should modify the data in place or return\n",
      " |          a modified copy.\n",
      " |      **kwargs\n",
      " |          See the documentation for :func:`eval` for complete details\n",
      " |          on the keyword arguments accepted by :meth:`DataFrame.query`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          DataFrame resulting from the provided query expression or\n",
      " |          None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      eval : Evaluate a string describing operations on\n",
      " |          DataFrame columns.\n",
      " |      DataFrame.eval : Evaluate a string describing operations on\n",
      " |          DataFrame columns.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The result of the evaluation of this expression is first passed to\n",
      " |      :attr:`DataFrame.loc` and if that fails because of a\n",
      " |      multidimensional key (e.g., a DataFrame) then the result will be passed\n",
      " |      to :meth:`DataFrame.__getitem__`.\n",
      " |      \n",
      " |      This method uses the top-level :func:`eval` function to\n",
      " |      evaluate the passed query.\n",
      " |      \n",
      " |      The :meth:`~pandas.DataFrame.query` method uses a slightly\n",
      " |      modified Python syntax by default. For example, the ``&`` and ``|``\n",
      " |      (bitwise) operators have the precedence of their boolean cousins,\n",
      " |      :keyword:`and` and :keyword:`or`. This *is* syntactically valid Python,\n",
      " |      however the semantics are different.\n",
      " |      \n",
      " |      You can change the semantics of the expression by passing the keyword\n",
      " |      argument ``parser='python'``. This enforces the same semantics as\n",
      " |      evaluation in Python space. Likewise, you can pass ``engine='python'``\n",
      " |      to evaluate an expression using Python itself as a backend. This is not\n",
      " |      recommended as it is inefficient compared to using ``numexpr`` as the\n",
      " |      engine.\n",
      " |      \n",
      " |      The :attr:`DataFrame.index` and\n",
      " |      :attr:`DataFrame.columns` attributes of the\n",
      " |      :class:`~pandas.DataFrame` instance are placed in the query namespace\n",
      " |      by default, which allows you to treat both the index and columns of the\n",
      " |      frame as a column in the frame.\n",
      " |      The identifier ``index`` is used for the frame index; you can also\n",
      " |      use the name of the index to identify it in a query. Please note that\n",
      " |      Python keywords may not be used as identifiers.\n",
      " |      \n",
      " |      For further details and examples see the ``query`` documentation in\n",
      " |      :ref:`indexing <indexing.query>`.\n",
      " |      \n",
      " |      *Backtick quoted variables*\n",
      " |      \n",
      " |      Backtick quoted variables are parsed as literal Python code and\n",
      " |      are converted internally to a Python valid identifier.\n",
      " |      This can lead to the following problems.\n",
      " |      \n",
      " |      During parsing a number of disallowed characters inside the backtick\n",
      " |      quoted string are replaced by strings that are allowed as a Python identifier.\n",
      " |      These characters include all operators in Python, the space character, the\n",
      " |      question mark, the exclamation mark, the dollar sign, and the euro sign.\n",
      " |      For other characters that fall outside the ASCII range (U+0001..U+007F)\n",
      " |      and those that are not further specified in PEP 3131,\n",
      " |      the query parser will raise an error.\n",
      " |      This excludes whitespace different than the space character,\n",
      " |      but also the hashtag (as it is used for comments) and the backtick\n",
      " |      itself (backtick can also not be escaped).\n",
      " |      \n",
      " |      In a special case, quotes that make a pair around a backtick can\n",
      " |      confuse the parser.\n",
      " |      For example, ```it's` > `that's``` will raise an error,\n",
      " |      as it forms a quoted string (``'s > `that'``) with a backtick inside.\n",
      " |      \n",
      " |      See also the Python documentation about lexical analysis\n",
      " |      (https://docs.python.org/3/reference/lexical_analysis.html)\n",
      " |      in combination with the source code in :mod:`pandas.core.computation.parsing`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': range(1, 6),\n",
      " |      ...                    'B': range(10, 0, -2),\n",
      " |      ...                    'C C': range(10, 5, -1)})\n",
      " |      >>> df\n",
      " |         A   B  C C\n",
      " |      0  1  10   10\n",
      " |      1  2   8    9\n",
      " |      2  3   6    8\n",
      " |      3  4   4    7\n",
      " |      4  5   2    6\n",
      " |      >>> df.query('A > B')\n",
      " |         A  B  C C\n",
      " |      4  5  2    6\n",
      " |      \n",
      " |      The previous expression is equivalent to\n",
      " |      \n",
      " |      >>> df[df.A > df.B]\n",
      " |         A  B  C C\n",
      " |      4  5  2    6\n",
      " |      \n",
      " |      For columns with spaces in their name, you can use backtick quoting.\n",
      " |      \n",
      " |      >>> df.query('B == `C C`')\n",
      " |         A   B  C C\n",
      " |      0  1  10   10\n",
      " |      \n",
      " |      The previous expression is equivalent to\n",
      " |      \n",
      " |      >>> df[df.B == df['C C']]\n",
      " |         A   B  C C\n",
      " |      0  1  10   10\n",
      " |  \n",
      " |  radd(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Addition of dataframe and other, element-wise (binary operator `radd`).\n",
      " |      \n",
      " |      Equivalent to ``other + dataframe``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `add`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  rdiv = rtruediv(self, other, axis='columns', level=None, fill_value=None)\n",
      " |  \n",
      " |  reindex(self, labels=None, index=None, columns=None, axis=None, method=None, copy=True, level=None, fill_value=nan, limit=None, tolerance=None)\n",
      " |      Conform Series/DataFrame to new index with optional filling logic.\n",
      " |      \n",
      " |      Places NA/NaN in locations having no value in the previous index. A new object\n",
      " |      is produced unless the new index is equivalent to the current one and\n",
      " |      ``copy=False``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      \n",
      " |      keywords for axes : array-like, optional\n",
      " |          New labels / index to conform to, should be specified using\n",
      " |          keywords. Preferably an Index object to avoid duplicating data.\n",
      " |      \n",
      " |      method : {None, 'backfill'/'bfill', 'pad'/'ffill', 'nearest'}\n",
      " |          Method to use for filling holes in reindexed DataFrame.\n",
      " |          Please note: this is only applicable to DataFrames/Series with a\n",
      " |          monotonically increasing/decreasing index.\n",
      " |      \n",
      " |          * None (default): don't fill gaps\n",
      " |          * pad / ffill: Propagate last valid observation forward to next\n",
      " |            valid.\n",
      " |          * backfill / bfill: Use next valid observation to fill gap.\n",
      " |          * nearest: Use nearest valid observations to fill gap.\n",
      " |      \n",
      " |      copy : bool, default True\n",
      " |          Return a new object, even if the passed indexes are the same.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : scalar, default np.NaN\n",
      " |          Value to use for missing values. Defaults to NaN, but can be any\n",
      " |          \"compatible\" value.\n",
      " |      limit : int, default None\n",
      " |          Maximum number of consecutive elements to forward or backward fill.\n",
      " |      tolerance : optional\n",
      " |          Maximum distance between original and new labels for inexact\n",
      " |          matches. The values of the index at the matching locations most\n",
      " |          satisfy the equation ``abs(index[indexer] - target) <= tolerance``.\n",
      " |      \n",
      " |          Tolerance may be a scalar value, which applies the same tolerance\n",
      " |          to all values, or list-like, which applies variable tolerance per\n",
      " |          element. List-like includes list, tuple, array, Series, and must be\n",
      " |          the same size as the index and its dtype must exactly match the\n",
      " |          index's type.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame with changed index.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.set_index : Set row labels.\n",
      " |      DataFrame.reset_index : Remove row labels or move them to new columns.\n",
      " |      DataFrame.reindex_like : Change to same indices as other DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      ``DataFrame.reindex`` supports two calling conventions\n",
      " |      \n",
      " |      * ``(index=index_labels, columns=column_labels, ...)``\n",
      " |      * ``(labels, axis={'index', 'columns'}, ...)``\n",
      " |      \n",
      " |      We *highly* recommend using keyword arguments to clarify your\n",
      " |      intent.\n",
      " |      \n",
      " |      Create a dataframe with some fictional data.\n",
      " |      \n",
      " |      >>> index = ['Firefox', 'Chrome', 'Safari', 'IE10', 'Konqueror']\n",
      " |      >>> df = pd.DataFrame({'http_status': [200, 200, 404, 404, 301],\n",
      " |      ...                   'response_time': [0.04, 0.02, 0.07, 0.08, 1.0]},\n",
      " |      ...                   index=index)\n",
      " |      >>> df\n",
      " |                 http_status  response_time\n",
      " |      Firefox            200           0.04\n",
      " |      Chrome             200           0.02\n",
      " |      Safari             404           0.07\n",
      " |      IE10               404           0.08\n",
      " |      Konqueror          301           1.00\n",
      " |      \n",
      " |      Create a new index and reindex the dataframe. By default\n",
      " |      values in the new index that do not have corresponding\n",
      " |      records in the dataframe are assigned ``NaN``.\n",
      " |      \n",
      " |      >>> new_index = ['Safari', 'Iceweasel', 'Comodo Dragon', 'IE10',\n",
      " |      ...              'Chrome']\n",
      " |      >>> df.reindex(new_index)\n",
      " |                     http_status  response_time\n",
      " |      Safari               404.0           0.07\n",
      " |      Iceweasel              NaN            NaN\n",
      " |      Comodo Dragon          NaN            NaN\n",
      " |      IE10                 404.0           0.08\n",
      " |      Chrome               200.0           0.02\n",
      " |      \n",
      " |      We can fill in the missing values by passing a value to\n",
      " |      the keyword ``fill_value``. Because the index is not monotonically\n",
      " |      increasing or decreasing, we cannot use arguments to the keyword\n",
      " |      ``method`` to fill the ``NaN`` values.\n",
      " |      \n",
      " |      >>> df.reindex(new_index, fill_value=0)\n",
      " |                     http_status  response_time\n",
      " |      Safari                 404           0.07\n",
      " |      Iceweasel                0           0.00\n",
      " |      Comodo Dragon            0           0.00\n",
      " |      IE10                   404           0.08\n",
      " |      Chrome                 200           0.02\n",
      " |      \n",
      " |      >>> df.reindex(new_index, fill_value='missing')\n",
      " |                    http_status response_time\n",
      " |      Safari                404          0.07\n",
      " |      Iceweasel         missing       missing\n",
      " |      Comodo Dragon     missing       missing\n",
      " |      IE10                  404          0.08\n",
      " |      Chrome                200          0.02\n",
      " |      \n",
      " |      We can also reindex the columns.\n",
      " |      \n",
      " |      >>> df.reindex(columns=['http_status', 'user_agent'])\n",
      " |                 http_status  user_agent\n",
      " |      Firefox            200         NaN\n",
      " |      Chrome             200         NaN\n",
      " |      Safari             404         NaN\n",
      " |      IE10               404         NaN\n",
      " |      Konqueror          301         NaN\n",
      " |      \n",
      " |      Or we can use \"axis-style\" keyword arguments\n",
      " |      \n",
      " |      >>> df.reindex(['http_status', 'user_agent'], axis=\"columns\")\n",
      " |                 http_status  user_agent\n",
      " |      Firefox            200         NaN\n",
      " |      Chrome             200         NaN\n",
      " |      Safari             404         NaN\n",
      " |      IE10               404         NaN\n",
      " |      Konqueror          301         NaN\n",
      " |      \n",
      " |      To further illustrate the filling functionality in\n",
      " |      ``reindex``, we will create a dataframe with a\n",
      " |      monotonically increasing index (for example, a sequence\n",
      " |      of dates).\n",
      " |      \n",
      " |      >>> date_index = pd.date_range('1/1/2010', periods=6, freq='D')\n",
      " |      >>> df2 = pd.DataFrame({\"prices\": [100, 101, np.nan, 100, 89, 88]},\n",
      " |      ...                    index=date_index)\n",
      " |      >>> df2\n",
      " |                  prices\n",
      " |      2010-01-01   100.0\n",
      " |      2010-01-02   101.0\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04   100.0\n",
      " |      2010-01-05    89.0\n",
      " |      2010-01-06    88.0\n",
      " |      \n",
      " |      Suppose we decide to expand the dataframe to cover a wider\n",
      " |      date range.\n",
      " |      \n",
      " |      >>> date_index2 = pd.date_range('12/29/2009', periods=10, freq='D')\n",
      " |      >>> df2.reindex(date_index2)\n",
      " |                  prices\n",
      " |      2009-12-29     NaN\n",
      " |      2009-12-30     NaN\n",
      " |      2009-12-31     NaN\n",
      " |      2010-01-01   100.0\n",
      " |      2010-01-02   101.0\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04   100.0\n",
      " |      2010-01-05    89.0\n",
      " |      2010-01-06    88.0\n",
      " |      2010-01-07     NaN\n",
      " |      \n",
      " |      The index entries that did not have a value in the original data frame\n",
      " |      (for example, '2009-12-29') are by default filled with ``NaN``.\n",
      " |      If desired, we can fill in the missing values using one of several\n",
      " |      options.\n",
      " |      \n",
      " |      For example, to back-propagate the last valid value to fill the ``NaN``\n",
      " |      values, pass ``bfill`` as an argument to the ``method`` keyword.\n",
      " |      \n",
      " |      >>> df2.reindex(date_index2, method='bfill')\n",
      " |                  prices\n",
      " |      2009-12-29   100.0\n",
      " |      2009-12-30   100.0\n",
      " |      2009-12-31   100.0\n",
      " |      2010-01-01   100.0\n",
      " |      2010-01-02   101.0\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04   100.0\n",
      " |      2010-01-05    89.0\n",
      " |      2010-01-06    88.0\n",
      " |      2010-01-07     NaN\n",
      " |      \n",
      " |      Please note that the ``NaN`` value present in the original dataframe\n",
      " |      (at index value 2010-01-03) will not be filled by any of the\n",
      " |      value propagation schemes. This is because filling while reindexing\n",
      " |      does not look at dataframe values, but only compares the original and\n",
      " |      desired indexes. If you do want to fill in the ``NaN`` values present\n",
      " |      in the original dataframe, use the ``fillna()`` method.\n",
      " |      \n",
      " |      See the :ref:`user guide <basics.reindexing>` for more.\n",
      " |  \n",
      " |  rename(self, mapper: 'Renamer | None' = None, *, index: 'Renamer | None' = None, columns: 'Renamer | None' = None, axis: 'Axis | None' = None, copy: 'bool' = True, inplace: 'bool' = False, level: 'Level | None' = None, errors: 'str' = 'ignore') -> 'DataFrame | None'\n",
      " |      Alter axes labels.\n",
      " |      \n",
      " |      Function / dict values must be unique (1-to-1). Labels not contained in\n",
      " |      a dict / Series will be left as-is. Extra labels listed don't throw an\n",
      " |      error.\n",
      " |      \n",
      " |      See the :ref:`user guide <basics.rename>` for more.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      mapper : dict-like or function\n",
      " |          Dict-like or function transformations to apply to\n",
      " |          that axis' values. Use either ``mapper`` and ``axis`` to\n",
      " |          specify the axis to target with ``mapper``, or ``index`` and\n",
      " |          ``columns``.\n",
      " |      index : dict-like or function\n",
      " |          Alternative to specifying axis (``mapper, axis=0``\n",
      " |          is equivalent to ``index=mapper``).\n",
      " |      columns : dict-like or function\n",
      " |          Alternative to specifying axis (``mapper, axis=1``\n",
      " |          is equivalent to ``columns=mapper``).\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Axis to target with ``mapper``. Can be either the axis name\n",
      " |          ('index', 'columns') or number (0, 1). The default is 'index'.\n",
      " |      copy : bool, default True\n",
      " |          Also copy underlying data.\n",
      " |      inplace : bool, default False\n",
      " |          Whether to return a new DataFrame. If True then value of copy is\n",
      " |          ignored.\n",
      " |      level : int or level name, default None\n",
      " |          In case of a MultiIndex, only rename labels in the specified\n",
      " |          level.\n",
      " |      errors : {'ignore', 'raise'}, default 'ignore'\n",
      " |          If 'raise', raise a `KeyError` when a dict-like `mapper`, `index`,\n",
      " |          or `columns` contains labels that are not present in the Index\n",
      " |          being transformed.\n",
      " |          If 'ignore', existing keys will be renamed and extra keys will be\n",
      " |          ignored.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          DataFrame with the renamed axis labels or None if ``inplace=True``.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError\n",
      " |          If any of the labels is not found in the selected axis and\n",
      " |          \"errors='raise'\".\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.rename_axis : Set the name of the axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      ``DataFrame.rename`` supports two calling conventions\n",
      " |      \n",
      " |      * ``(index=index_mapper, columns=columns_mapper, ...)``\n",
      " |      * ``(mapper, axis={'index', 'columns'}, ...)``\n",
      " |      \n",
      " |      We *highly* recommend using keyword arguments to clarify your\n",
      " |      intent.\n",
      " |      \n",
      " |      Rename columns using a mapping:\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n",
      " |      >>> df.rename(columns={\"A\": \"a\", \"B\": \"c\"})\n",
      " |         a  c\n",
      " |      0  1  4\n",
      " |      1  2  5\n",
      " |      2  3  6\n",
      " |      \n",
      " |      Rename index using a mapping:\n",
      " |      \n",
      " |      >>> df.rename(index={0: \"x\", 1: \"y\", 2: \"z\"})\n",
      " |         A  B\n",
      " |      x  1  4\n",
      " |      y  2  5\n",
      " |      z  3  6\n",
      " |      \n",
      " |      Cast index labels to a different type:\n",
      " |      \n",
      " |      >>> df.index\n",
      " |      RangeIndex(start=0, stop=3, step=1)\n",
      " |      >>> df.rename(index=str).index\n",
      " |      Index(['0', '1', '2'], dtype='object')\n",
      " |      \n",
      " |      >>> df.rename(columns={\"A\": \"a\", \"B\": \"b\", \"C\": \"c\"}, errors=\"raise\")\n",
      " |      Traceback (most recent call last):\n",
      " |      KeyError: ['C'] not found in axis\n",
      " |      \n",
      " |      Using axis-style parameters:\n",
      " |      \n",
      " |      >>> df.rename(str.lower, axis='columns')\n",
      " |         a  b\n",
      " |      0  1  4\n",
      " |      1  2  5\n",
      " |      2  3  6\n",
      " |      \n",
      " |      >>> df.rename({1: 2, 2: 4}, axis='index')\n",
      " |         A  B\n",
      " |      0  1  4\n",
      " |      2  2  5\n",
      " |      4  3  6\n",
      " |  \n",
      " |  reorder_levels(self, order: 'Sequence[Axis]', axis: 'Axis' = 0) -> 'DataFrame'\n",
      " |      Rearrange index levels using input order. May not drop or duplicate levels.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      order : list of int or list of str\n",
      " |          List representing new level order. Reference level by number\n",
      " |          (position) or by key (label).\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Where to reorder levels.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> data = {\n",
      " |      ...     \"class\": [\"Mammals\", \"Mammals\", \"Reptiles\"],\n",
      " |      ...     \"diet\": [\"Omnivore\", \"Carnivore\", \"Carnivore\"],\n",
      " |      ...     \"species\": [\"Humans\", \"Dogs\", \"Snakes\"],\n",
      " |      ... }\n",
      " |      >>> df = pd.DataFrame(data, columns=[\"class\", \"diet\", \"species\"])\n",
      " |      >>> df = df.set_index([\"class\", \"diet\"])\n",
      " |      >>> df\n",
      " |                                        species\n",
      " |      class      diet\n",
      " |      Mammals    Omnivore                Humans\n",
      " |                 Carnivore                 Dogs\n",
      " |      Reptiles   Carnivore               Snakes\n",
      " |      \n",
      " |      Let's reorder the levels of the index:\n",
      " |      \n",
      " |      >>> df.reorder_levels([\"diet\", \"class\"])\n",
      " |                                        species\n",
      " |      diet      class\n",
      " |      Omnivore  Mammals                  Humans\n",
      " |      Carnivore Mammals                    Dogs\n",
      " |                Reptiles                 Snakes\n",
      " |  \n",
      " |  replace(self, to_replace=None, value=<no_default>, inplace: 'bool' = False, limit=None, regex: 'bool' = False, method: 'str | lib.NoDefault' = <no_default>)\n",
      " |      Replace values given in `to_replace` with `value`.\n",
      " |      \n",
      " |      Values of the DataFrame are replaced with other values dynamically.\n",
      " |      \n",
      " |      This differs from updating with ``.loc`` or ``.iloc``, which require\n",
      " |      you to specify a location to update with some value.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      to_replace : str, regex, list, dict, Series, int, float, or None\n",
      " |          How to find the values that will be replaced.\n",
      " |      \n",
      " |          * numeric, str or regex:\n",
      " |      \n",
      " |              - numeric: numeric values equal to `to_replace` will be\n",
      " |                replaced with `value`\n",
      " |              - str: string exactly matching `to_replace` will be replaced\n",
      " |                with `value`\n",
      " |              - regex: regexs matching `to_replace` will be replaced with\n",
      " |                `value`\n",
      " |      \n",
      " |          * list of str, regex, or numeric:\n",
      " |      \n",
      " |              - First, if `to_replace` and `value` are both lists, they\n",
      " |                **must** be the same length.\n",
      " |              - Second, if ``regex=True`` then all of the strings in **both**\n",
      " |                lists will be interpreted as regexs otherwise they will match\n",
      " |                directly. This doesn't matter much for `value` since there\n",
      " |                are only a few possible substitution regexes you can use.\n",
      " |              - str, regex and numeric rules apply as above.\n",
      " |      \n",
      " |          * dict:\n",
      " |      \n",
      " |              - Dicts can be used to specify different replacement values\n",
      " |                for different existing values. For example,\n",
      " |                ``{'a': 'b', 'y': 'z'}`` replaces the value 'a' with 'b' and\n",
      " |                'y' with 'z'. To use a dict in this way the `value`\n",
      " |                parameter should be `None`.\n",
      " |              - For a DataFrame a dict can specify that different values\n",
      " |                should be replaced in different columns. For example,\n",
      " |                ``{'a': 1, 'b': 'z'}`` looks for the value 1 in column 'a'\n",
      " |                and the value 'z' in column 'b' and replaces these values\n",
      " |                with whatever is specified in `value`. The `value` parameter\n",
      " |                should not be ``None`` in this case. You can treat this as a\n",
      " |                special case of passing two lists except that you are\n",
      " |                specifying the column to search in.\n",
      " |              - For a DataFrame nested dictionaries, e.g.,\n",
      " |                ``{'a': {'b': np.nan}}``, are read as follows: look in column\n",
      " |                'a' for the value 'b' and replace it with NaN. The `value`\n",
      " |                parameter should be ``None`` to use a nested dict in this\n",
      " |                way. You can nest regular expressions as well. Note that\n",
      " |                column names (the top-level dictionary keys in a nested\n",
      " |                dictionary) **cannot** be regular expressions.\n",
      " |      \n",
      " |          * None:\n",
      " |      \n",
      " |              - This means that the `regex` argument must be a string,\n",
      " |                compiled regular expression, or list, dict, ndarray or\n",
      " |                Series of such elements. If `value` is also ``None`` then\n",
      " |                this **must** be a nested dictionary or Series.\n",
      " |      \n",
      " |          See the examples section for examples of each of these.\n",
      " |      value : scalar, dict, list, str, regex, default None\n",
      " |          Value to replace any values matching `to_replace` with.\n",
      " |          For a DataFrame a dict of values can be used to specify which\n",
      " |          value to use for each column (columns not in the dict will not be\n",
      " |          filled). Regular expressions, strings and lists or dicts of such\n",
      " |          objects are also allowed.\n",
      " |      \n",
      " |      inplace : bool, default False\n",
      " |          If True, performs operation inplace and returns None.\n",
      " |      limit : int, default None\n",
      " |          Maximum size gap to forward or backward fill.\n",
      " |      regex : bool or same types as `to_replace`, default False\n",
      " |          Whether to interpret `to_replace` and/or `value` as regular\n",
      " |          expressions. If this is ``True`` then `to_replace` *must* be a\n",
      " |          string. Alternatively, this could be a regular expression or a\n",
      " |          list, dict, or array of regular expressions in which case\n",
      " |          `to_replace` must be ``None``.\n",
      " |      method : {'pad', 'ffill', 'bfill', `None`}\n",
      " |          The method to use when for replacement, when `to_replace` is a\n",
      " |          scalar, list or tuple and `value` is ``None``.\n",
      " |      \n",
      " |          .. versionchanged:: 0.23.0\n",
      " |              Added to DataFrame.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Object after replacement.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      AssertionError\n",
      " |          * If `regex` is not a ``bool`` and `to_replace` is not\n",
      " |            ``None``.\n",
      " |      \n",
      " |      TypeError\n",
      " |          * If `to_replace` is not a scalar, array-like, ``dict``, or ``None``\n",
      " |          * If `to_replace` is a ``dict`` and `value` is not a ``list``,\n",
      " |            ``dict``, ``ndarray``, or ``Series``\n",
      " |          * If `to_replace` is ``None`` and `regex` is not compilable\n",
      " |            into a regular expression or is a list, dict, ndarray, or\n",
      " |            Series.\n",
      " |          * When replacing multiple ``bool`` or ``datetime64`` objects and\n",
      " |            the arguments to `to_replace` does not match the type of the\n",
      " |            value being replaced\n",
      " |      \n",
      " |      ValueError\n",
      " |          * If a ``list`` or an ``ndarray`` is passed to `to_replace` and\n",
      " |            `value` but they are not the same length.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.fillna : Fill NA values.\n",
      " |      DataFrame.where : Replace values based on boolean condition.\n",
      " |      Series.str.replace : Simple string replacement.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      * Regex substitution is performed under the hood with ``re.sub``. The\n",
      " |        rules for substitution for ``re.sub`` are the same.\n",
      " |      * Regular expressions will only substitute on strings, meaning you\n",
      " |        cannot provide, for example, a regular expression matching floating\n",
      " |        point numbers and expect the columns in your frame that have a\n",
      " |        numeric dtype to be matched. However, if those floating point\n",
      " |        numbers *are* strings, then you can do this.\n",
      " |      * This method has *a lot* of options. You are encouraged to experiment\n",
      " |        and play with this method to gain intuition about how it works.\n",
      " |      * When dict is used as the `to_replace` value, it is like\n",
      " |        key(s) in the dict are the to_replace part and\n",
      " |        value(s) in the dict are the value parameter.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      **Scalar `to_replace` and `value`**\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3, 4, 5])\n",
      " |      >>> s.replace(1, 5)\n",
      " |      0    5\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      4    5\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [0, 1, 2, 3, 4],\n",
      " |      ...                    'B': [5, 6, 7, 8, 9],\n",
      " |      ...                    'C': ['a', 'b', 'c', 'd', 'e']})\n",
      " |      >>> df.replace(0, 5)\n",
      " |          A  B  C\n",
      " |      0  5  5  a\n",
      " |      1  1  6  b\n",
      " |      2  2  7  c\n",
      " |      3  3  8  d\n",
      " |      4  4  9  e\n",
      " |      \n",
      " |      **List-like `to_replace`**\n",
      " |      \n",
      " |      >>> df.replace([0, 1, 2, 3], 4)\n",
      " |          A  B  C\n",
      " |      0  4  5  a\n",
      " |      1  4  6  b\n",
      " |      2  4  7  c\n",
      " |      3  4  8  d\n",
      " |      4  4  9  e\n",
      " |      \n",
      " |      >>> df.replace([0, 1, 2, 3], [4, 3, 2, 1])\n",
      " |          A  B  C\n",
      " |      0  4  5  a\n",
      " |      1  3  6  b\n",
      " |      2  2  7  c\n",
      " |      3  1  8  d\n",
      " |      4  4  9  e\n",
      " |      \n",
      " |      >>> s.replace([1, 2], method='bfill')\n",
      " |      0    3\n",
      " |      1    3\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      4    5\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      **dict-like `to_replace`**\n",
      " |      \n",
      " |      >>> df.replace({0: 10, 1: 100})\n",
      " |              A  B  C\n",
      " |      0   10  5  a\n",
      " |      1  100  6  b\n",
      " |      2    2  7  c\n",
      " |      3    3  8  d\n",
      " |      4    4  9  e\n",
      " |      \n",
      " |      >>> df.replace({'A': 0, 'B': 5}, 100)\n",
      " |              A    B  C\n",
      " |      0  100  100  a\n",
      " |      1    1    6  b\n",
      " |      2    2    7  c\n",
      " |      3    3    8  d\n",
      " |      4    4    9  e\n",
      " |      \n",
      " |      >>> df.replace({'A': {0: 100, 4: 400}})\n",
      " |              A  B  C\n",
      " |      0  100  5  a\n",
      " |      1    1  6  b\n",
      " |      2    2  7  c\n",
      " |      3    3  8  d\n",
      " |      4  400  9  e\n",
      " |      \n",
      " |      **Regular expression `to_replace`**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': ['bat', 'foo', 'bait'],\n",
      " |      ...                    'B': ['abc', 'bar', 'xyz']})\n",
      " |      >>> df.replace(to_replace=r'^ba.$', value='new', regex=True)\n",
      " |              A    B\n",
      " |      0   new  abc\n",
      " |      1   foo  new\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      >>> df.replace({'A': r'^ba.$'}, {'A': 'new'}, regex=True)\n",
      " |              A    B\n",
      " |      0   new  abc\n",
      " |      1   foo  bar\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      >>> df.replace(regex=r'^ba.$', value='new')\n",
      " |              A    B\n",
      " |      0   new  abc\n",
      " |      1   foo  new\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      >>> df.replace(regex={r'^ba.$': 'new', 'foo': 'xyz'})\n",
      " |              A    B\n",
      " |      0   new  abc\n",
      " |      1   xyz  new\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      >>> df.replace(regex=[r'^ba.$', 'foo'], value='new')\n",
      " |              A    B\n",
      " |      0   new  abc\n",
      " |      1   new  new\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      Compare the behavior of ``s.replace({'a': None})`` and\n",
      " |      ``s.replace('a', None)`` to understand the peculiarities\n",
      " |      of the `to_replace` parameter:\n",
      " |      \n",
      " |      >>> s = pd.Series([10, 'a', 'a', 'b', 'a'])\n",
      " |      \n",
      " |      When one uses a dict as the `to_replace` value, it is like the\n",
      " |      value(s) in the dict are equal to the `value` parameter.\n",
      " |      ``s.replace({'a': None})`` is equivalent to\n",
      " |      ``s.replace(to_replace={'a': None}, value=None, method=None)``:\n",
      " |      \n",
      " |      >>> s.replace({'a': None})\n",
      " |      0      10\n",
      " |      1    None\n",
      " |      2    None\n",
      " |      3       b\n",
      " |      4    None\n",
      " |      dtype: object\n",
      " |      \n",
      " |      When ``value`` is not explicitly passed and `to_replace` is a scalar, list\n",
      " |      or tuple, `replace` uses the method parameter (default 'pad') to do the\n",
      " |      replacement. So this is why the 'a' values are being replaced by 10\n",
      " |      in rows 1 and 2 and 'b' in row 4 in this case.\n",
      " |      \n",
      " |      >>> s.replace('a')\n",
      " |      0    10\n",
      " |      1    10\n",
      " |      2    10\n",
      " |      3     b\n",
      " |      4     b\n",
      " |      dtype: object\n",
      " |      \n",
      " |      On the other hand, if ``None`` is explicitly passed for ``value``, it will\n",
      " |      be respected:\n",
      " |      \n",
      " |      >>> s.replace('a', None)\n",
      " |      0      10\n",
      " |      1    None\n",
      " |      2    None\n",
      " |      3       b\n",
      " |      4    None\n",
      " |      dtype: object\n",
      " |      \n",
      " |          .. versionchanged:: 1.4.0\n",
      " |              Previously the explicit ``None`` was silently ignored.\n",
      " |  \n",
      " |  resample(self, rule, axis=0, closed: 'str | None' = None, label: 'str | None' = None, convention: 'str' = 'start', kind: 'str | None' = None, loffset=None, base: 'int | None' = None, on=None, level=None, origin: 'str | TimestampConvertibleTypes' = 'start_day', offset: 'TimedeltaConvertibleTypes | None' = None) -> 'Resampler'\n",
      " |      Resample time-series data.\n",
      " |      \n",
      " |      Convenience method for frequency conversion and resampling of time series.\n",
      " |      The object must have a datetime-like index (`DatetimeIndex`, `PeriodIndex`,\n",
      " |      or `TimedeltaIndex`), or the caller must pass the label of a datetime-like\n",
      " |      series/index to the ``on``/``level`` keyword parameter.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      rule : DateOffset, Timedelta or str\n",
      " |          The offset string or object representing target conversion.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Which axis to use for up- or down-sampling. For `Series` this\n",
      " |          will default to 0, i.e. along the rows. Must be\n",
      " |          `DatetimeIndex`, `TimedeltaIndex` or `PeriodIndex`.\n",
      " |      closed : {'right', 'left'}, default None\n",
      " |          Which side of bin interval is closed. The default is 'left'\n",
      " |          for all frequency offsets except for 'M', 'A', 'Q', 'BM',\n",
      " |          'BA', 'BQ', and 'W' which all have a default of 'right'.\n",
      " |      label : {'right', 'left'}, default None\n",
      " |          Which bin edge label to label bucket with. The default is 'left'\n",
      " |          for all frequency offsets except for 'M', 'A', 'Q', 'BM',\n",
      " |          'BA', 'BQ', and 'W' which all have a default of 'right'.\n",
      " |      convention : {'start', 'end', 's', 'e'}, default 'start'\n",
      " |          For `PeriodIndex` only, controls whether to use the start or\n",
      " |          end of `rule`.\n",
      " |      kind : {'timestamp', 'period'}, optional, default None\n",
      " |          Pass 'timestamp' to convert the resulting index to a\n",
      " |          `DateTimeIndex` or 'period' to convert it to a `PeriodIndex`.\n",
      " |          By default the input representation is retained.\n",
      " |      loffset : timedelta, default None\n",
      " |          Adjust the resampled time labels.\n",
      " |      \n",
      " |          .. deprecated:: 1.1.0\n",
      " |              You should add the loffset to the `df.index` after the resample.\n",
      " |              See below.\n",
      " |      \n",
      " |      base : int, default 0\n",
      " |          For frequencies that evenly subdivide 1 day, the \"origin\" of the\n",
      " |          aggregated intervals. For example, for '5min' frequency, base could\n",
      " |          range from 0 through 4. Defaults to 0.\n",
      " |      \n",
      " |          .. deprecated:: 1.1.0\n",
      " |              The new arguments that you should use are 'offset' or 'origin'.\n",
      " |      \n",
      " |      on : str, optional\n",
      " |          For a DataFrame, column to use instead of index for resampling.\n",
      " |          Column must be datetime-like.\n",
      " |      level : str or int, optional\n",
      " |          For a MultiIndex, level (name or number) to use for\n",
      " |          resampling. `level` must be datetime-like.\n",
      " |      origin : Timestamp or str, default 'start_day'\n",
      " |          The timestamp on which to adjust the grouping. The timezone of origin\n",
      " |          must match the timezone of the index.\n",
      " |          If string, must be one of the following:\n",
      " |      \n",
      " |          - 'epoch': `origin` is 1970-01-01\n",
      " |          - 'start': `origin` is the first value of the timeseries\n",
      " |          - 'start_day': `origin` is the first day at midnight of the timeseries\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |          - 'end': `origin` is the last value of the timeseries\n",
      " |          - 'end_day': `origin` is the ceiling midnight of the last day\n",
      " |      \n",
      " |          .. versionadded:: 1.3.0\n",
      " |      \n",
      " |      offset : Timedelta or str, default is None\n",
      " |          An offset timedelta added to the origin.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.core.Resampler\n",
      " |          :class:`~pandas.core.Resampler` object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.resample : Resample a Series.\n",
      " |      DataFrame.resample : Resample a DataFrame.\n",
      " |      groupby : Group DataFrame by mapping, function, label, or list of labels.\n",
      " |      asfreq : Reindex a DataFrame with the given frequency without grouping.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See the `user guide\n",
      " |      <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#resampling>`__\n",
      " |      for more.\n",
      " |      \n",
      " |      To learn more about the offset strings, please see `this link\n",
      " |      <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#dateoffset-objects>`__.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Start by creating a series with 9 one minute timestamps.\n",
      " |      \n",
      " |      >>> index = pd.date_range('1/1/2000', periods=9, freq='T')\n",
      " |      >>> series = pd.Series(range(9), index=index)\n",
      " |      >>> series\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      2000-01-01 00:03:00    3\n",
      " |      2000-01-01 00:04:00    4\n",
      " |      2000-01-01 00:05:00    5\n",
      " |      2000-01-01 00:06:00    6\n",
      " |      2000-01-01 00:07:00    7\n",
      " |      2000-01-01 00:08:00    8\n",
      " |      Freq: T, dtype: int64\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins and sum the values\n",
      " |      of the timestamps falling into a bin.\n",
      " |      \n",
      " |      >>> series.resample('3T').sum()\n",
      " |      2000-01-01 00:00:00     3\n",
      " |      2000-01-01 00:03:00    12\n",
      " |      2000-01-01 00:06:00    21\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins as above, but label each\n",
      " |      bin using the right edge instead of the left. Please note that the\n",
      " |      value in the bucket used as the label is not included in the bucket,\n",
      " |      which it labels. For example, in the original series the\n",
      " |      bucket ``2000-01-01 00:03:00`` contains the value 3, but the summed\n",
      " |      value in the resampled bucket with the label ``2000-01-01 00:03:00``\n",
      " |      does not include 3 (if it did, the summed value would be 6, not 3).\n",
      " |      To include this value close the right side of the bin interval as\n",
      " |      illustrated in the example below this one.\n",
      " |      \n",
      " |      >>> series.resample('3T', label='right').sum()\n",
      " |      2000-01-01 00:03:00     3\n",
      " |      2000-01-01 00:06:00    12\n",
      " |      2000-01-01 00:09:00    21\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins as above, but close the right\n",
      " |      side of the bin interval.\n",
      " |      \n",
      " |      >>> series.resample('3T', label='right', closed='right').sum()\n",
      " |      2000-01-01 00:00:00     0\n",
      " |      2000-01-01 00:03:00     6\n",
      " |      2000-01-01 00:06:00    15\n",
      " |      2000-01-01 00:09:00    15\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      Upsample the series into 30 second bins.\n",
      " |      \n",
      " |      >>> series.resample('30S').asfreq()[0:5]   # Select first 5 rows\n",
      " |      2000-01-01 00:00:00   0.0\n",
      " |      2000-01-01 00:00:30   NaN\n",
      " |      2000-01-01 00:01:00   1.0\n",
      " |      2000-01-01 00:01:30   NaN\n",
      " |      2000-01-01 00:02:00   2.0\n",
      " |      Freq: 30S, dtype: float64\n",
      " |      \n",
      " |      Upsample the series into 30 second bins and fill the ``NaN``\n",
      " |      values using the ``pad`` method.\n",
      " |      \n",
      " |      >>> series.resample('30S').pad()[0:5]\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:00:30    0\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:01:30    1\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      Freq: 30S, dtype: int64\n",
      " |      \n",
      " |      Upsample the series into 30 second bins and fill the\n",
      " |      ``NaN`` values using the ``bfill`` method.\n",
      " |      \n",
      " |      >>> series.resample('30S').bfill()[0:5]\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:00:30    1\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:01:30    2\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      Freq: 30S, dtype: int64\n",
      " |      \n",
      " |      Pass a custom function via ``apply``\n",
      " |      \n",
      " |      >>> def custom_resampler(arraylike):\n",
      " |      ...     return np.sum(arraylike) + 5\n",
      " |      ...\n",
      " |      >>> series.resample('3T').apply(custom_resampler)\n",
      " |      2000-01-01 00:00:00     8\n",
      " |      2000-01-01 00:03:00    17\n",
      " |      2000-01-01 00:06:00    26\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      For a Series with a PeriodIndex, the keyword `convention` can be\n",
      " |      used to control whether to use the start or end of `rule`.\n",
      " |      \n",
      " |      Resample a year by quarter using 'start' `convention`. Values are\n",
      " |      assigned to the first quarter of the period.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2], index=pd.period_range('2012-01-01',\n",
      " |      ...                                             freq='A',\n",
      " |      ...                                             periods=2))\n",
      " |      >>> s\n",
      " |      2012    1\n",
      " |      2013    2\n",
      " |      Freq: A-DEC, dtype: int64\n",
      " |      >>> s.resample('Q', convention='start').asfreq()\n",
      " |      2012Q1    1.0\n",
      " |      2012Q2    NaN\n",
      " |      2012Q3    NaN\n",
      " |      2012Q4    NaN\n",
      " |      2013Q1    2.0\n",
      " |      2013Q2    NaN\n",
      " |      2013Q3    NaN\n",
      " |      2013Q4    NaN\n",
      " |      Freq: Q-DEC, dtype: float64\n",
      " |      \n",
      " |      Resample quarters by month using 'end' `convention`. Values are\n",
      " |      assigned to the last month of the period.\n",
      " |      \n",
      " |      >>> q = pd.Series([1, 2, 3, 4], index=pd.period_range('2018-01-01',\n",
      " |      ...                                                   freq='Q',\n",
      " |      ...                                                   periods=4))\n",
      " |      >>> q\n",
      " |      2018Q1    1\n",
      " |      2018Q2    2\n",
      " |      2018Q3    3\n",
      " |      2018Q4    4\n",
      " |      Freq: Q-DEC, dtype: int64\n",
      " |      >>> q.resample('M', convention='end').asfreq()\n",
      " |      2018-03    1.0\n",
      " |      2018-04    NaN\n",
      " |      2018-05    NaN\n",
      " |      2018-06    2.0\n",
      " |      2018-07    NaN\n",
      " |      2018-08    NaN\n",
      " |      2018-09    3.0\n",
      " |      2018-10    NaN\n",
      " |      2018-11    NaN\n",
      " |      2018-12    4.0\n",
      " |      Freq: M, dtype: float64\n",
      " |      \n",
      " |      For DataFrame objects, the keyword `on` can be used to specify the\n",
      " |      column instead of the index for resampling.\n",
      " |      \n",
      " |      >>> d = {'price': [10, 11, 9, 13, 14, 18, 17, 19],\n",
      " |      ...      'volume': [50, 60, 40, 100, 50, 100, 40, 50]}\n",
      " |      >>> df = pd.DataFrame(d)\n",
      " |      >>> df['week_starting'] = pd.date_range('01/01/2018',\n",
      " |      ...                                     periods=8,\n",
      " |      ...                                     freq='W')\n",
      " |      >>> df\n",
      " |         price  volume week_starting\n",
      " |      0     10      50    2018-01-07\n",
      " |      1     11      60    2018-01-14\n",
      " |      2      9      40    2018-01-21\n",
      " |      3     13     100    2018-01-28\n",
      " |      4     14      50    2018-02-04\n",
      " |      5     18     100    2018-02-11\n",
      " |      6     17      40    2018-02-18\n",
      " |      7     19      50    2018-02-25\n",
      " |      >>> df.resample('M', on='week_starting').mean()\n",
      " |                     price  volume\n",
      " |      week_starting\n",
      " |      2018-01-31     10.75    62.5\n",
      " |      2018-02-28     17.00    60.0\n",
      " |      \n",
      " |      For a DataFrame with MultiIndex, the keyword `level` can be used to\n",
      " |      specify on which level the resampling needs to take place.\n",
      " |      \n",
      " |      >>> days = pd.date_range('1/1/2000', periods=4, freq='D')\n",
      " |      >>> d2 = {'price': [10, 11, 9, 13, 14, 18, 17, 19],\n",
      " |      ...       'volume': [50, 60, 40, 100, 50, 100, 40, 50]}\n",
      " |      >>> df2 = pd.DataFrame(\n",
      " |      ...     d2,\n",
      " |      ...     index=pd.MultiIndex.from_product(\n",
      " |      ...         [days, ['morning', 'afternoon']]\n",
      " |      ...     )\n",
      " |      ... )\n",
      " |      >>> df2\n",
      " |                            price  volume\n",
      " |      2000-01-01 morning       10      50\n",
      " |                 afternoon     11      60\n",
      " |      2000-01-02 morning        9      40\n",
      " |                 afternoon     13     100\n",
      " |      2000-01-03 morning       14      50\n",
      " |                 afternoon     18     100\n",
      " |      2000-01-04 morning       17      40\n",
      " |                 afternoon     19      50\n",
      " |      >>> df2.resample('D', level=0).sum()\n",
      " |                  price  volume\n",
      " |      2000-01-01     21     110\n",
      " |      2000-01-02     22     140\n",
      " |      2000-01-03     32     150\n",
      " |      2000-01-04     36      90\n",
      " |      \n",
      " |      If you want to adjust the start of the bins based on a fixed timestamp:\n",
      " |      \n",
      " |      >>> start, end = '2000-10-01 23:30:00', '2000-10-02 00:30:00'\n",
      " |      >>> rng = pd.date_range(start, end, freq='7min')\n",
      " |      >>> ts = pd.Series(np.arange(len(rng)) * 3, index=rng)\n",
      " |      >>> ts\n",
      " |      2000-10-01 23:30:00     0\n",
      " |      2000-10-01 23:37:00     3\n",
      " |      2000-10-01 23:44:00     6\n",
      " |      2000-10-01 23:51:00     9\n",
      " |      2000-10-01 23:58:00    12\n",
      " |      2000-10-02 00:05:00    15\n",
      " |      2000-10-02 00:12:00    18\n",
      " |      2000-10-02 00:19:00    21\n",
      " |      2000-10-02 00:26:00    24\n",
      " |      Freq: 7T, dtype: int64\n",
      " |      \n",
      " |      >>> ts.resample('17min').sum()\n",
      " |      2000-10-01 23:14:00     0\n",
      " |      2000-10-01 23:31:00     9\n",
      " |      2000-10-01 23:48:00    21\n",
      " |      2000-10-02 00:05:00    54\n",
      " |      2000-10-02 00:22:00    24\n",
      " |      Freq: 17T, dtype: int64\n",
      " |      \n",
      " |      >>> ts.resample('17min', origin='epoch').sum()\n",
      " |      2000-10-01 23:18:00     0\n",
      " |      2000-10-01 23:35:00    18\n",
      " |      2000-10-01 23:52:00    27\n",
      " |      2000-10-02 00:09:00    39\n",
      " |      2000-10-02 00:26:00    24\n",
      " |      Freq: 17T, dtype: int64\n",
      " |      \n",
      " |      >>> ts.resample('17min', origin='2000-01-01').sum()\n",
      " |      2000-10-01 23:24:00     3\n",
      " |      2000-10-01 23:41:00    15\n",
      " |      2000-10-01 23:58:00    45\n",
      " |      2000-10-02 00:15:00    45\n",
      " |      Freq: 17T, dtype: int64\n",
      " |      \n",
      " |      If you want to adjust the start of the bins with an `offset` Timedelta, the two\n",
      " |      following lines are equivalent:\n",
      " |      \n",
      " |      >>> ts.resample('17min', origin='start').sum()\n",
      " |      2000-10-01 23:30:00     9\n",
      " |      2000-10-01 23:47:00    21\n",
      " |      2000-10-02 00:04:00    54\n",
      " |      2000-10-02 00:21:00    24\n",
      " |      Freq: 17T, dtype: int64\n",
      " |      \n",
      " |      >>> ts.resample('17min', offset='23h30min').sum()\n",
      " |      2000-10-01 23:30:00     9\n",
      " |      2000-10-01 23:47:00    21\n",
      " |      2000-10-02 00:04:00    54\n",
      " |      2000-10-02 00:21:00    24\n",
      " |      Freq: 17T, dtype: int64\n",
      " |      \n",
      " |      If you want to take the largest Timestamp as the end of the bins:\n",
      " |      \n",
      " |      >>> ts.resample('17min', origin='end').sum()\n",
      " |      2000-10-01 23:35:00     0\n",
      " |      2000-10-01 23:52:00    18\n",
      " |      2000-10-02 00:09:00    27\n",
      " |      2000-10-02 00:26:00    63\n",
      " |      Freq: 17T, dtype: int64\n",
      " |      \n",
      " |      In contrast with the `start_day`, you can use `end_day` to take the ceiling\n",
      " |      midnight of the largest Timestamp as the end of the bins and drop the bins\n",
      " |      not containing data:\n",
      " |      \n",
      " |      >>> ts.resample('17min', origin='end_day').sum()\n",
      " |      2000-10-01 23:38:00     3\n",
      " |      2000-10-01 23:55:00    15\n",
      " |      2000-10-02 00:12:00    45\n",
      " |      2000-10-02 00:29:00    45\n",
      " |      Freq: 17T, dtype: int64\n",
      " |      \n",
      " |      To replace the use of the deprecated `base` argument, you can now use `offset`,\n",
      " |      in this example it is equivalent to have `base=2`:\n",
      " |      \n",
      " |      >>> ts.resample('17min', offset='2min').sum()\n",
      " |      2000-10-01 23:16:00     0\n",
      " |      2000-10-01 23:33:00     9\n",
      " |      2000-10-01 23:50:00    36\n",
      " |      2000-10-02 00:07:00    39\n",
      " |      2000-10-02 00:24:00    24\n",
      " |      Freq: 17T, dtype: int64\n",
      " |      \n",
      " |      To replace the use of the deprecated `loffset` argument:\n",
      " |      \n",
      " |      >>> from pandas.tseries.frequencies import to_offset\n",
      " |      >>> loffset = '19min'\n",
      " |      >>> ts_out = ts.resample('17min').sum()\n",
      " |      >>> ts_out.index = ts_out.index + to_offset(loffset)\n",
      " |      >>> ts_out\n",
      " |      2000-10-01 23:33:00     0\n",
      " |      2000-10-01 23:50:00     9\n",
      " |      2000-10-02 00:07:00    21\n",
      " |      2000-10-02 00:24:00    54\n",
      " |      2000-10-02 00:41:00    24\n",
      " |      Freq: 17T, dtype: int64\n",
      " |  \n",
      " |  reset_index(self, level: 'Hashable | Sequence[Hashable] | None' = None, drop: 'bool' = False, inplace: 'bool' = False, col_level: 'Hashable' = 0, col_fill: 'Hashable' = '') -> 'DataFrame | None'\n",
      " |      Reset the index, or a level of it.\n",
      " |      \n",
      " |      Reset the index of the DataFrame, and use the default one instead.\n",
      " |      If the DataFrame has a MultiIndex, this method can remove one or more\n",
      " |      levels.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, str, tuple, or list, default None\n",
      " |          Only remove the given levels from the index. Removes all levels by\n",
      " |          default.\n",
      " |      drop : bool, default False\n",
      " |          Do not try to insert index into dataframe columns. This resets\n",
      " |          the index to the default integer index.\n",
      " |      inplace : bool, default False\n",
      " |          Modify the DataFrame in place (do not create a new object).\n",
      " |      col_level : int or str, default 0\n",
      " |          If the columns have multiple levels, determines which level the\n",
      " |          labels are inserted into. By default it is inserted into the first\n",
      " |          level.\n",
      " |      col_fill : object, default ''\n",
      " |          If the columns have multiple levels, determines how the other\n",
      " |          levels are named. If None then the index name is repeated.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          DataFrame with the new index or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.set_index : Opposite of reset_index.\n",
      " |      DataFrame.reindex : Change to new indices or expand indices.\n",
      " |      DataFrame.reindex_like : Change to same indices as other DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('bird', 389.0),\n",
      " |      ...                    ('bird', 24.0),\n",
      " |      ...                    ('mammal', 80.5),\n",
      " |      ...                    ('mammal', np.nan)],\n",
      " |      ...                   index=['falcon', 'parrot', 'lion', 'monkey'],\n",
      " |      ...                   columns=('class', 'max_speed'))\n",
      " |      >>> df\n",
      " |               class  max_speed\n",
      " |      falcon    bird      389.0\n",
      " |      parrot    bird       24.0\n",
      " |      lion    mammal       80.5\n",
      " |      monkey  mammal        NaN\n",
      " |      \n",
      " |      When we reset the index, the old index is added as a column, and a\n",
      " |      new sequential index is used:\n",
      " |      \n",
      " |      >>> df.reset_index()\n",
      " |          index   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      1  parrot    bird       24.0\n",
      " |      2    lion  mammal       80.5\n",
      " |      3  monkey  mammal        NaN\n",
      " |      \n",
      " |      We can use the `drop` parameter to avoid the old index being added as\n",
      " |      a column:\n",
      " |      \n",
      " |      >>> df.reset_index(drop=True)\n",
      " |          class  max_speed\n",
      " |      0    bird      389.0\n",
      " |      1    bird       24.0\n",
      " |      2  mammal       80.5\n",
      " |      3  mammal        NaN\n",
      " |      \n",
      " |      You can also use `reset_index` with `MultiIndex`.\n",
      " |      \n",
      " |      >>> index = pd.MultiIndex.from_tuples([('bird', 'falcon'),\n",
      " |      ...                                    ('bird', 'parrot'),\n",
      " |      ...                                    ('mammal', 'lion'),\n",
      " |      ...                                    ('mammal', 'monkey')],\n",
      " |      ...                                   names=['class', 'name'])\n",
      " |      >>> columns = pd.MultiIndex.from_tuples([('speed', 'max'),\n",
      " |      ...                                      ('species', 'type')])\n",
      " |      >>> df = pd.DataFrame([(389.0, 'fly'),\n",
      " |      ...                    ( 24.0, 'fly'),\n",
      " |      ...                    ( 80.5, 'run'),\n",
      " |      ...                    (np.nan, 'jump')],\n",
      " |      ...                   index=index,\n",
      " |      ...                   columns=columns)\n",
      " |      >>> df\n",
      " |                     speed species\n",
      " |                       max    type\n",
      " |      class  name\n",
      " |      bird   falcon  389.0     fly\n",
      " |             parrot   24.0     fly\n",
      " |      mammal lion     80.5     run\n",
      " |             monkey    NaN    jump\n",
      " |      \n",
      " |      If the index has multiple levels, we can reset a subset of them:\n",
      " |      \n",
      " |      >>> df.reset_index(level='class')\n",
      " |               class  speed species\n",
      " |                        max    type\n",
      " |      name\n",
      " |      falcon    bird  389.0     fly\n",
      " |      parrot    bird   24.0     fly\n",
      " |      lion    mammal   80.5     run\n",
      " |      monkey  mammal    NaN    jump\n",
      " |      \n",
      " |      If we are not dropping the index, by default, it is placed in the top\n",
      " |      level. We can place it in another level:\n",
      " |      \n",
      " |      >>> df.reset_index(level='class', col_level=1)\n",
      " |                      speed species\n",
      " |               class    max    type\n",
      " |      name\n",
      " |      falcon    bird  389.0     fly\n",
      " |      parrot    bird   24.0     fly\n",
      " |      lion    mammal   80.5     run\n",
      " |      monkey  mammal    NaN    jump\n",
      " |      \n",
      " |      When the index is inserted under another level, we can specify under\n",
      " |      which one with the parameter `col_fill`:\n",
      " |      \n",
      " |      >>> df.reset_index(level='class', col_level=1, col_fill='species')\n",
      " |                    species  speed species\n",
      " |                      class    max    type\n",
      " |      name\n",
      " |      falcon           bird  389.0     fly\n",
      " |      parrot           bird   24.0     fly\n",
      " |      lion           mammal   80.5     run\n",
      " |      monkey         mammal    NaN    jump\n",
      " |      \n",
      " |      If we specify a nonexistent level for `col_fill`, it is created:\n",
      " |      \n",
      " |      >>> df.reset_index(level='class', col_level=1, col_fill='genus')\n",
      " |                      genus  speed species\n",
      " |                      class    max    type\n",
      " |      name\n",
      " |      falcon           bird  389.0     fly\n",
      " |      parrot           bird   24.0     fly\n",
      " |      lion           mammal   80.5     run\n",
      " |      monkey         mammal    NaN    jump\n",
      " |  \n",
      " |  rfloordiv(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Integer division of dataframe and other, element-wise (binary operator `rfloordiv`).\n",
      " |      \n",
      " |      Equivalent to ``other // dataframe``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `floordiv`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  rmod(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Modulo of dataframe and other, element-wise (binary operator `rmod`).\n",
      " |      \n",
      " |      Equivalent to ``other % dataframe``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `mod`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  rmul(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Multiplication of dataframe and other, element-wise (binary operator `rmul`).\n",
      " |      \n",
      " |      Equivalent to ``other * dataframe``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `mul`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  round(self, decimals: 'int | dict[IndexLabel, int] | Series' = 0, *args, **kwargs) -> 'DataFrame'\n",
      " |      Round a DataFrame to a variable number of decimal places.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      decimals : int, dict, Series\n",
      " |          Number of decimal places to round each column to. If an int is\n",
      " |          given, round each column to the same number of places.\n",
      " |          Otherwise dict and Series round to variable numbers of places.\n",
      " |          Column names should be in the keys if `decimals` is a\n",
      " |          dict-like, or in the index if `decimals` is a Series. Any\n",
      " |          columns not included in `decimals` will be left as is. Elements\n",
      " |          of `decimals` which are not columns of the input will be\n",
      " |          ignored.\n",
      " |      *args\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with numpy.\n",
      " |      **kwargs\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with numpy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          A DataFrame with the affected columns rounded to the specified\n",
      " |          number of decimal places.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.around : Round a numpy array to the given number of decimals.\n",
      " |      Series.round : Round a Series to the given number of decimals.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([(.21, .32), (.01, .67), (.66, .03), (.21, .18)],\n",
      " |      ...                   columns=['dogs', 'cats'])\n",
      " |      >>> df\n",
      " |          dogs  cats\n",
      " |      0  0.21  0.32\n",
      " |      1  0.01  0.67\n",
      " |      2  0.66  0.03\n",
      " |      3  0.21  0.18\n",
      " |      \n",
      " |      By providing an integer each column is rounded to the same number\n",
      " |      of decimal places\n",
      " |      \n",
      " |      >>> df.round(1)\n",
      " |          dogs  cats\n",
      " |      0   0.2   0.3\n",
      " |      1   0.0   0.7\n",
      " |      2   0.7   0.0\n",
      " |      3   0.2   0.2\n",
      " |      \n",
      " |      With a dict, the number of places for specific columns can be\n",
      " |      specified with the column names as key and the number of decimal\n",
      " |      places as value\n",
      " |      \n",
      " |      >>> df.round({'dogs': 1, 'cats': 0})\n",
      " |          dogs  cats\n",
      " |      0   0.2   0.0\n",
      " |      1   0.0   1.0\n",
      " |      2   0.7   0.0\n",
      " |      3   0.2   0.0\n",
      " |      \n",
      " |      Using a Series, the number of places for specific columns can be\n",
      " |      specified with the column names as index and the number of\n",
      " |      decimal places as value\n",
      " |      \n",
      " |      >>> decimals = pd.Series([0, 1], index=['cats', 'dogs'])\n",
      " |      >>> df.round(decimals)\n",
      " |          dogs  cats\n",
      " |      0   0.2   0.0\n",
      " |      1   0.0   1.0\n",
      " |      2   0.7   0.0\n",
      " |      3   0.2   0.0\n",
      " |  \n",
      " |  rpow(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Exponential power of dataframe and other, element-wise (binary operator `rpow`).\n",
      " |      \n",
      " |      Equivalent to ``other ** dataframe``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `pow`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  rsub(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Subtraction of dataframe and other, element-wise (binary operator `rsub`).\n",
      " |      \n",
      " |      Equivalent to ``other - dataframe``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `sub`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  rtruediv(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Floating division of dataframe and other, element-wise (binary operator `rtruediv`).\n",
      " |      \n",
      " |      Equivalent to ``other / dataframe``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `truediv`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  select_dtypes(self, include=None, exclude=None) -> 'DataFrame'\n",
      " |      Return a subset of the DataFrame's columns based on the column dtypes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      include, exclude : scalar or list-like\n",
      " |          A selection of dtypes or strings to be included/excluded. At least\n",
      " |          one of these parameters must be supplied.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The subset of the frame including the dtypes in ``include`` and\n",
      " |          excluding the dtypes in ``exclude``.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          * If both of ``include`` and ``exclude`` are empty\n",
      " |          * If ``include`` and ``exclude`` have overlapping elements\n",
      " |          * If any kind of string dtype is passed in.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.dtypes: Return Series with the data type of each column.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      * To select all *numeric* types, use ``np.number`` or ``'number'``\n",
      " |      * To select strings you must use the ``object`` dtype, but note that\n",
      " |        this will return *all* object dtype columns\n",
      " |      * See the `numpy dtype hierarchy\n",
      " |        <https://numpy.org/doc/stable/reference/arrays.scalars.html>`__\n",
      " |      * To select datetimes, use ``np.datetime64``, ``'datetime'`` or\n",
      " |        ``'datetime64'``\n",
      " |      * To select timedeltas, use ``np.timedelta64``, ``'timedelta'`` or\n",
      " |        ``'timedelta64'``\n",
      " |      * To select Pandas categorical dtypes, use ``'category'``\n",
      " |      * To select Pandas datetimetz dtypes, use ``'datetimetz'`` (new in\n",
      " |        0.20.0) or ``'datetime64[ns, tz]'``\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'a': [1, 2] * 3,\n",
      " |      ...                    'b': [True, False] * 3,\n",
      " |      ...                    'c': [1.0, 2.0] * 3})\n",
      " |      >>> df\n",
      " |              a      b  c\n",
      " |      0       1   True  1.0\n",
      " |      1       2  False  2.0\n",
      " |      2       1   True  1.0\n",
      " |      3       2  False  2.0\n",
      " |      4       1   True  1.0\n",
      " |      5       2  False  2.0\n",
      " |      \n",
      " |      >>> df.select_dtypes(include='bool')\n",
      " |         b\n",
      " |      0  True\n",
      " |      1  False\n",
      " |      2  True\n",
      " |      3  False\n",
      " |      4  True\n",
      " |      5  False\n",
      " |      \n",
      " |      >>> df.select_dtypes(include=['float64'])\n",
      " |         c\n",
      " |      0  1.0\n",
      " |      1  2.0\n",
      " |      2  1.0\n",
      " |      3  2.0\n",
      " |      4  1.0\n",
      " |      5  2.0\n",
      " |      \n",
      " |      >>> df.select_dtypes(exclude=['int64'])\n",
      " |             b    c\n",
      " |      0   True  1.0\n",
      " |      1  False  2.0\n",
      " |      2   True  1.0\n",
      " |      3  False  2.0\n",
      " |      4   True  1.0\n",
      " |      5  False  2.0\n",
      " |  \n",
      " |  sem(self, axis=None, skipna=True, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      " |      Return unbiased standard error of the mean over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      ddof : int, default 1\n",
      " |          Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\n",
      " |          where N represents the number of elements.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  set_axis(self, labels, axis: 'Axis' = 0, inplace: 'bool' = False)\n",
      " |      Assign desired index to given axis.\n",
      " |      \n",
      " |      Indexes for column or row labels can be changed by assigning\n",
      " |      a list-like or Index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      labels : list-like, Index\n",
      " |          The values for the new index.\n",
      " |      \n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to update. The value 0 identifies the rows, and 1 identifies the columns.\n",
      " |      \n",
      " |      inplace : bool, default False\n",
      " |          Whether to return a new DataFrame instance.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      renamed : DataFrame or None\n",
      " |          An object of type DataFrame or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.rename_axis : Alter the name of the index or columns.\n",
      " |      \n",
      " |              Examples\n",
      " |              --------\n",
      " |              >>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n",
      " |      \n",
      " |              Change the row labels.\n",
      " |      \n",
      " |              >>> df.set_axis(['a', 'b', 'c'], axis='index')\n",
      " |                 A  B\n",
      " |              a  1  4\n",
      " |              b  2  5\n",
      " |              c  3  6\n",
      " |      \n",
      " |              Change the column labels.\n",
      " |      \n",
      " |              >>> df.set_axis(['I', 'II'], axis='columns')\n",
      " |                 I  II\n",
      " |              0  1   4\n",
      " |              1  2   5\n",
      " |              2  3   6\n",
      " |      \n",
      " |              Now, update the labels inplace.\n",
      " |      \n",
      " |              >>> df.set_axis(['i', 'ii'], axis='columns', inplace=True)\n",
      " |              >>> df\n",
      " |                 i  ii\n",
      " |              0  1   4\n",
      " |              1  2   5\n",
      " |              2  3   6\n",
      " |  \n",
      " |  set_index(self, keys, drop: 'bool' = True, append: 'bool' = False, inplace: 'bool' = False, verify_integrity: 'bool' = False)\n",
      " |      Set the DataFrame index using existing columns.\n",
      " |      \n",
      " |      Set the DataFrame index (row labels) using one or more existing\n",
      " |      columns or arrays (of the correct length). The index can replace the\n",
      " |      existing index or expand on it.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      keys : label or array-like or list of labels/arrays\n",
      " |          This parameter can be either a single column key, a single array of\n",
      " |          the same length as the calling DataFrame, or a list containing an\n",
      " |          arbitrary combination of column keys and arrays. Here, \"array\"\n",
      " |          encompasses :class:`Series`, :class:`Index`, ``np.ndarray``, and\n",
      " |          instances of :class:`~collections.abc.Iterator`.\n",
      " |      drop : bool, default True\n",
      " |          Delete columns to be used as the new index.\n",
      " |      append : bool, default False\n",
      " |          Whether to append columns to existing index.\n",
      " |      inplace : bool, default False\n",
      " |          If True, modifies the DataFrame in place (do not create a new object).\n",
      " |      verify_integrity : bool, default False\n",
      " |          Check the new index for duplicates. Otherwise defer the check until\n",
      " |          necessary. Setting to False will improve the performance of this\n",
      " |          method.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          Changed row labels or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.reset_index : Opposite of set_index.\n",
      " |      DataFrame.reindex : Change to new indices or expand indices.\n",
      " |      DataFrame.reindex_like : Change to same indices as other DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'month': [1, 4, 7, 10],\n",
      " |      ...                    'year': [2012, 2014, 2013, 2014],\n",
      " |      ...                    'sale': [55, 40, 84, 31]})\n",
      " |      >>> df\n",
      " |         month  year  sale\n",
      " |      0      1  2012    55\n",
      " |      1      4  2014    40\n",
      " |      2      7  2013    84\n",
      " |      3     10  2014    31\n",
      " |      \n",
      " |      Set the index to become the 'month' column:\n",
      " |      \n",
      " |      >>> df.set_index('month')\n",
      " |             year  sale\n",
      " |      month\n",
      " |      1      2012    55\n",
      " |      4      2014    40\n",
      " |      7      2013    84\n",
      " |      10     2014    31\n",
      " |      \n",
      " |      Create a MultiIndex using columns 'year' and 'month':\n",
      " |      \n",
      " |      >>> df.set_index(['year', 'month'])\n",
      " |                  sale\n",
      " |      year  month\n",
      " |      2012  1     55\n",
      " |      2014  4     40\n",
      " |      2013  7     84\n",
      " |      2014  10    31\n",
      " |      \n",
      " |      Create a MultiIndex using an Index and a column:\n",
      " |      \n",
      " |      >>> df.set_index([pd.Index([1, 2, 3, 4]), 'year'])\n",
      " |               month  sale\n",
      " |         year\n",
      " |      1  2012  1      55\n",
      " |      2  2014  4      40\n",
      " |      3  2013  7      84\n",
      " |      4  2014  10     31\n",
      " |      \n",
      " |      Create a MultiIndex using two Series:\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> df.set_index([s, s**2])\n",
      " |            month  year  sale\n",
      " |      1 1       1  2012    55\n",
      " |      2 4       4  2014    40\n",
      " |      3 9       7  2013    84\n",
      " |      4 16     10  2014    31\n",
      " |  \n",
      " |  shift(self, periods=1, freq: 'Frequency | None' = None, axis: 'Axis' = 0, fill_value=<no_default>) -> 'DataFrame'\n",
      " |      Shift index by desired number of periods with an optional time `freq`.\n",
      " |      \n",
      " |      When `freq` is not passed, shift the index without realigning the data.\n",
      " |      If `freq` is passed (in this case, the index must be date or datetime,\n",
      " |      or it will raise a `NotImplementedError`), the index will be\n",
      " |      increased using the periods and the `freq`. `freq` can be inferred\n",
      " |      when specified as \"infer\" as long as either freq or inferred_freq\n",
      " |      attribute is set in the index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to shift. Can be positive or negative.\n",
      " |      freq : DateOffset, tseries.offsets, timedelta, or str, optional\n",
      " |          Offset to use from the tseries module or time rule (e.g. 'EOM').\n",
      " |          If `freq` is specified then the index values are shifted but the\n",
      " |          data is not realigned. That is, use `freq` if you would like to\n",
      " |          extend the index when shifting and preserve the original data.\n",
      " |          If `freq` is specified as \"infer\" then it will be inferred from\n",
      " |          the freq or inferred_freq attributes of the index. If neither of\n",
      " |          those attributes exist, a ValueError is thrown.\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default None\n",
      " |          Shift direction.\n",
      " |      fill_value : object, optional\n",
      " |          The scalar value to use for newly introduced missing values.\n",
      " |          the default depends on the dtype of `self`.\n",
      " |          For numeric data, ``np.nan`` is used.\n",
      " |          For datetime, timedelta, or period data, etc. :attr:`NaT` is used.\n",
      " |          For extension dtypes, ``self.dtype.na_value`` is used.\n",
      " |      \n",
      " |          .. versionchanged:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Copy of input object, shifted.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.shift : Shift values of Index.\n",
      " |      DatetimeIndex.shift : Shift values of DatetimeIndex.\n",
      " |      PeriodIndex.shift : Shift values of PeriodIndex.\n",
      " |      tshift : Shift the time index, using the index's frequency if\n",
      " |          available.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"Col1\": [10, 20, 15, 30, 45],\n",
      " |      ...                    \"Col2\": [13, 23, 18, 33, 48],\n",
      " |      ...                    \"Col3\": [17, 27, 22, 37, 52]},\n",
      " |      ...                   index=pd.date_range(\"2020-01-01\", \"2020-01-05\"))\n",
      " |      >>> df\n",
      " |                  Col1  Col2  Col3\n",
      " |      2020-01-01    10    13    17\n",
      " |      2020-01-02    20    23    27\n",
      " |      2020-01-03    15    18    22\n",
      " |      2020-01-04    30    33    37\n",
      " |      2020-01-05    45    48    52\n",
      " |      \n",
      " |      >>> df.shift(periods=3)\n",
      " |                  Col1  Col2  Col3\n",
      " |      2020-01-01   NaN   NaN   NaN\n",
      " |      2020-01-02   NaN   NaN   NaN\n",
      " |      2020-01-03   NaN   NaN   NaN\n",
      " |      2020-01-04  10.0  13.0  17.0\n",
      " |      2020-01-05  20.0  23.0  27.0\n",
      " |      \n",
      " |      >>> df.shift(periods=1, axis=\"columns\")\n",
      " |                  Col1  Col2  Col3\n",
      " |      2020-01-01   NaN    10    13\n",
      " |      2020-01-02   NaN    20    23\n",
      " |      2020-01-03   NaN    15    18\n",
      " |      2020-01-04   NaN    30    33\n",
      " |      2020-01-05   NaN    45    48\n",
      " |      \n",
      " |      >>> df.shift(periods=3, fill_value=0)\n",
      " |                  Col1  Col2  Col3\n",
      " |      2020-01-01     0     0     0\n",
      " |      2020-01-02     0     0     0\n",
      " |      2020-01-03     0     0     0\n",
      " |      2020-01-04    10    13    17\n",
      " |      2020-01-05    20    23    27\n",
      " |      \n",
      " |      >>> df.shift(periods=3, freq=\"D\")\n",
      " |                  Col1  Col2  Col3\n",
      " |      2020-01-04    10    13    17\n",
      " |      2020-01-05    20    23    27\n",
      " |      2020-01-06    15    18    22\n",
      " |      2020-01-07    30    33    37\n",
      " |      2020-01-08    45    48    52\n",
      " |      \n",
      " |      >>> df.shift(periods=3, freq=\"infer\")\n",
      " |                  Col1  Col2  Col3\n",
      " |      2020-01-04    10    13    17\n",
      " |      2020-01-05    20    23    27\n",
      " |      2020-01-06    15    18    22\n",
      " |      2020-01-07    30    33    37\n",
      " |      2020-01-08    45    48    52\n",
      " |  \n",
      " |  skew(self, axis: 'int | None | lib.NoDefault' = <no_default>, skipna=True, level=None, numeric_only=None, **kwargs)\n",
      " |      Return unbiased skew over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  sort_index(self, axis: 'Axis' = 0, level: 'Level | None' = None, ascending: 'bool | int | Sequence[bool | int]' = True, inplace: 'bool' = False, kind: 'str' = 'quicksort', na_position: 'str' = 'last', sort_remaining: 'bool' = True, ignore_index: 'bool' = False, key: 'IndexKeyFunc' = None)\n",
      " |      Sort object by labels (along an axis).\n",
      " |      \n",
      " |      Returns a new DataFrame sorted by label if `inplace` argument is\n",
      " |      ``False``, otherwise updates the original DataFrame and returns None.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis along which to sort.  The value 0 identifies the rows,\n",
      " |          and 1 identifies the columns.\n",
      " |      level : int or level name or list of ints or list of level names\n",
      " |          If not None, sort on values in specified index level(s).\n",
      " |      ascending : bool or list-like of bools, default True\n",
      " |          Sort ascending vs. descending. When the index is a MultiIndex the\n",
      " |          sort direction can be controlled for each level individually.\n",
      " |      inplace : bool, default False\n",
      " |          If True, perform operation in-place.\n",
      " |      kind : {'quicksort', 'mergesort', 'heapsort', 'stable'}, default 'quicksort'\n",
      " |          Choice of sorting algorithm. See also :func:`numpy.sort` for more\n",
      " |          information. `mergesort` and `stable` are the only stable algorithms. For\n",
      " |          DataFrames, this option is only applied when sorting on a single\n",
      " |          column or label.\n",
      " |      na_position : {'first', 'last'}, default 'last'\n",
      " |          Puts NaNs at the beginning if `first`; `last` puts NaNs at the end.\n",
      " |          Not implemented for MultiIndex.\n",
      " |      sort_remaining : bool, default True\n",
      " |          If True and sorting by level and index is multilevel, sort by other\n",
      " |          levels too (in order) after sorting by specified level.\n",
      " |      ignore_index : bool, default False\n",
      " |          If True, the resulting axis will be labeled 0, 1, …, n - 1.\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      key : callable, optional\n",
      " |          If not None, apply the key function to the index values\n",
      " |          before sorting. This is similar to the `key` argument in the\n",
      " |          builtin :meth:`sorted` function, with the notable difference that\n",
      " |          this `key` function should be *vectorized*. It should expect an\n",
      " |          ``Index`` and return an ``Index`` of the same shape. For MultiIndex\n",
      " |          inputs, the key is applied *per level*.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          The original DataFrame sorted by the labels or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sort_index : Sort Series by the index.\n",
      " |      DataFrame.sort_values : Sort DataFrame by the value.\n",
      " |      Series.sort_values : Sort Series by the value.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([1, 2, 3, 4, 5], index=[100, 29, 234, 1, 150],\n",
      " |      ...                   columns=['A'])\n",
      " |      >>> df.sort_index()\n",
      " |           A\n",
      " |      1    4\n",
      " |      29   2\n",
      " |      100  1\n",
      " |      150  5\n",
      " |      234  3\n",
      " |      \n",
      " |      By default, it sorts in ascending order, to sort in descending order,\n",
      " |      use ``ascending=False``\n",
      " |      \n",
      " |      >>> df.sort_index(ascending=False)\n",
      " |           A\n",
      " |      234  3\n",
      " |      150  5\n",
      " |      100  1\n",
      " |      29   2\n",
      " |      1    4\n",
      " |      \n",
      " |      A key function can be specified which is applied to the index before\n",
      " |      sorting. For a ``MultiIndex`` this is applied to each level separately.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"a\": [1, 2, 3, 4]}, index=['A', 'b', 'C', 'd'])\n",
      " |      >>> df.sort_index(key=lambda x: x.str.lower())\n",
      " |         a\n",
      " |      A  1\n",
      " |      b  2\n",
      " |      C  3\n",
      " |      d  4\n",
      " |  \n",
      " |  sort_values(self, by, axis: 'Axis' = 0, ascending=True, inplace: 'bool' = False, kind: 'str' = 'quicksort', na_position: 'str' = 'last', ignore_index: 'bool' = False, key: 'ValueKeyFunc' = None)\n",
      " |      Sort by the values along either axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |              by : str or list of str\n",
      " |                  Name or list of names to sort by.\n",
      " |      \n",
      " |                  - if `axis` is 0 or `'index'` then `by` may contain index\n",
      " |                    levels and/or column labels.\n",
      " |                  - if `axis` is 1 or `'columns'` then `by` may contain column\n",
      " |                    levels and/or index labels.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |           Axis to be sorted.\n",
      " |      ascending : bool or list of bool, default True\n",
      " |           Sort ascending vs. descending. Specify list for multiple sort\n",
      " |           orders.  If this is a list of bools, must match the length of\n",
      " |           the by.\n",
      " |      inplace : bool, default False\n",
      " |           If True, perform operation in-place.\n",
      " |      kind : {'quicksort', 'mergesort', 'heapsort', 'stable'}, default 'quicksort'\n",
      " |           Choice of sorting algorithm. See also :func:`numpy.sort` for more\n",
      " |           information. `mergesort` and `stable` are the only stable algorithms. For\n",
      " |           DataFrames, this option is only applied when sorting on a single\n",
      " |           column or label.\n",
      " |      na_position : {'first', 'last'}, default 'last'\n",
      " |           Puts NaNs at the beginning if `first`; `last` puts NaNs at the\n",
      " |           end.\n",
      " |      ignore_index : bool, default False\n",
      " |           If True, the resulting axis will be labeled 0, 1, …, n - 1.\n",
      " |      \n",
      " |           .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      key : callable, optional\n",
      " |          Apply the key function to the values\n",
      " |          before sorting. This is similar to the `key` argument in the\n",
      " |          builtin :meth:`sorted` function, with the notable difference that\n",
      " |          this `key` function should be *vectorized*. It should expect a\n",
      " |          ``Series`` and return a Series with the same shape as the input.\n",
      " |          It will be applied to each column in `by` independently.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          DataFrame with sorted values or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.sort_index : Sort a DataFrame by the index.\n",
      " |      Series.sort_values : Similar method for a Series.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'col1': ['A', 'A', 'B', np.nan, 'D', 'C'],\n",
      " |      ...     'col2': [2, 1, 9, 8, 7, 4],\n",
      " |      ...     'col3': [0, 1, 9, 4, 2, 3],\n",
      " |      ...     'col4': ['a', 'B', 'c', 'D', 'e', 'F']\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |        col1  col2  col3 col4\n",
      " |      0    A     2     0    a\n",
      " |      1    A     1     1    B\n",
      " |      2    B     9     9    c\n",
      " |      3  NaN     8     4    D\n",
      " |      4    D     7     2    e\n",
      " |      5    C     4     3    F\n",
      " |      \n",
      " |      Sort by col1\n",
      " |      \n",
      " |      >>> df.sort_values(by=['col1'])\n",
      " |        col1  col2  col3 col4\n",
      " |      0    A     2     0    a\n",
      " |      1    A     1     1    B\n",
      " |      2    B     9     9    c\n",
      " |      5    C     4     3    F\n",
      " |      4    D     7     2    e\n",
      " |      3  NaN     8     4    D\n",
      " |      \n",
      " |      Sort by multiple columns\n",
      " |      \n",
      " |      >>> df.sort_values(by=['col1', 'col2'])\n",
      " |        col1  col2  col3 col4\n",
      " |      1    A     1     1    B\n",
      " |      0    A     2     0    a\n",
      " |      2    B     9     9    c\n",
      " |      5    C     4     3    F\n",
      " |      4    D     7     2    e\n",
      " |      3  NaN     8     4    D\n",
      " |      \n",
      " |      Sort Descending\n",
      " |      \n",
      " |      >>> df.sort_values(by='col1', ascending=False)\n",
      " |        col1  col2  col3 col4\n",
      " |      4    D     7     2    e\n",
      " |      5    C     4     3    F\n",
      " |      2    B     9     9    c\n",
      " |      0    A     2     0    a\n",
      " |      1    A     1     1    B\n",
      " |      3  NaN     8     4    D\n",
      " |      \n",
      " |      Putting NAs first\n",
      " |      \n",
      " |      >>> df.sort_values(by='col1', ascending=False, na_position='first')\n",
      " |        col1  col2  col3 col4\n",
      " |      3  NaN     8     4    D\n",
      " |      4    D     7     2    e\n",
      " |      5    C     4     3    F\n",
      " |      2    B     9     9    c\n",
      " |      0    A     2     0    a\n",
      " |      1    A     1     1    B\n",
      " |      \n",
      " |      Sorting with a key function\n",
      " |      \n",
      " |      >>> df.sort_values(by='col4', key=lambda col: col.str.lower())\n",
      " |         col1  col2  col3 col4\n",
      " |      0    A     2     0    a\n",
      " |      1    A     1     1    B\n",
      " |      2    B     9     9    c\n",
      " |      3  NaN     8     4    D\n",
      " |      4    D     7     2    e\n",
      " |      5    C     4     3    F\n",
      " |      \n",
      " |      Natural sort with the key argument,\n",
      " |      using the `natsort <https://github.com/SethMMorton/natsort>` package.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...    \"time\": ['0hr', '128hr', '72hr', '48hr', '96hr'],\n",
      " |      ...    \"value\": [10, 20, 30, 40, 50]\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |          time  value\n",
      " |      0    0hr     10\n",
      " |      1  128hr     20\n",
      " |      2   72hr     30\n",
      " |      3   48hr     40\n",
      " |      4   96hr     50\n",
      " |      >>> from natsort import index_natsorted\n",
      " |      >>> df.sort_values(\n",
      " |      ...    by=\"time\",\n",
      " |      ...    key=lambda x: np.argsort(index_natsorted(df[\"time\"]))\n",
      " |      ... )\n",
      " |          time  value\n",
      " |      0    0hr     10\n",
      " |      3   48hr     40\n",
      " |      2   72hr     30\n",
      " |      4   96hr     50\n",
      " |      1  128hr     20\n",
      " |  \n",
      " |  stack(self, level: 'Level' = -1, dropna: 'bool' = True)\n",
      " |      Stack the prescribed level(s) from columns to index.\n",
      " |      \n",
      " |      Return a reshaped DataFrame or Series having a multi-level\n",
      " |      index with one or more new inner-most levels compared to the current\n",
      " |      DataFrame. The new inner-most levels are created by pivoting the\n",
      " |      columns of the current dataframe:\n",
      " |      \n",
      " |        - if the columns have a single level, the output is a Series;\n",
      " |        - if the columns have multiple levels, the new index\n",
      " |          level(s) is (are) taken from the prescribed level(s) and\n",
      " |          the output is a DataFrame.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, str, list, default -1\n",
      " |          Level(s) to stack from the column axis onto the index\n",
      " |          axis, defined as one index or label, or a list of indices\n",
      " |          or labels.\n",
      " |      dropna : bool, default True\n",
      " |          Whether to drop rows in the resulting Frame/Series with\n",
      " |          missing values. Stacking a column level onto the index\n",
      " |          axis can create combinations of index and column values\n",
      " |          that are missing from the original dataframe. See Examples\n",
      " |          section.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or Series\n",
      " |          Stacked dataframe or series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.unstack : Unstack prescribed level(s) from index axis\n",
      " |           onto column axis.\n",
      " |      DataFrame.pivot : Reshape dataframe from long format to wide\n",
      " |           format.\n",
      " |      DataFrame.pivot_table : Create a spreadsheet-style pivot table\n",
      " |           as a DataFrame.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The function is named by analogy with a collection of books\n",
      " |      being reorganized from being side by side on a horizontal\n",
      " |      position (the columns of the dataframe) to being stacked\n",
      " |      vertically on top of each other (in the index of the\n",
      " |      dataframe).\n",
      " |      \n",
      " |      Reference :ref:`the user guide <reshaping.stacking>` for more examples.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Single level columns**\n",
      " |      \n",
      " |      >>> df_single_level_cols = pd.DataFrame([[0, 1], [2, 3]],\n",
      " |      ...                                     index=['cat', 'dog'],\n",
      " |      ...                                     columns=['weight', 'height'])\n",
      " |      \n",
      " |      Stacking a dataframe with a single level column axis returns a Series:\n",
      " |      \n",
      " |      >>> df_single_level_cols\n",
      " |           weight height\n",
      " |      cat       0      1\n",
      " |      dog       2      3\n",
      " |      >>> df_single_level_cols.stack()\n",
      " |      cat  weight    0\n",
      " |           height    1\n",
      " |      dog  weight    2\n",
      " |           height    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      **Multi level columns: simple case**\n",
      " |      \n",
      " |      >>> multicol1 = pd.MultiIndex.from_tuples([('weight', 'kg'),\n",
      " |      ...                                        ('weight', 'pounds')])\n",
      " |      >>> df_multi_level_cols1 = pd.DataFrame([[1, 2], [2, 4]],\n",
      " |      ...                                     index=['cat', 'dog'],\n",
      " |      ...                                     columns=multicol1)\n",
      " |      \n",
      " |      Stacking a dataframe with a multi-level column axis:\n",
      " |      \n",
      " |      >>> df_multi_level_cols1\n",
      " |           weight\n",
      " |               kg    pounds\n",
      " |      cat       1        2\n",
      " |      dog       2        4\n",
      " |      >>> df_multi_level_cols1.stack()\n",
      " |                  weight\n",
      " |      cat kg           1\n",
      " |          pounds       2\n",
      " |      dog kg           2\n",
      " |          pounds       4\n",
      " |      \n",
      " |      **Missing values**\n",
      " |      \n",
      " |      >>> multicol2 = pd.MultiIndex.from_tuples([('weight', 'kg'),\n",
      " |      ...                                        ('height', 'm')])\n",
      " |      >>> df_multi_level_cols2 = pd.DataFrame([[1.0, 2.0], [3.0, 4.0]],\n",
      " |      ...                                     index=['cat', 'dog'],\n",
      " |      ...                                     columns=multicol2)\n",
      " |      \n",
      " |      It is common to have missing values when stacking a dataframe\n",
      " |      with multi-level columns, as the stacked dataframe typically\n",
      " |      has more values than the original dataframe. Missing values\n",
      " |      are filled with NaNs:\n",
      " |      \n",
      " |      >>> df_multi_level_cols2\n",
      " |          weight height\n",
      " |              kg      m\n",
      " |      cat    1.0    2.0\n",
      " |      dog    3.0    4.0\n",
      " |      >>> df_multi_level_cols2.stack()\n",
      " |              height  weight\n",
      " |      cat kg     NaN     1.0\n",
      " |          m      2.0     NaN\n",
      " |      dog kg     NaN     3.0\n",
      " |          m      4.0     NaN\n",
      " |      \n",
      " |      **Prescribing the level(s) to be stacked**\n",
      " |      \n",
      " |      The first parameter controls which level or levels are stacked:\n",
      " |      \n",
      " |      >>> df_multi_level_cols2.stack(0)\n",
      " |                   kg    m\n",
      " |      cat height  NaN  2.0\n",
      " |          weight  1.0  NaN\n",
      " |      dog height  NaN  4.0\n",
      " |          weight  3.0  NaN\n",
      " |      >>> df_multi_level_cols2.stack([0, 1])\n",
      " |      cat  height  m     2.0\n",
      " |           weight  kg    1.0\n",
      " |      dog  height  m     4.0\n",
      " |           weight  kg    3.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **Dropping missing values**\n",
      " |      \n",
      " |      >>> df_multi_level_cols3 = pd.DataFrame([[None, 1.0], [2.0, 3.0]],\n",
      " |      ...                                     index=['cat', 'dog'],\n",
      " |      ...                                     columns=multicol2)\n",
      " |      \n",
      " |      Note that rows where all values are missing are dropped by\n",
      " |      default but this behaviour can be controlled via the dropna\n",
      " |      keyword parameter:\n",
      " |      \n",
      " |      >>> df_multi_level_cols3\n",
      " |          weight height\n",
      " |              kg      m\n",
      " |      cat    NaN    1.0\n",
      " |      dog    2.0    3.0\n",
      " |      >>> df_multi_level_cols3.stack(dropna=False)\n",
      " |              height  weight\n",
      " |      cat kg     NaN     NaN\n",
      " |          m      1.0     NaN\n",
      " |      dog kg     NaN     2.0\n",
      " |          m      3.0     NaN\n",
      " |      >>> df_multi_level_cols3.stack(dropna=True)\n",
      " |              height  weight\n",
      " |      cat m      1.0     NaN\n",
      " |      dog kg     NaN     2.0\n",
      " |          m      3.0     NaN\n",
      " |  \n",
      " |  std(self, axis=None, skipna=True, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      " |      Return sample standard deviation over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      ddof : int, default 1\n",
      " |          Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\n",
      " |          where N represents the number of elements.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified) \n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      To have the same behaviour as `numpy.std`, use `ddof=0` (instead of the\n",
      " |      default `ddof=1`)\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'person_id': [0, 1, 2, 3],\n",
      " |      ...                   'age': [21, 25, 62, 43],\n",
      " |      ...                   'height': [1.61, 1.87, 1.49, 2.01]}\n",
      " |      ...                  ).set_index('person_id')\n",
      " |      >>> df\n",
      " |                 age  height\n",
      " |      person_id\n",
      " |      0           21    1.61\n",
      " |      1           25    1.87\n",
      " |      2           62    1.49\n",
      " |      3           43    2.01\n",
      " |      \n",
      " |      The standard deviation of the columns can be found as follows:\n",
      " |      \n",
      " |      >>> df.std()\n",
      " |      age       18.786076\n",
      " |      height     0.237417\n",
      " |      \n",
      " |      Alternatively, `ddof=0` can be set to normalize by N instead of N-1:\n",
      " |      \n",
      " |      >>> df.std(ddof=0)\n",
      " |      age       16.269219\n",
      " |      height     0.205609\n",
      " |  \n",
      " |  sub(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Subtraction of dataframe and other, element-wise (binary operator `sub`).\n",
      " |      \n",
      " |      Equivalent to ``dataframe - other``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `rsub`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  subtract = sub(self, other, axis='columns', level=None, fill_value=None)\n",
      " |  \n",
      " |  sum(self, axis=None, skipna=True, level=None, numeric_only=None, min_count=0, **kwargs)\n",
      " |      Return the sum of the values over the requested axis.\n",
      " |      \n",
      " |      This is equivalent to the method ``numpy.sum``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      min_count : int, default 0\n",
      " |          The required number of valid values to perform the operation. If fewer than\n",
      " |          ``min_count`` non-NA values are present the result will be NA.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sum : Return the sum.\n",
      " |      Series.min : Return the minimum.\n",
      " |      Series.max : Return the maximum.\n",
      " |      Series.idxmin : Return the index of the minimum.\n",
      " |      Series.idxmax : Return the index of the maximum.\n",
      " |      DataFrame.sum : Return the sum over the requested axis.\n",
      " |      DataFrame.min : Return the minimum over the requested axis.\n",
      " |      DataFrame.max : Return the maximum over the requested axis.\n",
      " |      DataFrame.idxmin : Return the index of the minimum over the requested axis.\n",
      " |      DataFrame.idxmax : Return the index of the maximum over the requested axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.MultiIndex.from_arrays([\n",
      " |      ...     ['warm', 'warm', 'cold', 'cold'],\n",
      " |      ...     ['dog', 'falcon', 'fish', 'spider']],\n",
      " |      ...     names=['blooded', 'animal'])\n",
      " |      >>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)\n",
      " |      >>> s\n",
      " |      blooded  animal\n",
      " |      warm     dog       4\n",
      " |               falcon    2\n",
      " |      cold     fish      0\n",
      " |               spider    8\n",
      " |      Name: legs, dtype: int64\n",
      " |      \n",
      " |      >>> s.sum()\n",
      " |      14\n",
      " |      \n",
      " |      By default, the sum of an empty or all-NA Series is ``0``.\n",
      " |      \n",
      " |      >>> pd.Series([], dtype=\"float64\").sum()  # min_count=0 is the default\n",
      " |      0.0\n",
      " |      \n",
      " |      This can be controlled with the ``min_count`` parameter. For example, if\n",
      " |      you'd like the sum of an empty series to be NaN, pass ``min_count=1``.\n",
      " |      \n",
      " |      >>> pd.Series([], dtype=\"float64\").sum(min_count=1)\n",
      " |      nan\n",
      " |      \n",
      " |      Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and\n",
      " |      empty series identically.\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).sum()\n",
      " |      0.0\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).sum(min_count=1)\n",
      " |      nan\n",
      " |  \n",
      " |  swaplevel(self, i: 'Axis' = -2, j: 'Axis' = -1, axis: 'Axis' = 0) -> 'DataFrame'\n",
      " |      Swap levels i and j in a :class:`MultiIndex`.\n",
      " |      \n",
      " |      Default is to swap the two innermost levels of the index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      i, j : int or str\n",
      " |          Levels of the indices to be swapped. Can pass level name as string.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |                  The axis to swap levels on. 0 or 'index' for row-wise, 1 or\n",
      " |                  'columns' for column-wise.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          DataFrame with levels swapped in MultiIndex.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(\n",
      " |      ...     {\"Grade\": [\"A\", \"B\", \"A\", \"C\"]},\n",
      " |      ...     index=[\n",
      " |      ...         [\"Final exam\", \"Final exam\", \"Coursework\", \"Coursework\"],\n",
      " |      ...         [\"History\", \"Geography\", \"History\", \"Geography\"],\n",
      " |      ...         [\"January\", \"February\", \"March\", \"April\"],\n",
      " |      ...     ],\n",
      " |      ... )\n",
      " |      >>> df\n",
      " |                                          Grade\n",
      " |      Final exam  History     January      A\n",
      " |                  Geography   February     B\n",
      " |      Coursework  History     March        A\n",
      " |                  Geography   April        C\n",
      " |      \n",
      " |      In the following example, we will swap the levels of the indices.\n",
      " |      Here, we will swap the levels column-wise, but levels can be swapped row-wise\n",
      " |      in a similar manner. Note that column-wise is the default behaviour.\n",
      " |      By not supplying any arguments for i and j, we swap the last and second to\n",
      " |      last indices.\n",
      " |      \n",
      " |      >>> df.swaplevel()\n",
      " |                                          Grade\n",
      " |      Final exam  January     History         A\n",
      " |                  February    Geography       B\n",
      " |      Coursework  March       History         A\n",
      " |                  April       Geography       C\n",
      " |      \n",
      " |      By supplying one argument, we can choose which index to swap the last\n",
      " |      index with. We can for example swap the first index with the last one as\n",
      " |      follows.\n",
      " |      \n",
      " |      >>> df.swaplevel(0)\n",
      " |                                          Grade\n",
      " |      January     History     Final exam      A\n",
      " |      February    Geography   Final exam      B\n",
      " |      March       History     Coursework      A\n",
      " |      April       Geography   Coursework      C\n",
      " |      \n",
      " |      We can also define explicitly which indices we want to swap by supplying values\n",
      " |      for both i and j. Here, we for example swap the first and second indices.\n",
      " |      \n",
      " |      >>> df.swaplevel(0, 1)\n",
      " |                                          Grade\n",
      " |      History     Final exam  January         A\n",
      " |      Geography   Final exam  February        B\n",
      " |      History     Coursework  March           A\n",
      " |      Geography   Coursework  April           C\n",
      " |  \n",
      " |  to_dict(self, orient: 'str' = 'dict', into=<class 'dict'>)\n",
      " |      Convert the DataFrame to a dictionary.\n",
      " |      \n",
      " |      The type of the key-value pairs can be customized with the parameters\n",
      " |      (see below).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      orient : str {'dict', 'list', 'series', 'split', 'records', 'index'}\n",
      " |          Determines the type of the values of the dictionary.\n",
      " |      \n",
      " |          - 'dict' (default) : dict like {column -> {index -> value}}\n",
      " |          - 'list' : dict like {column -> [values]}\n",
      " |          - 'series' : dict like {column -> Series(values)}\n",
      " |          - 'split' : dict like\n",
      " |            {'index' -> [index], 'columns' -> [columns], 'data' -> [values]}\n",
      " |          - 'tight' : dict like\n",
      " |            {'index' -> [index], 'columns' -> [columns], 'data' -> [values],\n",
      " |            'index_names' -> [index.names], 'column_names' -> [column.names]}\n",
      " |          - 'records' : list like\n",
      " |            [{column -> value}, ... , {column -> value}]\n",
      " |          - 'index' : dict like {index -> {column -> value}}\n",
      " |      \n",
      " |          Abbreviations are allowed. `s` indicates `series` and `sp`\n",
      " |          indicates `split`.\n",
      " |      \n",
      " |          .. versionadded:: 1.4.0\n",
      " |              'tight' as an allowed value for the ``orient`` argument\n",
      " |      \n",
      " |      into : class, default dict\n",
      " |          The collections.abc.Mapping subclass used for all Mappings\n",
      " |          in the return value.  Can be the actual class or an empty\n",
      " |          instance of the mapping type you want.  If you want a\n",
      " |          collections.defaultdict, you must pass it initialized.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dict, list or collections.abc.Mapping\n",
      " |          Return a collections.abc.Mapping object representing the DataFrame.\n",
      " |          The resulting transformation depends on the `orient` parameter.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.from_dict: Create a DataFrame from a dictionary.\n",
      " |      DataFrame.to_json: Convert a DataFrame to JSON format.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2],\n",
      " |      ...                    'col2': [0.5, 0.75]},\n",
      " |      ...                   index=['row1', 'row2'])\n",
      " |      >>> df\n",
      " |            col1  col2\n",
      " |      row1     1  0.50\n",
      " |      row2     2  0.75\n",
      " |      >>> df.to_dict()\n",
      " |      {'col1': {'row1': 1, 'row2': 2}, 'col2': {'row1': 0.5, 'row2': 0.75}}\n",
      " |      \n",
      " |      You can specify the return orientation.\n",
      " |      \n",
      " |      >>> df.to_dict('series')\n",
      " |      {'col1': row1    1\n",
      " |               row2    2\n",
      " |      Name: col1, dtype: int64,\n",
      " |      'col2': row1    0.50\n",
      " |              row2    0.75\n",
      " |      Name: col2, dtype: float64}\n",
      " |      \n",
      " |      >>> df.to_dict('split')\n",
      " |      {'index': ['row1', 'row2'], 'columns': ['col1', 'col2'],\n",
      " |       'data': [[1, 0.5], [2, 0.75]]}\n",
      " |      \n",
      " |      >>> df.to_dict('records')\n",
      " |      [{'col1': 1, 'col2': 0.5}, {'col1': 2, 'col2': 0.75}]\n",
      " |      \n",
      " |      >>> df.to_dict('index')\n",
      " |      {'row1': {'col1': 1, 'col2': 0.5}, 'row2': {'col1': 2, 'col2': 0.75}}\n",
      " |      \n",
      " |      >>> df.to_dict('tight')\n",
      " |      {'index': ['row1', 'row2'], 'columns': ['col1', 'col2'],\n",
      " |       'data': [[1, 0.5], [2, 0.75]], 'index_names': [None], 'column_names': [None]}\n",
      " |      \n",
      " |      You can also specify the mapping type.\n",
      " |      \n",
      " |      >>> from collections import OrderedDict, defaultdict\n",
      " |      >>> df.to_dict(into=OrderedDict)\n",
      " |      OrderedDict([('col1', OrderedDict([('row1', 1), ('row2', 2)])),\n",
      " |                   ('col2', OrderedDict([('row1', 0.5), ('row2', 0.75)]))])\n",
      " |      \n",
      " |      If you want a `defaultdict`, you need to initialize it:\n",
      " |      \n",
      " |      >>> dd = defaultdict(list)\n",
      " |      >>> df.to_dict('records', into=dd)\n",
      " |      [defaultdict(<class 'list'>, {'col1': 1, 'col2': 0.5}),\n",
      " |       defaultdict(<class 'list'>, {'col1': 2, 'col2': 0.75})]\n",
      " |  \n",
      " |  to_feather(self, path: 'FilePath | WriteBuffer[bytes]', **kwargs) -> 'None'\n",
      " |      Write a DataFrame to the binary Feather format.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : str, path object, file-like object\n",
      " |          String, path object (implementing ``os.PathLike[str]``), or file-like\n",
      " |          object implementing a binary ``write()`` function. If a string or a path,\n",
      " |          it will be used as Root Directory path when writing a partitioned dataset.\n",
      " |      **kwargs :\n",
      " |          Additional keywords passed to :func:`pyarrow.feather.write_feather`.\n",
      " |          Starting with pyarrow 0.17, this includes the `compression`,\n",
      " |          `compression_level`, `chunksize` and `version` keywords.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This function writes the dataframe as a `feather file\n",
      " |      <https://arrow.apache.org/docs/python/feather.html>`_. Requires a default\n",
      " |      index. For saving the DataFrame with your custom index use a method that\n",
      " |      supports custom indices e.g. `to_parquet`.\n",
      " |  \n",
      " |  to_gbq(self, destination_table: 'str', project_id: 'str | None' = None, chunksize: 'int | None' = None, reauth: 'bool' = False, if_exists: 'str' = 'fail', auth_local_webserver: 'bool' = False, table_schema: 'list[dict[str, str]] | None' = None, location: 'str | None' = None, progress_bar: 'bool' = True, credentials=None) -> 'None'\n",
      " |      Write a DataFrame to a Google BigQuery table.\n",
      " |      \n",
      " |      This function requires the `pandas-gbq package\n",
      " |      <https://pandas-gbq.readthedocs.io>`__.\n",
      " |      \n",
      " |      See the `How to authenticate with Google BigQuery\n",
      " |      <https://pandas-gbq.readthedocs.io/en/latest/howto/authentication.html>`__\n",
      " |      guide for authentication instructions.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      destination_table : str\n",
      " |          Name of table to be written, in the form ``dataset.tablename``.\n",
      " |      project_id : str, optional\n",
      " |          Google BigQuery Account project ID. Optional when available from\n",
      " |          the environment.\n",
      " |      chunksize : int, optional\n",
      " |          Number of rows to be inserted in each chunk from the dataframe.\n",
      " |          Set to ``None`` to load the whole dataframe at once.\n",
      " |      reauth : bool, default False\n",
      " |          Force Google BigQuery to re-authenticate the user. This is useful\n",
      " |          if multiple accounts are used.\n",
      " |      if_exists : str, default 'fail'\n",
      " |          Behavior when the destination table exists. Value can be one of:\n",
      " |      \n",
      " |          ``'fail'``\n",
      " |              If table exists raise pandas_gbq.gbq.TableCreationError.\n",
      " |          ``'replace'``\n",
      " |              If table exists, drop it, recreate it, and insert data.\n",
      " |          ``'append'``\n",
      " |              If table exists, insert data. Create if does not exist.\n",
      " |      auth_local_webserver : bool, default False\n",
      " |          Use the `local webserver flow`_ instead of the `console flow`_\n",
      " |          when getting user credentials.\n",
      " |      \n",
      " |          .. _local webserver flow:\n",
      " |              https://google-auth-oauthlib.readthedocs.io/en/latest/reference/google_auth_oauthlib.flow.html#google_auth_oauthlib.flow.InstalledAppFlow.run_local_server\n",
      " |          .. _console flow:\n",
      " |              https://google-auth-oauthlib.readthedocs.io/en/latest/reference/google_auth_oauthlib.flow.html#google_auth_oauthlib.flow.InstalledAppFlow.run_console\n",
      " |      \n",
      " |          *New in version 0.2.0 of pandas-gbq*.\n",
      " |      table_schema : list of dicts, optional\n",
      " |          List of BigQuery table fields to which according DataFrame\n",
      " |          columns conform to, e.g. ``[{'name': 'col1', 'type':\n",
      " |          'STRING'},...]``. If schema is not provided, it will be\n",
      " |          generated according to dtypes of DataFrame columns. See\n",
      " |          BigQuery API documentation on available names of a field.\n",
      " |      \n",
      " |          *New in version 0.3.1 of pandas-gbq*.\n",
      " |      location : str, optional\n",
      " |          Location where the load job should run. See the `BigQuery locations\n",
      " |          documentation\n",
      " |          <https://cloud.google.com/bigquery/docs/dataset-locations>`__ for a\n",
      " |          list of available locations. The location must match that of the\n",
      " |          target dataset.\n",
      " |      \n",
      " |          *New in version 0.5.0 of pandas-gbq*.\n",
      " |      progress_bar : bool, default True\n",
      " |          Use the library `tqdm` to show the progress bar for the upload,\n",
      " |          chunk by chunk.\n",
      " |      \n",
      " |          *New in version 0.5.0 of pandas-gbq*.\n",
      " |      credentials : google.auth.credentials.Credentials, optional\n",
      " |          Credentials for accessing Google APIs. Use this parameter to\n",
      " |          override default credentials, such as to use Compute Engine\n",
      " |          :class:`google.auth.compute_engine.Credentials` or Service\n",
      " |          Account :class:`google.oauth2.service_account.Credentials`\n",
      " |          directly.\n",
      " |      \n",
      " |          *New in version 0.8.0 of pandas-gbq*.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas_gbq.to_gbq : This function in the pandas-gbq library.\n",
      " |      read_gbq : Read a DataFrame from Google BigQuery.\n",
      " |  \n",
      " |  to_html(self, buf: 'FilePath | WriteBuffer[str] | None' = None, columns: 'Sequence[str] | None' = None, col_space: 'ColspaceArgType | None' = None, header: 'bool | Sequence[str]' = True, index: 'bool' = True, na_rep: 'str' = 'NaN', formatters: 'FormattersType | None' = None, float_format: 'FloatFormatType | None' = None, sparsify: 'bool | None' = None, index_names: 'bool' = True, justify: 'str | None' = None, max_rows: 'int | None' = None, max_cols: 'int | None' = None, show_dimensions: 'bool | str' = False, decimal: 'str' = '.', bold_rows: 'bool' = True, classes: 'str | list | tuple | None' = None, escape: 'bool' = True, notebook: 'bool' = False, border: 'int | None' = None, table_id: 'str | None' = None, render_links: 'bool' = False, encoding: 'str | None' = None)\n",
      " |      Render a DataFrame as an HTML table.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      buf : str, Path or StringIO-like, optional, default None\n",
      " |          Buffer to write to. If None, the output is returned as a string.\n",
      " |      columns : sequence, optional, default None\n",
      " |          The subset of columns to write. Writes all columns by default.\n",
      " |      col_space : str or int, list or dict of int or str, optional\n",
      " |          The minimum width of each column in CSS length units.  An int is assumed to be px units.\n",
      " |      \n",
      " |          .. versionadded:: 0.25.0\n",
      " |              Ability to use str.\n",
      " |      header : bool, optional\n",
      " |          Whether to print column labels, default True.\n",
      " |      index : bool, optional, default True\n",
      " |          Whether to print index (row) labels.\n",
      " |      na_rep : str, optional, default 'NaN'\n",
      " |          String representation of ``NaN`` to use.\n",
      " |      formatters : list, tuple or dict of one-param. functions, optional\n",
      " |          Formatter functions to apply to columns' elements by position or\n",
      " |          name.\n",
      " |          The result of each function must be a unicode string.\n",
      " |          List/tuple must be of length equal to the number of columns.\n",
      " |      float_format : one-parameter function, optional, default None\n",
      " |          Formatter function to apply to columns' elements if they are\n",
      " |          floats. This function must return a unicode string and will be\n",
      " |          applied only to the non-``NaN`` elements, with ``NaN`` being\n",
      " |          handled by ``na_rep``.\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |      \n",
      " |      sparsify : bool, optional, default True\n",
      " |          Set to False for a DataFrame with a hierarchical index to print\n",
      " |          every multiindex key at each row.\n",
      " |      index_names : bool, optional, default True\n",
      " |          Prints the names of the indexes.\n",
      " |      justify : str, default None\n",
      " |          How to justify the column labels. If None uses the option from\n",
      " |          the print configuration (controlled by set_option), 'right' out\n",
      " |          of the box. Valid values are\n",
      " |      \n",
      " |          * left\n",
      " |          * right\n",
      " |          * center\n",
      " |          * justify\n",
      " |          * justify-all\n",
      " |          * start\n",
      " |          * end\n",
      " |          * inherit\n",
      " |          * match-parent\n",
      " |          * initial\n",
      " |          * unset.\n",
      " |      max_rows : int, optional\n",
      " |          Maximum number of rows to display in the console.\n",
      " |      max_cols : int, optional\n",
      " |          Maximum number of columns to display in the console.\n",
      " |      show_dimensions : bool, default False\n",
      " |          Display DataFrame dimensions (number of rows by number of columns).\n",
      " |      decimal : str, default '.'\n",
      " |          Character recognized as decimal separator, e.g. ',' in Europe.\n",
      " |      \n",
      " |      bold_rows : bool, default True\n",
      " |          Make the row labels bold in the output.\n",
      " |      classes : str or list or tuple, default None\n",
      " |          CSS class(es) to apply to the resulting html table.\n",
      " |      escape : bool, default True\n",
      " |          Convert the characters <, >, and & to HTML-safe sequences.\n",
      " |      notebook : {True, False}, default False\n",
      " |          Whether the generated HTML is for IPython Notebook.\n",
      " |      border : int\n",
      " |          A ``border=border`` attribute is included in the opening\n",
      " |          `<table>` tag. Default ``pd.options.display.html.border``.\n",
      " |      table_id : str, optional\n",
      " |          A css id is included in the opening `<table>` tag if specified.\n",
      " |      render_links : bool, default False\n",
      " |          Convert URLs to HTML links.\n",
      " |      encoding : str, default \"utf-8\"\n",
      " |          Set character encoding.\n",
      " |      \n",
      " |          .. versionadded:: 1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str or None\n",
      " |          If buf is None, returns the result as a string. Otherwise returns\n",
      " |          None.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      to_string : Convert DataFrame to a string.\n",
      " |  \n",
      " |  to_markdown(self, buf: 'IO[str] | str | None' = None, mode: 'str' = 'wt', index: 'bool' = True, storage_options: 'StorageOptions' = None, **kwargs) -> 'str | None'\n",
      " |      Print DataFrame in Markdown-friendly format.\n",
      " |      \n",
      " |      .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      buf : str, Path or StringIO-like, optional, default None\n",
      " |          Buffer to write to. If None, the output is returned as a string.\n",
      " |      mode : str, optional\n",
      " |          Mode in which file is opened, \"wt\" by default.\n",
      " |      index : bool, optional, default True\n",
      " |          Add index (row) labels.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib`` as header options. For other URLs (e.g.\n",
      " |          starting with \"s3://\", and \"gcs://\") the key-value pairs are forwarded to\n",
      " |          ``fsspec``. Please see ``fsspec`` and ``urllib`` for more details.\n",
      " |      \n",
      " |          .. versionadded:: 1.2.0\n",
      " |      \n",
      " |      **kwargs\n",
      " |          These parameters will be passed to `tabulate                 <https://pypi.org/project/tabulate>`_.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str\n",
      " |          DataFrame in Markdown-friendly format.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Requires the `tabulate <https://pypi.org/project/tabulate>`_ package.\n",
      " |      \n",
      " |      Examples\n",
      " |              --------\n",
      " |              >>> df = pd.DataFrame(\n",
      " |              ...     data={\"animal_1\": [\"elk\", \"pig\"], \"animal_2\": [\"dog\", \"quetzal\"]}\n",
      " |              ... )\n",
      " |              >>> print(df.to_markdown())\n",
      " |              |    | animal_1   | animal_2   |\n",
      " |              |---:|:-----------|:-----------|\n",
      " |              |  0 | elk        | dog        |\n",
      " |              |  1 | pig        | quetzal    |\n",
      " |      \n",
      " |              Output markdown with a tabulate option.\n",
      " |      \n",
      " |              >>> print(df.to_markdown(tablefmt=\"grid\"))\n",
      " |              +----+------------+------------+\n",
      " |              |    | animal_1   | animal_2   |\n",
      " |              +====+============+============+\n",
      " |              |  0 | elk        | dog        |\n",
      " |              +----+------------+------------+\n",
      " |              |  1 | pig        | quetzal    |\n",
      " |              +----+------------+------------+\n",
      " |  \n",
      " |  to_numpy(self, dtype: 'npt.DTypeLike | None' = None, copy: 'bool' = False, na_value=<no_default>) -> 'np.ndarray'\n",
      " |      Convert the DataFrame to a NumPy array.\n",
      " |      \n",
      " |      By default, the dtype of the returned array will be the common NumPy\n",
      " |      dtype of all types in the DataFrame. For example, if the dtypes are\n",
      " |      ``float16`` and ``float32``, the results dtype will be ``float32``.\n",
      " |      This may require copying data and coercing values, which may be\n",
      " |      expensive.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dtype : str or numpy.dtype, optional\n",
      " |          The dtype to pass to :meth:`numpy.asarray`.\n",
      " |      copy : bool, default False\n",
      " |          Whether to ensure that the returned value is not a view on\n",
      " |          another array. Note that ``copy=False`` does not *ensure* that\n",
      " |          ``to_numpy()`` is no-copy. Rather, ``copy=True`` ensure that\n",
      " |          a copy is made, even if not strictly necessary.\n",
      " |      na_value : Any, optional\n",
      " |          The value to use for missing values. The default value depends\n",
      " |          on `dtype` and the dtypes of the DataFrame columns.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.to_numpy : Similar method for Series.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> pd.DataFrame({\"A\": [1, 2], \"B\": [3, 4]}).to_numpy()\n",
      " |      array([[1, 3],\n",
      " |             [2, 4]])\n",
      " |      \n",
      " |      With heterogeneous data, the lowest common type will have to\n",
      " |      be used.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2], \"B\": [3.0, 4.5]})\n",
      " |      >>> df.to_numpy()\n",
      " |      array([[1. , 3. ],\n",
      " |             [2. , 4.5]])\n",
      " |      \n",
      " |      For a mix of numeric and non-numeric types, the output array will\n",
      " |      have object dtype.\n",
      " |      \n",
      " |      >>> df['C'] = pd.date_range('2000', periods=2)\n",
      " |      >>> df.to_numpy()\n",
      " |      array([[1, 3.0, Timestamp('2000-01-01 00:00:00')],\n",
      " |             [2, 4.5, Timestamp('2000-01-02 00:00:00')]], dtype=object)\n",
      " |  \n",
      " |  to_parquet(self, path: 'FilePath | WriteBuffer[bytes] | None' = None, engine: 'str' = 'auto', compression: 'str | None' = 'snappy', index: 'bool | None' = None, partition_cols: 'list[str] | None' = None, storage_options: 'StorageOptions' = None, **kwargs) -> 'bytes | None'\n",
      " |      Write a DataFrame to the binary parquet format.\n",
      " |      \n",
      " |      This function writes the dataframe as a `parquet file\n",
      " |      <https://parquet.apache.org/>`_. You can choose different parquet\n",
      " |      backends, and have the option of compression. See\n",
      " |      :ref:`the user guide <io.parquet>` for more details.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : str, path object, file-like object, or None, default None\n",
      " |          String, path object (implementing ``os.PathLike[str]``), or file-like\n",
      " |          object implementing a binary ``write()`` function. If None, the result is\n",
      " |          returned as bytes. If a string or path, it will be used as Root Directory\n",
      " |          path when writing a partitioned dataset.\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |      \n",
      " |          Previously this was \"fname\"\n",
      " |      \n",
      " |      engine : {'auto', 'pyarrow', 'fastparquet'}, default 'auto'\n",
      " |          Parquet library to use. If 'auto', then the option\n",
      " |          ``io.parquet.engine`` is used. The default ``io.parquet.engine``\n",
      " |          behavior is to try 'pyarrow', falling back to 'fastparquet' if\n",
      " |          'pyarrow' is unavailable.\n",
      " |      compression : {'snappy', 'gzip', 'brotli', None}, default 'snappy'\n",
      " |          Name of the compression to use. Use ``None`` for no compression.\n",
      " |      index : bool, default None\n",
      " |          If ``True``, include the dataframe's index(es) in the file output.\n",
      " |          If ``False``, they will not be written to the file.\n",
      " |          If ``None``, similar to ``True`` the dataframe's index(es)\n",
      " |          will be saved. However, instead of being saved as values,\n",
      " |          the RangeIndex will be stored as a range in the metadata so it\n",
      " |          doesn't require much space and is faster. Other indexes will\n",
      " |          be included as columns in the file output.\n",
      " |      partition_cols : list, optional, default None\n",
      " |          Column names by which to partition the dataset.\n",
      " |          Columns are partitioned in the order they are given.\n",
      " |          Must be None if path is not a string.\n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib`` as header options. For other URLs (e.g.\n",
      " |          starting with \"s3://\", and \"gcs://\") the key-value pairs are forwarded to\n",
      " |          ``fsspec``. Please see ``fsspec`` and ``urllib`` for more details.\n",
      " |      \n",
      " |          .. versionadded:: 1.2.0\n",
      " |      \n",
      " |      **kwargs\n",
      " |          Additional arguments passed to the parquet library. See\n",
      " |          :ref:`pandas io <io.parquet>` for more details.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bytes if no path argument is provided else None\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_parquet : Read a parquet file.\n",
      " |      DataFrame.to_csv : Write a csv file.\n",
      " |      DataFrame.to_sql : Write to a sql table.\n",
      " |      DataFrame.to_hdf : Write to hdf.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This function requires either the `fastparquet\n",
      " |      <https://pypi.org/project/fastparquet>`_ or `pyarrow\n",
      " |      <https://arrow.apache.org/docs/python/>`_ library.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(data={'col1': [1, 2], 'col2': [3, 4]})\n",
      " |      >>> df.to_parquet('df.parquet.gzip',\n",
      " |      ...               compression='gzip')  # doctest: +SKIP\n",
      " |      >>> pd.read_parquet('df.parquet.gzip')  # doctest: +SKIP\n",
      " |         col1  col2\n",
      " |      0     1     3\n",
      " |      1     2     4\n",
      " |      \n",
      " |      If you want to get a buffer to the parquet content you can use a io.BytesIO\n",
      " |      object, as long as you don't use partition_cols, which creates multiple files.\n",
      " |      \n",
      " |      >>> import io\n",
      " |      >>> f = io.BytesIO()\n",
      " |      >>> df.to_parquet(f)\n",
      " |      >>> f.seek(0)\n",
      " |      0\n",
      " |      >>> content = f.read()\n",
      " |  \n",
      " |  to_period(self, freq: 'Frequency | None' = None, axis: 'Axis' = 0, copy: 'bool' = True) -> 'DataFrame'\n",
      " |      Convert DataFrame from DatetimeIndex to PeriodIndex.\n",
      " |      \n",
      " |      Convert DataFrame from DatetimeIndex to PeriodIndex with desired\n",
      " |      frequency (inferred from index if not passed).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : str, default\n",
      " |          Frequency of the PeriodIndex.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to convert (the index by default).\n",
      " |      copy : bool, default True\n",
      " |          If False then underlying input data is not copied.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame with PeriodIndex\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.to_datetime(\n",
      " |      ...     [\n",
      " |      ...         \"2001-03-31 00:00:00\",\n",
      " |      ...         \"2002-05-31 00:00:00\",\n",
      " |      ...         \"2003-08-31 00:00:00\",\n",
      " |      ...     ]\n",
      " |      ... )\n",
      " |      \n",
      " |      >>> idx\n",
      " |      DatetimeIndex(['2001-03-31', '2002-05-31', '2003-08-31'],\n",
      " |      dtype='datetime64[ns]', freq=None)\n",
      " |      \n",
      " |      >>> idx.to_period(\"M\")\n",
      " |      PeriodIndex(['2001-03', '2002-05', '2003-08'], dtype='period[M]')\n",
      " |      \n",
      " |      For the yearly frequency\n",
      " |      \n",
      " |      >>> idx.to_period(\"Y\")\n",
      " |      PeriodIndex(['2001', '2002', '2003'], dtype='period[A-DEC]')\n",
      " |  \n",
      " |  to_records(self, index=True, column_dtypes=None, index_dtypes=None) -> 'np.recarray'\n",
      " |      Convert DataFrame to a NumPy record array.\n",
      " |      \n",
      " |      Index will be included as the first field of the record array if\n",
      " |      requested.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : bool, default True\n",
      " |          Include index in resulting record array, stored in 'index'\n",
      " |          field or using the index label, if set.\n",
      " |      column_dtypes : str, type, dict, default None\n",
      " |          If a string or type, the data type to store all columns. If\n",
      " |          a dictionary, a mapping of column names and indices (zero-indexed)\n",
      " |          to specific data types.\n",
      " |      index_dtypes : str, type, dict, default None\n",
      " |          If a string or type, the data type to store all index levels. If\n",
      " |          a dictionary, a mapping of index level names and indices\n",
      " |          (zero-indexed) to specific data types.\n",
      " |      \n",
      " |          This mapping is applied only if `index=True`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.recarray\n",
      " |          NumPy ndarray with the DataFrame labels as fields and each row\n",
      " |          of the DataFrame as entries.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.from_records: Convert structured or record ndarray\n",
      " |          to DataFrame.\n",
      " |      numpy.recarray: An ndarray that allows field access using\n",
      " |          attributes, analogous to typed columns in a\n",
      " |          spreadsheet.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [1, 2], 'B': [0.5, 0.75]},\n",
      " |      ...                   index=['a', 'b'])\n",
      " |      >>> df\n",
      " |         A     B\n",
      " |      a  1  0.50\n",
      " |      b  2  0.75\n",
      " |      >>> df.to_records()\n",
      " |      rec.array([('a', 1, 0.5 ), ('b', 2, 0.75)],\n",
      " |                dtype=[('index', 'O'), ('A', '<i8'), ('B', '<f8')])\n",
      " |      \n",
      " |      If the DataFrame index has no label then the recarray field name\n",
      " |      is set to 'index'. If the index has a label then this is used as the\n",
      " |      field name:\n",
      " |      \n",
      " |      >>> df.index = df.index.rename(\"I\")\n",
      " |      >>> df.to_records()\n",
      " |      rec.array([('a', 1, 0.5 ), ('b', 2, 0.75)],\n",
      " |                dtype=[('I', 'O'), ('A', '<i8'), ('B', '<f8')])\n",
      " |      \n",
      " |      The index can be excluded from the record array:\n",
      " |      \n",
      " |      >>> df.to_records(index=False)\n",
      " |      rec.array([(1, 0.5 ), (2, 0.75)],\n",
      " |                dtype=[('A', '<i8'), ('B', '<f8')])\n",
      " |      \n",
      " |      Data types can be specified for the columns:\n",
      " |      \n",
      " |      >>> df.to_records(column_dtypes={\"A\": \"int32\"})\n",
      " |      rec.array([('a', 1, 0.5 ), ('b', 2, 0.75)],\n",
      " |                dtype=[('I', 'O'), ('A', '<i4'), ('B', '<f8')])\n",
      " |      \n",
      " |      As well as for the index:\n",
      " |      \n",
      " |      >>> df.to_records(index_dtypes=\"<S2\")\n",
      " |      rec.array([(b'a', 1, 0.5 ), (b'b', 2, 0.75)],\n",
      " |                dtype=[('I', 'S2'), ('A', '<i8'), ('B', '<f8')])\n",
      " |      \n",
      " |      >>> index_dtypes = f\"<S{df.index.str.len().max()}\"\n",
      " |      >>> df.to_records(index_dtypes=index_dtypes)\n",
      " |      rec.array([(b'a', 1, 0.5 ), (b'b', 2, 0.75)],\n",
      " |                dtype=[('I', 'S1'), ('A', '<i8'), ('B', '<f8')])\n",
      " |  \n",
      " |  to_stata(self, path: 'FilePath | WriteBuffer[bytes]', convert_dates: 'dict[Hashable, str] | None' = None, write_index: 'bool' = True, byteorder: 'str | None' = None, time_stamp: 'datetime.datetime | None' = None, data_label: 'str | None' = None, variable_labels: 'dict[Hashable, str] | None' = None, version: 'int | None' = 114, convert_strl: 'Sequence[Hashable] | None' = None, compression: 'CompressionOptions' = 'infer', storage_options: 'StorageOptions' = None, *, value_labels: 'dict[Hashable, dict[float | int, str]] | None' = None) -> 'None'\n",
      " |      Export DataFrame object to Stata dta format.\n",
      " |      \n",
      " |      Writes the DataFrame to a Stata dataset file.\n",
      " |      \"dta\" files contain a Stata dataset.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : str, path object, or buffer\n",
      " |          String, path object (implementing ``os.PathLike[str]``), or file-like\n",
      " |          object implementing a binary ``write()`` function.\n",
      " |      \n",
      " |          .. versionchanged:: 1.0.0\n",
      " |      \n",
      " |          Previously this was \"fname\"\n",
      " |      \n",
      " |      convert_dates : dict\n",
      " |          Dictionary mapping columns containing datetime types to stata\n",
      " |          internal format to use when writing the dates. Options are 'tc',\n",
      " |          'td', 'tm', 'tw', 'th', 'tq', 'ty'. Column can be either an integer\n",
      " |          or a name. Datetime columns that do not have a conversion type\n",
      " |          specified will be converted to 'tc'. Raises NotImplementedError if\n",
      " |          a datetime column has timezone information.\n",
      " |      write_index : bool\n",
      " |          Write the index to Stata dataset.\n",
      " |      byteorder : str\n",
      " |          Can be \">\", \"<\", \"little\", or \"big\". default is `sys.byteorder`.\n",
      " |      time_stamp : datetime\n",
      " |          A datetime to use as file creation date.  Default is the current\n",
      " |          time.\n",
      " |      data_label : str, optional\n",
      " |          A label for the data set.  Must be 80 characters or smaller.\n",
      " |      variable_labels : dict\n",
      " |          Dictionary containing columns as keys and variable labels as\n",
      " |          values. Each label must be 80 characters or smaller.\n",
      " |      version : {114, 117, 118, 119, None}, default 114\n",
      " |          Version to use in the output dta file. Set to None to let pandas\n",
      " |          decide between 118 or 119 formats depending on the number of\n",
      " |          columns in the frame. Version 114 can be read by Stata 10 and\n",
      " |          later. Version 117 can be read by Stata 13 or later. Version 118\n",
      " |          is supported in Stata 14 and later. Version 119 is supported in\n",
      " |          Stata 15 and later. Version 114 limits string variables to 244\n",
      " |          characters or fewer while versions 117 and later allow strings\n",
      " |          with lengths up to 2,000,000 characters. Versions 118 and 119\n",
      " |          support Unicode characters, and version 119 supports more than\n",
      " |          32,767 variables.\n",
      " |      \n",
      " |          Version 119 should usually only be used when the number of\n",
      " |          variables exceeds the capacity of dta format 118. Exporting\n",
      " |          smaller datasets in format 119 may have unintended consequences,\n",
      " |          and, as of November 2020, Stata SE cannot read version 119 files.\n",
      " |      \n",
      " |          .. versionchanged:: 1.0.0\n",
      " |      \n",
      " |              Added support for formats 118 and 119.\n",
      " |      \n",
      " |      convert_strl : list, optional\n",
      " |          List of column names to convert to string columns to Stata StrL\n",
      " |          format. Only available if version is 117.  Storing strings in the\n",
      " |          StrL format can produce smaller dta files if strings have more than\n",
      " |          8 characters and values are repeated.\n",
      " |      compression : str or dict, default 'infer'\n",
      " |          For on-the-fly compression of the output data. If 'infer' and 'path'\n",
      " |          path-like, then detect compression from the following extensions: '.gz',\n",
      " |          '.bz2', '.zip', '.xz', or '.zst' (otherwise no compression). Set to\n",
      " |          ``None`` for no compression. Can also be a dict with key ``'method'`` set\n",
      " |          to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``} and other\n",
      " |          key-value pairs are forwarded to ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
      " |          ``bz2.BZ2File``, or ``zstandard.ZstdDecompressor``, respectively. As an\n",
      " |          example, the following could be passed for faster compression and to create\n",
      " |          a reproducible gzip archive:\n",
      " |          ``compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}``.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |          .. versionchanged:: 1.4.0 Zstandard support.\n",
      " |      \n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib`` as header options. For other URLs (e.g.\n",
      " |          starting with \"s3://\", and \"gcs://\") the key-value pairs are forwarded to\n",
      " |          ``fsspec``. Please see ``fsspec`` and ``urllib`` for more details.\n",
      " |      \n",
      " |          .. versionadded:: 1.2.0\n",
      " |      \n",
      " |      value_labels : dict of dicts\n",
      " |          Dictionary containing columns as keys and dictionaries of column value\n",
      " |          to labels as values. Labels for a single variable must be 32,000\n",
      " |          characters or smaller.\n",
      " |      \n",
      " |          .. versionadded:: 1.4.0\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      NotImplementedError\n",
      " |          * If datetimes contain timezone information\n",
      " |          * Column dtype is not representable in Stata\n",
      " |      ValueError\n",
      " |          * Columns listed in convert_dates are neither datetime64[ns]\n",
      " |            or datetime.datetime\n",
      " |          * Column listed in convert_dates is not in DataFrame\n",
      " |          * Categorical label contains more than 32,000 characters\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_stata : Import Stata data files.\n",
      " |      io.stata.StataWriter : Low-level writer for Stata data files.\n",
      " |      io.stata.StataWriter117 : Low-level writer for version 117 files.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'animal': ['falcon', 'parrot', 'falcon',\n",
      " |      ...                               'parrot'],\n",
      " |      ...                    'speed': [350, 18, 361, 15]})\n",
      " |      >>> df.to_stata('animals.dta')  # doctest: +SKIP\n",
      " |  \n",
      " |  to_string(self, buf: 'FilePath | WriteBuffer[str] | None' = None, columns: 'Sequence[str] | None' = None, col_space: 'int | list[int] | dict[Hashable, int] | None' = None, header: 'bool | Sequence[str]' = True, index: 'bool' = True, na_rep: 'str' = 'NaN', formatters: 'fmt.FormattersType | None' = None, float_format: 'fmt.FloatFormatType | None' = None, sparsify: 'bool | None' = None, index_names: 'bool' = True, justify: 'str | None' = None, max_rows: 'int | None' = None, max_cols: 'int | None' = None, show_dimensions: 'bool' = False, decimal: 'str' = '.', line_width: 'int | None' = None, min_rows: 'int | None' = None, max_colwidth: 'int | None' = None, encoding: 'str | None' = None) -> 'str | None'\n",
      " |      Render a DataFrame to a console-friendly tabular output.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      buf : str, Path or StringIO-like, optional, default None\n",
      " |          Buffer to write to. If None, the output is returned as a string.\n",
      " |      columns : sequence, optional, default None\n",
      " |          The subset of columns to write. Writes all columns by default.\n",
      " |      col_space : int, list or dict of int, optional\n",
      " |          The minimum width of each column. If a list of ints is given every integers corresponds with one column. If a dict is given, the key references the column, while the value defines the space to use..\n",
      " |      header : bool or sequence of str, optional\n",
      " |          Write out the column names. If a list of strings is given, it is assumed to be aliases for the column names.\n",
      " |      index : bool, optional, default True\n",
      " |          Whether to print index (row) labels.\n",
      " |      na_rep : str, optional, default 'NaN'\n",
      " |          String representation of ``NaN`` to use.\n",
      " |      formatters : list, tuple or dict of one-param. functions, optional\n",
      " |          Formatter functions to apply to columns' elements by position or\n",
      " |          name.\n",
      " |          The result of each function must be a unicode string.\n",
      " |          List/tuple must be of length equal to the number of columns.\n",
      " |      float_format : one-parameter function, optional, default None\n",
      " |          Formatter function to apply to columns' elements if they are\n",
      " |          floats. This function must return a unicode string and will be\n",
      " |          applied only to the non-``NaN`` elements, with ``NaN`` being\n",
      " |          handled by ``na_rep``.\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |      \n",
      " |      sparsify : bool, optional, default True\n",
      " |          Set to False for a DataFrame with a hierarchical index to print\n",
      " |          every multiindex key at each row.\n",
      " |      index_names : bool, optional, default True\n",
      " |          Prints the names of the indexes.\n",
      " |      justify : str, default None\n",
      " |          How to justify the column labels. If None uses the option from\n",
      " |          the print configuration (controlled by set_option), 'right' out\n",
      " |          of the box. Valid values are\n",
      " |      \n",
      " |          * left\n",
      " |          * right\n",
      " |          * center\n",
      " |          * justify\n",
      " |          * justify-all\n",
      " |          * start\n",
      " |          * end\n",
      " |          * inherit\n",
      " |          * match-parent\n",
      " |          * initial\n",
      " |          * unset.\n",
      " |      max_rows : int, optional\n",
      " |          Maximum number of rows to display in the console.\n",
      " |      max_cols : int, optional\n",
      " |          Maximum number of columns to display in the console.\n",
      " |      show_dimensions : bool, default False\n",
      " |          Display DataFrame dimensions (number of rows by number of columns).\n",
      " |      decimal : str, default '.'\n",
      " |          Character recognized as decimal separator, e.g. ',' in Europe.\n",
      " |      \n",
      " |      line_width : int, optional\n",
      " |          Width to wrap a line in characters.\n",
      " |      min_rows : int, optional\n",
      " |          The number of rows to display in the console in a truncated repr\n",
      " |          (when number of rows is above `max_rows`).\n",
      " |      max_colwidth : int, optional\n",
      " |          Max width to truncate each column in characters. By default, no limit.\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |      encoding : str, default \"utf-8\"\n",
      " |          Set character encoding.\n",
      " |      \n",
      " |          .. versionadded:: 1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str or None\n",
      " |          If buf is None, returns the result as a string. Otherwise returns\n",
      " |          None.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      to_html : Convert DataFrame to HTML.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> d = {'col1': [1, 2, 3], 'col2': [4, 5, 6]}\n",
      " |      >>> df = pd.DataFrame(d)\n",
      " |      >>> print(df.to_string())\n",
      " |         col1  col2\n",
      " |      0     1     4\n",
      " |      1     2     5\n",
      " |      2     3     6\n",
      " |  \n",
      " |  to_timestamp(self, freq: 'Frequency | None' = None, how: 'str' = 'start', axis: 'Axis' = 0, copy: 'bool' = True) -> 'DataFrame'\n",
      " |      Cast to DatetimeIndex of timestamps, at *beginning* of period.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : str, default frequency of PeriodIndex\n",
      " |          Desired frequency.\n",
      " |      how : {'s', 'e', 'start', 'end'}\n",
      " |          Convention for converting period to timestamp; start of period\n",
      " |          vs. end.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to convert (the index by default).\n",
      " |      copy : bool, default True\n",
      " |          If False then underlying input data is not copied.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame with DatetimeIndex\n",
      " |  \n",
      " |  to_xml(self, path_or_buffer: 'FilePath | WriteBuffer[bytes] | WriteBuffer[str] | None' = None, index: 'bool' = True, root_name: 'str | None' = 'data', row_name: 'str | None' = 'row', na_rep: 'str | None' = None, attr_cols: 'list[str] | None' = None, elem_cols: 'list[str] | None' = None, namespaces: 'dict[str | None, str] | None' = None, prefix: 'str | None' = None, encoding: 'str' = 'utf-8', xml_declaration: 'bool | None' = True, pretty_print: 'bool | None' = True, parser: 'str | None' = 'lxml', stylesheet: 'FilePath | ReadBuffer[str] | ReadBuffer[bytes] | None' = None, compression: 'CompressionOptions' = 'infer', storage_options: 'StorageOptions' = None) -> 'str | None'\n",
      " |      Render a DataFrame to an XML document.\n",
      " |      \n",
      " |      .. versionadded:: 1.3.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buffer : str, path object, file-like object, or None, default None\n",
      " |          String, path object (implementing ``os.PathLike[str]``), or file-like\n",
      " |          object implementing a ``write()`` function. If None, the result is returned\n",
      " |          as a string.\n",
      " |      index : bool, default True\n",
      " |          Whether to include index in XML document.\n",
      " |      root_name : str, default 'data'\n",
      " |          The name of root element in XML document.\n",
      " |      row_name : str, default 'row'\n",
      " |          The name of row element in XML document.\n",
      " |      na_rep : str, optional\n",
      " |          Missing data representation.\n",
      " |      attr_cols : list-like, optional\n",
      " |          List of columns to write as attributes in row element.\n",
      " |          Hierarchical columns will be flattened with underscore\n",
      " |          delimiting the different levels.\n",
      " |      elem_cols : list-like, optional\n",
      " |          List of columns to write as children in row element. By default,\n",
      " |          all columns output as children of row element. Hierarchical\n",
      " |          columns will be flattened with underscore delimiting the\n",
      " |          different levels.\n",
      " |      namespaces : dict, optional\n",
      " |          All namespaces to be defined in root element. Keys of dict\n",
      " |          should be prefix names and values of dict corresponding URIs.\n",
      " |          Default namespaces should be given empty string key. For\n",
      " |          example, ::\n",
      " |      \n",
      " |              namespaces = {\"\": \"https://example.com\"}\n",
      " |      \n",
      " |      prefix : str, optional\n",
      " |          Namespace prefix to be used for every element and/or attribute\n",
      " |          in document. This should be one of the keys in ``namespaces``\n",
      " |          dict.\n",
      " |      encoding : str, default 'utf-8'\n",
      " |          Encoding of the resulting document.\n",
      " |      xml_declaration : bool, default True\n",
      " |          Whether to include the XML declaration at start of document.\n",
      " |      pretty_print : bool, default True\n",
      " |          Whether output should be pretty printed with indentation and\n",
      " |          line breaks.\n",
      " |      parser : {'lxml','etree'}, default 'lxml'\n",
      " |          Parser module to use for building of tree. Only 'lxml' and\n",
      " |          'etree' are supported. With 'lxml', the ability to use XSLT\n",
      " |          stylesheet is supported.\n",
      " |      stylesheet : str, path object or file-like object, optional\n",
      " |          A URL, file-like object, or a raw string containing an XSLT\n",
      " |          script used to transform the raw XML output. Script should use\n",
      " |          layout of elements and attributes from original output. This\n",
      " |          argument requires ``lxml`` to be installed. Only XSLT 1.0\n",
      " |          scripts and not later versions is currently supported.\n",
      " |      compression : str or dict, default 'infer'\n",
      " |          For on-the-fly compression of the output data. If 'infer' and 'path_or_buffer'\n",
      " |          path-like, then detect compression from the following extensions: '.gz',\n",
      " |          '.bz2', '.zip', '.xz', or '.zst' (otherwise no compression). Set to\n",
      " |          ``None`` for no compression. Can also be a dict with key ``'method'`` set\n",
      " |          to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``} and other\n",
      " |          key-value pairs are forwarded to ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
      " |          ``bz2.BZ2File``, or ``zstandard.ZstdDecompressor``, respectively. As an\n",
      " |          example, the following could be passed for faster compression and to create\n",
      " |          a reproducible gzip archive:\n",
      " |          ``compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}``.\n",
      " |      \n",
      " |          .. versionchanged:: 1.4.0 Zstandard support.\n",
      " |      \n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib`` as header options. For other URLs (e.g.\n",
      " |          starting with \"s3://\", and \"gcs://\") the key-value pairs are forwarded to\n",
      " |          ``fsspec``. Please see ``fsspec`` and ``urllib`` for more details.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      None or str\n",
      " |          If ``io`` is None, returns the resulting XML format as a\n",
      " |          string. Otherwise returns None.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      to_json : Convert the pandas object to a JSON string.\n",
      " |      to_html : Convert DataFrame to a html.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'shape': ['square', 'circle', 'triangle'],\n",
      " |      ...                    'degrees': [360, 360, 180],\n",
      " |      ...                    'sides': [4, np.nan, 3]})\n",
      " |      \n",
      " |      >>> df.to_xml()  # doctest: +SKIP\n",
      " |      <?xml version='1.0' encoding='utf-8'?>\n",
      " |      <data>\n",
      " |        <row>\n",
      " |          <index>0</index>\n",
      " |          <shape>square</shape>\n",
      " |          <degrees>360</degrees>\n",
      " |          <sides>4.0</sides>\n",
      " |        </row>\n",
      " |        <row>\n",
      " |          <index>1</index>\n",
      " |          <shape>circle</shape>\n",
      " |          <degrees>360</degrees>\n",
      " |          <sides/>\n",
      " |        </row>\n",
      " |        <row>\n",
      " |          <index>2</index>\n",
      " |          <shape>triangle</shape>\n",
      " |          <degrees>180</degrees>\n",
      " |          <sides>3.0</sides>\n",
      " |        </row>\n",
      " |      </data>\n",
      " |      \n",
      " |      >>> df.to_xml(attr_cols=[\n",
      " |      ...           'index', 'shape', 'degrees', 'sides'\n",
      " |      ...           ])  # doctest: +SKIP\n",
      " |      <?xml version='1.0' encoding='utf-8'?>\n",
      " |      <data>\n",
      " |        <row index=\"0\" shape=\"square\" degrees=\"360\" sides=\"4.0\"/>\n",
      " |        <row index=\"1\" shape=\"circle\" degrees=\"360\"/>\n",
      " |        <row index=\"2\" shape=\"triangle\" degrees=\"180\" sides=\"3.0\"/>\n",
      " |      </data>\n",
      " |      \n",
      " |      >>> df.to_xml(namespaces={\"doc\": \"https://example.com\"},\n",
      " |      ...           prefix=\"doc\")  # doctest: +SKIP\n",
      " |      <?xml version='1.0' encoding='utf-8'?>\n",
      " |      <doc:data xmlns:doc=\"https://example.com\">\n",
      " |        <doc:row>\n",
      " |          <doc:index>0</doc:index>\n",
      " |          <doc:shape>square</doc:shape>\n",
      " |          <doc:degrees>360</doc:degrees>\n",
      " |          <doc:sides>4.0</doc:sides>\n",
      " |        </doc:row>\n",
      " |        <doc:row>\n",
      " |          <doc:index>1</doc:index>\n",
      " |          <doc:shape>circle</doc:shape>\n",
      " |          <doc:degrees>360</doc:degrees>\n",
      " |          <doc:sides/>\n",
      " |        </doc:row>\n",
      " |        <doc:row>\n",
      " |          <doc:index>2</doc:index>\n",
      " |          <doc:shape>triangle</doc:shape>\n",
      " |          <doc:degrees>180</doc:degrees>\n",
      " |          <doc:sides>3.0</doc:sides>\n",
      " |        </doc:row>\n",
      " |      </doc:data>\n",
      " |  \n",
      " |  transform(self, func: 'AggFuncType', axis: 'Axis' = 0, *args, **kwargs) -> 'DataFrame'\n",
      " |      Call ``func`` on self producing a DataFrame with the same axis shape as self.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function, str, list-like or dict-like\n",
      " |          Function to use for transforming the data. If a function, must either\n",
      " |          work when passed a DataFrame or when passed to DataFrame.apply. If func\n",
      " |          is both list-like and dict-like, dict-like behavior takes precedence.\n",
      " |      \n",
      " |          Accepted combinations are:\n",
      " |      \n",
      " |          - function\n",
      " |          - string function name\n",
      " |          - list-like of functions and/or function names, e.g. ``[np.exp, 'sqrt']``\n",
      " |          - dict-like of axis labels -> functions, function names or list-like of such.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |              If 0 or 'index': apply function to each column.\n",
      " |              If 1 or 'columns': apply function to each row.\n",
      " |      *args\n",
      " |          Positional arguments to pass to `func`.\n",
      " |      **kwargs\n",
      " |          Keyword arguments to pass to `func`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          A DataFrame that must have the same length as self.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError : If the returned DataFrame has a different length than self.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.agg : Only perform aggregating type operations.\n",
      " |      DataFrame.apply : Invoke function on a DataFrame.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Functions that mutate the passed object can produce unexpected\n",
      " |      behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`\n",
      " |      for more details.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': range(3), 'B': range(1, 4)})\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  0  1\n",
      " |      1  1  2\n",
      " |      2  2  3\n",
      " |      >>> df.transform(lambda x: x + 1)\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      1  2  3\n",
      " |      2  3  4\n",
      " |      \n",
      " |      Even though the resulting DataFrame must have the same length as the\n",
      " |      input DataFrame, it is possible to provide several input functions:\n",
      " |      \n",
      " |      >>> s = pd.Series(range(3))\n",
      " |      >>> s\n",
      " |      0    0\n",
      " |      1    1\n",
      " |      2    2\n",
      " |      dtype: int64\n",
      " |      >>> s.transform([np.sqrt, np.exp])\n",
      " |             sqrt        exp\n",
      " |      0  0.000000   1.000000\n",
      " |      1  1.000000   2.718282\n",
      " |      2  1.414214   7.389056\n",
      " |      \n",
      " |      You can call transform on a GroupBy object:\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     \"Date\": [\n",
      " |      ...         \"2015-05-08\", \"2015-05-07\", \"2015-05-06\", \"2015-05-05\",\n",
      " |      ...         \"2015-05-08\", \"2015-05-07\", \"2015-05-06\", \"2015-05-05\"],\n",
      " |      ...     \"Data\": [5, 8, 6, 1, 50, 100, 60, 120],\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |               Date  Data\n",
      " |      0  2015-05-08     5\n",
      " |      1  2015-05-07     8\n",
      " |      2  2015-05-06     6\n",
      " |      3  2015-05-05     1\n",
      " |      4  2015-05-08    50\n",
      " |      5  2015-05-07   100\n",
      " |      6  2015-05-06    60\n",
      " |      7  2015-05-05   120\n",
      " |      >>> df.groupby('Date')['Data'].transform('sum')\n",
      " |      0     55\n",
      " |      1    108\n",
      " |      2     66\n",
      " |      3    121\n",
      " |      4     55\n",
      " |      5    108\n",
      " |      6     66\n",
      " |      7    121\n",
      " |      Name: Data, dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     \"c\": [1, 1, 1, 2, 2, 2, 2],\n",
      " |      ...     \"type\": [\"m\", \"n\", \"o\", \"m\", \"m\", \"n\", \"n\"]\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |         c type\n",
      " |      0  1    m\n",
      " |      1  1    n\n",
      " |      2  1    o\n",
      " |      3  2    m\n",
      " |      4  2    m\n",
      " |      5  2    n\n",
      " |      6  2    n\n",
      " |      >>> df['size'] = df.groupby('c')['type'].transform(len)\n",
      " |      >>> df\n",
      " |         c type size\n",
      " |      0  1    m    3\n",
      " |      1  1    n    3\n",
      " |      2  1    o    3\n",
      " |      3  2    m    4\n",
      " |      4  2    m    4\n",
      " |      5  2    n    4\n",
      " |      6  2    n    4\n",
      " |  \n",
      " |  transpose(self, *args, copy: 'bool' = False) -> 'DataFrame'\n",
      " |      Transpose index and columns.\n",
      " |      \n",
      " |      Reflect the DataFrame over its main diagonal by writing rows as columns\n",
      " |      and vice-versa. The property :attr:`.T` is an accessor to the method\n",
      " |      :meth:`transpose`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      *args : tuple, optional\n",
      " |          Accepted for compatibility with NumPy.\n",
      " |      copy : bool, default False\n",
      " |          Whether to copy the data after transposing, even for DataFrames\n",
      " |          with a single dtype.\n",
      " |      \n",
      " |          Note that a copy is always required for mixed dtype DataFrames,\n",
      " |          or for DataFrames with any extension types.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The transposed DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.transpose : Permute the dimensions of a given array.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Transposing a DataFrame with mixed dtypes will result in a homogeneous\n",
      " |      DataFrame with the `object` dtype. In such a case, a copy of the data\n",
      " |      is always made.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Square DataFrame with homogeneous dtype**\n",
      " |      \n",
      " |      >>> d1 = {'col1': [1, 2], 'col2': [3, 4]}\n",
      " |      >>> df1 = pd.DataFrame(data=d1)\n",
      " |      >>> df1\n",
      " |         col1  col2\n",
      " |      0     1     3\n",
      " |      1     2     4\n",
      " |      \n",
      " |      >>> df1_transposed = df1.T # or df1.transpose()\n",
      " |      >>> df1_transposed\n",
      " |            0  1\n",
      " |      col1  1  2\n",
      " |      col2  3  4\n",
      " |      \n",
      " |      When the dtype is homogeneous in the original DataFrame, we get a\n",
      " |      transposed DataFrame with the same dtype:\n",
      " |      \n",
      " |      >>> df1.dtypes\n",
      " |      col1    int64\n",
      " |      col2    int64\n",
      " |      dtype: object\n",
      " |      >>> df1_transposed.dtypes\n",
      " |      0    int64\n",
      " |      1    int64\n",
      " |      dtype: object\n",
      " |      \n",
      " |      **Non-square DataFrame with mixed dtypes**\n",
      " |      \n",
      " |      >>> d2 = {'name': ['Alice', 'Bob'],\n",
      " |      ...       'score': [9.5, 8],\n",
      " |      ...       'employed': [False, True],\n",
      " |      ...       'kids': [0, 0]}\n",
      " |      >>> df2 = pd.DataFrame(data=d2)\n",
      " |      >>> df2\n",
      " |          name  score  employed  kids\n",
      " |      0  Alice    9.5     False     0\n",
      " |      1    Bob    8.0      True     0\n",
      " |      \n",
      " |      >>> df2_transposed = df2.T # or df2.transpose()\n",
      " |      >>> df2_transposed\n",
      " |                    0     1\n",
      " |      name      Alice   Bob\n",
      " |      score       9.5   8.0\n",
      " |      employed  False  True\n",
      " |      kids          0     0\n",
      " |      \n",
      " |      When the DataFrame has mixed dtypes, we get a transposed DataFrame with\n",
      " |      the `object` dtype:\n",
      " |      \n",
      " |      >>> df2.dtypes\n",
      " |      name         object\n",
      " |      score       float64\n",
      " |      employed       bool\n",
      " |      kids          int64\n",
      " |      dtype: object\n",
      " |      >>> df2_transposed.dtypes\n",
      " |      0    object\n",
      " |      1    object\n",
      " |      dtype: object\n",
      " |  \n",
      " |  truediv(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Floating division of dataframe and other, element-wise (binary operator `truediv`).\n",
      " |      \n",
      " |      Equivalent to ``dataframe / other``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `rtruediv`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  unstack(self, level: 'Level' = -1, fill_value=None)\n",
      " |      Pivot a level of the (necessarily hierarchical) index labels.\n",
      " |      \n",
      " |      Returns a DataFrame having a new level of column labels whose inner-most level\n",
      " |      consists of the pivoted index labels.\n",
      " |      \n",
      " |      If the index is not a MultiIndex, the output will be a Series\n",
      " |      (the analogue of stack when the columns are not a MultiIndex).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, str, or list of these, default -1 (last level)\n",
      " |          Level(s) of index to unstack, can pass level name.\n",
      " |      fill_value : int, str or dict\n",
      " |          Replace NaN with this value if the unstack produces missing values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.pivot : Pivot a table based on column values.\n",
      " |      DataFrame.stack : Pivot a level of the column labels (inverse operation\n",
      " |          from `unstack`).\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Reference :ref:`the user guide <reshaping.stacking>` for more examples.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> index = pd.MultiIndex.from_tuples([('one', 'a'), ('one', 'b'),\n",
      " |      ...                                    ('two', 'a'), ('two', 'b')])\n",
      " |      >>> s = pd.Series(np.arange(1.0, 5.0), index=index)\n",
      " |      >>> s\n",
      " |      one  a   1.0\n",
      " |           b   2.0\n",
      " |      two  a   3.0\n",
      " |           b   4.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.unstack(level=-1)\n",
      " |           a   b\n",
      " |      one  1.0  2.0\n",
      " |      two  3.0  4.0\n",
      " |      \n",
      " |      >>> s.unstack(level=0)\n",
      " |         one  two\n",
      " |      a  1.0   3.0\n",
      " |      b  2.0   4.0\n",
      " |      \n",
      " |      >>> df = s.unstack(level=0)\n",
      " |      >>> df.unstack()\n",
      " |      one  a  1.0\n",
      " |           b  2.0\n",
      " |      two  a  3.0\n",
      " |           b  4.0\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  update(self, other, join: 'str' = 'left', overwrite: 'bool' = True, filter_func=None, errors: 'str' = 'ignore') -> 'None'\n",
      " |      Modify in place using non-NA values from another DataFrame.\n",
      " |      \n",
      " |      Aligns on indices. There is no return value.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame, or object coercible into a DataFrame\n",
      " |          Should have at least one matching index/column label\n",
      " |          with the original DataFrame. If a Series is passed,\n",
      " |          its name attribute must be set, and that will be\n",
      " |          used as the column name to align with the original DataFrame.\n",
      " |      join : {'left'}, default 'left'\n",
      " |          Only left join is implemented, keeping the index and columns of the\n",
      " |          original object.\n",
      " |      overwrite : bool, default True\n",
      " |          How to handle non-NA values for overlapping keys:\n",
      " |      \n",
      " |          * True: overwrite original DataFrame's values\n",
      " |            with values from `other`.\n",
      " |          * False: only update values that are NA in\n",
      " |            the original DataFrame.\n",
      " |      \n",
      " |      filter_func : callable(1d-array) -> bool 1d-array, optional\n",
      " |          Can choose to replace values other than NA. Return True for values\n",
      " |          that should be updated.\n",
      " |      errors : {'raise', 'ignore'}, default 'ignore'\n",
      " |          If 'raise', will raise a ValueError if the DataFrame and `other`\n",
      " |          both contain non-NA data in the same place.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      None : method directly changes calling object\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          * When `errors='raise'` and there's overlapping non-NA data.\n",
      " |          * When `errors` is not either `'ignore'` or `'raise'`\n",
      " |      NotImplementedError\n",
      " |          * If `join != 'left'`\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      dict.update : Similar method for dictionaries.\n",
      " |      DataFrame.merge : For column(s)-on-column(s) operations.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3],\n",
      " |      ...                    'B': [400, 500, 600]})\n",
      " |      >>> new_df = pd.DataFrame({'B': [4, 5, 6],\n",
      " |      ...                        'C': [7, 8, 9]})\n",
      " |      >>> df.update(new_df)\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  1  4\n",
      " |      1  2  5\n",
      " |      2  3  6\n",
      " |      \n",
      " |      The DataFrame's length does not increase as a result of the update,\n",
      " |      only values at matching index/column labels are updated.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': ['a', 'b', 'c'],\n",
      " |      ...                    'B': ['x', 'y', 'z']})\n",
      " |      >>> new_df = pd.DataFrame({'B': ['d', 'e', 'f', 'g', 'h', 'i']})\n",
      " |      >>> df.update(new_df)\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  a  d\n",
      " |      1  b  e\n",
      " |      2  c  f\n",
      " |      \n",
      " |      For Series, its name attribute must be set.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': ['a', 'b', 'c'],\n",
      " |      ...                    'B': ['x', 'y', 'z']})\n",
      " |      >>> new_column = pd.Series(['d', 'e'], name='B', index=[0, 2])\n",
      " |      >>> df.update(new_column)\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  a  d\n",
      " |      1  b  y\n",
      " |      2  c  e\n",
      " |      >>> df = pd.DataFrame({'A': ['a', 'b', 'c'],\n",
      " |      ...                    'B': ['x', 'y', 'z']})\n",
      " |      >>> new_df = pd.DataFrame({'B': ['d', 'e']}, index=[1, 2])\n",
      " |      >>> df.update(new_df)\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  a  x\n",
      " |      1  b  d\n",
      " |      2  c  e\n",
      " |      \n",
      " |      If `other` contains NaNs the corresponding values are not updated\n",
      " |      in the original dataframe.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3],\n",
      " |      ...                    'B': [400, 500, 600]})\n",
      " |      >>> new_df = pd.DataFrame({'B': [4, np.nan, 6]})\n",
      " |      >>> df.update(new_df)\n",
      " |      >>> df\n",
      " |         A      B\n",
      " |      0  1    4.0\n",
      " |      1  2  500.0\n",
      " |      2  3    6.0\n",
      " |  \n",
      " |  value_counts(self, subset: 'Sequence[Hashable] | None' = None, normalize: 'bool' = False, sort: 'bool' = True, ascending: 'bool' = False, dropna: 'bool' = True)\n",
      " |      Return a Series containing counts of unique rows in the DataFrame.\n",
      " |      \n",
      " |      .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      subset : list-like, optional\n",
      " |          Columns to use when counting unique combinations.\n",
      " |      normalize : bool, default False\n",
      " |          Return proportions rather than frequencies.\n",
      " |      sort : bool, default True\n",
      " |          Sort by frequencies.\n",
      " |      ascending : bool, default False\n",
      " |          Sort in ascending order.\n",
      " |      dropna : bool, default True\n",
      " |          Don’t include counts of rows that contain NA values.\n",
      " |      \n",
      " |          .. versionadded:: 1.3.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.value_counts: Equivalent method on Series.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The returned Series will have a MultiIndex with one level per input\n",
      " |      column. By default, rows that contain any NA values are omitted from\n",
      " |      the result. By default, the resulting Series will be in descending\n",
      " |      order so that the first element is the most frequently-occurring row.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'num_legs': [2, 4, 4, 6],\n",
      " |      ...                    'num_wings': [2, 0, 0, 0]},\n",
      " |      ...                   index=['falcon', 'dog', 'cat', 'ant'])\n",
      " |      >>> df\n",
      " |              num_legs  num_wings\n",
      " |      falcon         2          2\n",
      " |      dog            4          0\n",
      " |      cat            4          0\n",
      " |      ant            6          0\n",
      " |      \n",
      " |      >>> df.value_counts()\n",
      " |      num_legs  num_wings\n",
      " |      4         0            2\n",
      " |      2         2            1\n",
      " |      6         0            1\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df.value_counts(sort=False)\n",
      " |      num_legs  num_wings\n",
      " |      2         2            1\n",
      " |      4         0            2\n",
      " |      6         0            1\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df.value_counts(ascending=True)\n",
      " |      num_legs  num_wings\n",
      " |      2         2            1\n",
      " |      6         0            1\n",
      " |      4         0            2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df.value_counts(normalize=True)\n",
      " |      num_legs  num_wings\n",
      " |      4         0            0.50\n",
      " |      2         2            0.25\n",
      " |      6         0            0.25\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      With `dropna` set to `False` we can also count rows with NA values.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'first_name': ['John', 'Anne', 'John', 'Beth'],\n",
      " |      ...                    'middle_name': ['Smith', pd.NA, pd.NA, 'Louise']})\n",
      " |      >>> df\n",
      " |        first_name middle_name\n",
      " |      0       John       Smith\n",
      " |      1       Anne        <NA>\n",
      " |      2       John        <NA>\n",
      " |      3       Beth      Louise\n",
      " |      \n",
      " |      >>> df.value_counts()\n",
      " |      first_name  middle_name\n",
      " |      Beth        Louise         1\n",
      " |      John        Smith          1\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df.value_counts(dropna=False)\n",
      " |      first_name  middle_name\n",
      " |      Anne        NaN            1\n",
      " |      Beth        Louise         1\n",
      " |      John        Smith          1\n",
      " |                  NaN            1\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  var(self, axis=None, skipna=True, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      " |      Return unbiased variance over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      ddof : int, default 1\n",
      " |          Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\n",
      " |          where N represents the number of elements.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified) \n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'person_id': [0, 1, 2, 3],\n",
      " |      ...                   'age': [21, 25, 62, 43],\n",
      " |      ...                   'height': [1.61, 1.87, 1.49, 2.01]}\n",
      " |      ...                  ).set_index('person_id')\n",
      " |      >>> df\n",
      " |                 age  height\n",
      " |      person_id\n",
      " |      0           21    1.61\n",
      " |      1           25    1.87\n",
      " |      2           62    1.49\n",
      " |      3           43    2.01\n",
      " |      \n",
      " |      >>> df.var()\n",
      " |      age       352.916667\n",
      " |      height      0.056367\n",
      " |      \n",
      " |      Alternatively, ``ddof=0`` can be set to normalize by N instead of N-1:\n",
      " |      \n",
      " |      >>> df.var(ddof=0)\n",
      " |      age       264.687500\n",
      " |      height      0.042275\n",
      " |  \n",
      " |  where(self, cond, other=<no_default>, inplace=False, axis=None, level=None, errors='raise', try_cast=<no_default>)\n",
      " |      Replace values where the condition is False.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      cond : bool Series/DataFrame, array-like, or callable\n",
      " |          Where `cond` is True, keep the original value. Where\n",
      " |          False, replace with corresponding value from `other`.\n",
      " |          If `cond` is callable, it is computed on the Series/DataFrame and\n",
      " |          should return boolean Series/DataFrame or array. The callable must\n",
      " |          not change input Series/DataFrame (though pandas doesn't check it).\n",
      " |      other : scalar, Series/DataFrame, or callable\n",
      " |          Entries where `cond` is False are replaced with\n",
      " |          corresponding value from `other`.\n",
      " |          If other is callable, it is computed on the Series/DataFrame and\n",
      " |          should return scalar or Series/DataFrame. The callable must not\n",
      " |          change input Series/DataFrame (though pandas doesn't check it).\n",
      " |      inplace : bool, default False\n",
      " |          Whether to perform the operation in place on the data.\n",
      " |      axis : int, default None\n",
      " |          Alignment axis if needed.\n",
      " |      level : int, default None\n",
      " |          Alignment level if needed.\n",
      " |      errors : str, {'raise', 'ignore'}, default 'raise'\n",
      " |          Note that currently this parameter won't affect\n",
      " |          the results and will always coerce to a suitable dtype.\n",
      " |      \n",
      " |          - 'raise' : allow exceptions to be raised.\n",
      " |          - 'ignore' : suppress exceptions. On error return original object.\n",
      " |      \n",
      " |      try_cast : bool, default None\n",
      " |          Try to cast the result back to the input type (if possible).\n",
      " |      \n",
      " |          .. deprecated:: 1.3.0\n",
      " |              Manually cast back if necessary.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Same type as caller or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      :func:`DataFrame.mask` : Return an object of same shape as\n",
      " |          self.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The where method is an application of the if-then idiom. For each\n",
      " |      element in the calling DataFrame, if ``cond`` is ``True`` the\n",
      " |      element is used; otherwise the corresponding element from the DataFrame\n",
      " |      ``other`` is used.\n",
      " |      \n",
      " |      The signature for :func:`DataFrame.where` differs from\n",
      " |      :func:`numpy.where`. Roughly ``df1.where(m, df2)`` is equivalent to\n",
      " |      ``np.where(m, df1, df2)``.\n",
      " |      \n",
      " |      For further details and examples see the ``where`` documentation in\n",
      " |      :ref:`indexing <indexing.where_mask>`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(range(5))\n",
      " |      >>> s.where(s > 0)\n",
      " |      0    NaN\n",
      " |      1    1.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      4    4.0\n",
      " |      dtype: float64\n",
      " |      >>> s.mask(s > 0)\n",
      " |      0    0.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.where(s > 1, 10)\n",
      " |      0    10\n",
      " |      1    10\n",
      " |      2    2\n",
      " |      3    3\n",
      " |      4    4\n",
      " |      dtype: int64\n",
      " |      >>> s.mask(s > 1, 10)\n",
      " |      0     0\n",
      " |      1     1\n",
      " |      2    10\n",
      " |      3    10\n",
      " |      4    10\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  0  1\n",
      " |      1  2  3\n",
      " |      2  4  5\n",
      " |      3  6  7\n",
      " |      4  8  9\n",
      " |      >>> m = df % 3 == 0\n",
      " |      >>> df.where(m, -df)\n",
      " |         A  B\n",
      " |      0  0 -1\n",
      " |      1 -2  3\n",
      " |      2 -4 -5\n",
      " |      3  6 -7\n",
      " |      4 -8  9\n",
      " |      >>> df.where(m, -df) == np.where(m, df, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |      >>> df.where(m, -df) == df.mask(~m, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  from_dict(data, orient: 'str' = 'columns', dtype: 'Dtype | None' = None, columns=None) -> 'DataFrame' from builtins.type\n",
      " |      Construct DataFrame from dict of array-like or dicts.\n",
      " |      \n",
      " |      Creates DataFrame object from dictionary by columns or by index\n",
      " |      allowing dtype specification.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : dict\n",
      " |          Of the form {field : array-like} or {field : dict}.\n",
      " |      orient : {'columns', 'index', 'tight'}, default 'columns'\n",
      " |          The \"orientation\" of the data. If the keys of the passed dict\n",
      " |          should be the columns of the resulting DataFrame, pass 'columns'\n",
      " |          (default). Otherwise if the keys should be rows, pass 'index'.\n",
      " |          If 'tight', assume a dict with keys ['index', 'columns', 'data',\n",
      " |          'index_names', 'column_names'].\n",
      " |      \n",
      " |          .. versionadded:: 1.4.0\n",
      " |             'tight' as an allowed value for the ``orient`` argument\n",
      " |      \n",
      " |      dtype : dtype, default None\n",
      " |          Data type to force, otherwise infer.\n",
      " |      columns : list, default None\n",
      " |          Column labels to use when ``orient='index'``. Raises a ValueError\n",
      " |          if used with ``orient='columns'`` or ``orient='tight'``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.from_records : DataFrame from structured ndarray, sequence\n",
      " |          of tuples or dicts, or DataFrame.\n",
      " |      DataFrame : DataFrame object creation using constructor.\n",
      " |      DataFrame.to_dict : Convert the DataFrame to a dictionary.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      By default the keys of the dict become the DataFrame columns:\n",
      " |      \n",
      " |      >>> data = {'col_1': [3, 2, 1, 0], 'col_2': ['a', 'b', 'c', 'd']}\n",
      " |      >>> pd.DataFrame.from_dict(data)\n",
      " |         col_1 col_2\n",
      " |      0      3     a\n",
      " |      1      2     b\n",
      " |      2      1     c\n",
      " |      3      0     d\n",
      " |      \n",
      " |      Specify ``orient='index'`` to create the DataFrame using dictionary\n",
      " |      keys as rows:\n",
      " |      \n",
      " |      >>> data = {'row_1': [3, 2, 1, 0], 'row_2': ['a', 'b', 'c', 'd']}\n",
      " |      >>> pd.DataFrame.from_dict(data, orient='index')\n",
      " |             0  1  2  3\n",
      " |      row_1  3  2  1  0\n",
      " |      row_2  a  b  c  d\n",
      " |      \n",
      " |      When using the 'index' orientation, the column names can be\n",
      " |      specified manually:\n",
      " |      \n",
      " |      >>> pd.DataFrame.from_dict(data, orient='index',\n",
      " |      ...                        columns=['A', 'B', 'C', 'D'])\n",
      " |             A  B  C  D\n",
      " |      row_1  3  2  1  0\n",
      " |      row_2  a  b  c  d\n",
      " |      \n",
      " |      Specify ``orient='tight'`` to create the DataFrame using a 'tight'\n",
      " |      format:\n",
      " |      \n",
      " |      >>> data = {'index': [('a', 'b'), ('a', 'c')],\n",
      " |      ...         'columns': [('x', 1), ('y', 2)],\n",
      " |      ...         'data': [[1, 3], [2, 4]],\n",
      " |      ...         'index_names': ['n1', 'n2'],\n",
      " |      ...         'column_names': ['z1', 'z2']}\n",
      " |      >>> pd.DataFrame.from_dict(data, orient='tight')\n",
      " |      z1     x  y\n",
      " |      z2     1  2\n",
      " |      n1 n2\n",
      " |      a  b   1  3\n",
      " |         c   2  4\n",
      " |  \n",
      " |  from_records(data, index=None, exclude=None, columns=None, coerce_float: 'bool' = False, nrows: 'int | None' = None) -> 'DataFrame' from builtins.type\n",
      " |      Convert structured or record ndarray to DataFrame.\n",
      " |      \n",
      " |      Creates a DataFrame object from a structured ndarray, sequence of\n",
      " |      tuples or dicts, or DataFrame.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : structured ndarray, sequence of tuples or dicts, or DataFrame\n",
      " |          Structured input data.\n",
      " |      index : str, list of fields, array-like\n",
      " |          Field of array to use as the index, alternately a specific set of\n",
      " |          input labels to use.\n",
      " |      exclude : sequence, default None\n",
      " |          Columns or fields to exclude.\n",
      " |      columns : sequence, default None\n",
      " |          Column names to use. If the passed data do not have names\n",
      " |          associated with them, this argument provides names for the\n",
      " |          columns. Otherwise this argument indicates the order of the columns\n",
      " |          in the result (any names not found in the data will become all-NA\n",
      " |          columns).\n",
      " |      coerce_float : bool, default False\n",
      " |          Attempt to convert values of non-string, non-numeric objects (like\n",
      " |          decimal.Decimal) to floating point, useful for SQL result sets.\n",
      " |      nrows : int, default None\n",
      " |          Number of rows to read if data is an iterator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.from_dict : DataFrame from dict of array-like or dicts.\n",
      " |      DataFrame : DataFrame object creation using constructor.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Data can be provided as a structured ndarray:\n",
      " |      \n",
      " |      >>> data = np.array([(3, 'a'), (2, 'b'), (1, 'c'), (0, 'd')],\n",
      " |      ...                 dtype=[('col_1', 'i4'), ('col_2', 'U1')])\n",
      " |      >>> pd.DataFrame.from_records(data)\n",
      " |         col_1 col_2\n",
      " |      0      3     a\n",
      " |      1      2     b\n",
      " |      2      1     c\n",
      " |      3      0     d\n",
      " |      \n",
      " |      Data can be provided as a list of dicts:\n",
      " |      \n",
      " |      >>> data = [{'col_1': 3, 'col_2': 'a'},\n",
      " |      ...         {'col_1': 2, 'col_2': 'b'},\n",
      " |      ...         {'col_1': 1, 'col_2': 'c'},\n",
      " |      ...         {'col_1': 0, 'col_2': 'd'}]\n",
      " |      >>> pd.DataFrame.from_records(data)\n",
      " |         col_1 col_2\n",
      " |      0      3     a\n",
      " |      1      2     b\n",
      " |      2      1     c\n",
      " |      3      0     d\n",
      " |      \n",
      " |      Data can be provided as a list of tuples with corresponding columns:\n",
      " |      \n",
      " |      >>> data = [(3, 'a'), (2, 'b'), (1, 'c'), (0, 'd')]\n",
      " |      >>> pd.DataFrame.from_records(data, columns=['col_1', 'col_2'])\n",
      " |         col_1 col_2\n",
      " |      0      3     a\n",
      " |      1      2     b\n",
      " |      2      1     c\n",
      " |      3      0     d\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  T\n",
      " |  \n",
      " |  axes\n",
      " |      Return a list representing the axes of the DataFrame.\n",
      " |      \n",
      " |      It has the row axis labels and column axis labels as the only members.\n",
      " |      They are returned in that order.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n",
      " |      >>> df.axes\n",
      " |      [RangeIndex(start=0, stop=2, step=1), Index(['col1', 'col2'],\n",
      " |      dtype='object')]\n",
      " |  \n",
      " |  shape\n",
      " |      Return a tuple representing the dimensionality of the DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      ndarray.shape : Tuple of array dimensions.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n",
      " |      >>> df.shape\n",
      " |      (2, 2)\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4],\n",
      " |      ...                    'col3': [5, 6]})\n",
      " |      >>> df.shape\n",
      " |      (2, 3)\n",
      " |  \n",
      " |  style\n",
      " |      Returns a Styler object.\n",
      " |      \n",
      " |      Contains methods for building a styled HTML representation of the DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      io.formats.style.Styler : Helps style a DataFrame or Series according to the\n",
      " |          data with HTML and CSS.\n",
      " |  \n",
      " |  values\n",
      " |      Return a Numpy representation of the DataFrame.\n",
      " |      \n",
      " |      .. warning::\n",
      " |      \n",
      " |         We recommend using :meth:`DataFrame.to_numpy` instead.\n",
      " |      \n",
      " |      Only the values in the DataFrame will be returned, the axes labels\n",
      " |      will be removed.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray\n",
      " |          The values of the DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.to_numpy : Recommended alternative to this method.\n",
      " |      DataFrame.index : Retrieve the index labels.\n",
      " |      DataFrame.columns : Retrieving the column names.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The dtype will be a lower-common-denominator dtype (implicit\n",
      " |      upcasting); that is to say if the dtypes (even of numeric types)\n",
      " |      are mixed, the one that accommodates all will be chosen. Use this\n",
      " |      with care if you are not dealing with the blocks.\n",
      " |      \n",
      " |      e.g. If the dtypes are float16 and float32, dtype will be upcast to\n",
      " |      float32.  If dtypes are int32 and uint8, dtype will be upcast to\n",
      " |      int32. By :func:`numpy.find_common_type` convention, mixing int64\n",
      " |      and uint64 will result in a float64 dtype.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      A DataFrame where all columns are the same type (e.g., int64) results\n",
      " |      in an array of the same type.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'age':    [ 3,  29],\n",
      " |      ...                    'height': [94, 170],\n",
      " |      ...                    'weight': [31, 115]})\n",
      " |      >>> df\n",
      " |         age  height  weight\n",
      " |      0    3      94      31\n",
      " |      1   29     170     115\n",
      " |      >>> df.dtypes\n",
      " |      age       int64\n",
      " |      height    int64\n",
      " |      weight    int64\n",
      " |      dtype: object\n",
      " |      >>> df.values\n",
      " |      array([[  3,  94,  31],\n",
      " |             [ 29, 170, 115]])\n",
      " |      \n",
      " |      A DataFrame with mixed type columns(e.g., str/object, int64, float32)\n",
      " |      results in an ndarray of the broadest type that accommodates these\n",
      " |      mixed types (e.g., object).\n",
      " |      \n",
      " |      >>> df2 = pd.DataFrame([('parrot',   24.0, 'second'),\n",
      " |      ...                     ('lion',     80.5, 1),\n",
      " |      ...                     ('monkey', np.nan, None)],\n",
      " |      ...                   columns=('name', 'max_speed', 'rank'))\n",
      " |      >>> df2.dtypes\n",
      " |      name          object\n",
      " |      max_speed    float64\n",
      " |      rank          object\n",
      " |      dtype: object\n",
      " |      >>> df2.values\n",
      " |      array([['parrot', 24.0, 'second'],\n",
      " |             ['lion', 80.5, 1],\n",
      " |             ['monkey', nan, None]], dtype=object)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  columns\n",
      " |      The column labels of the DataFrame.\n",
      " |  \n",
      " |  index\n",
      " |      The index (row labels) of the DataFrame.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {'_AXIS_TO_AXIS_NUMBER': 'dict[Axis, int]', '_access...\n",
      " |  \n",
      " |  plot = <class 'pandas.plotting._core.PlotAccessor'>\n",
      " |      Make plots of Series or DataFrame.\n",
      " |      \n",
      " |      Uses the backend specified by the\n",
      " |      option ``plotting.backend``. By default, matplotlib is used.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : Series or DataFrame\n",
      " |          The object for which the method is called.\n",
      " |      x : label or position, default None\n",
      " |          Only used if data is a DataFrame.\n",
      " |      y : label, position or list of label, positions, default None\n",
      " |          Allows plotting of one column versus another. Only used if data is a\n",
      " |          DataFrame.\n",
      " |      kind : str\n",
      " |          The kind of plot to produce:\n",
      " |      \n",
      " |          - 'line' : line plot (default)\n",
      " |          - 'bar' : vertical bar plot\n",
      " |          - 'barh' : horizontal bar plot\n",
      " |          - 'hist' : histogram\n",
      " |          - 'box' : boxplot\n",
      " |          - 'kde' : Kernel Density Estimation plot\n",
      " |          - 'density' : same as 'kde'\n",
      " |          - 'area' : area plot\n",
      " |          - 'pie' : pie plot\n",
      " |          - 'scatter' : scatter plot (DataFrame only)\n",
      " |          - 'hexbin' : hexbin plot (DataFrame only)\n",
      " |      ax : matplotlib axes object, default None\n",
      " |          An axes of the current figure.\n",
      " |      subplots : bool, default False\n",
      " |          Make separate subplots for each column.\n",
      " |      sharex : bool, default True if ax is None else False\n",
      " |          In case ``subplots=True``, share x axis and set some x axis labels\n",
      " |          to invisible; defaults to True if ax is None otherwise False if\n",
      " |          an ax is passed in; Be aware, that passing in both an ax and\n",
      " |          ``sharex=True`` will alter all x axis labels for all axis in a figure.\n",
      " |      sharey : bool, default False\n",
      " |          In case ``subplots=True``, share y axis and set some y axis labels to invisible.\n",
      " |      layout : tuple, optional\n",
      " |          (rows, columns) for the layout of subplots.\n",
      " |      figsize : a tuple (width, height) in inches\n",
      " |          Size of a figure object.\n",
      " |      use_index : bool, default True\n",
      " |          Use index as ticks for x axis.\n",
      " |      title : str or list\n",
      " |          Title to use for the plot. If a string is passed, print the string\n",
      " |          at the top of the figure. If a list is passed and `subplots` is\n",
      " |          True, print each item in the list above the corresponding subplot.\n",
      " |      grid : bool, default None (matlab style default)\n",
      " |          Axis grid lines.\n",
      " |      legend : bool or {'reverse'}\n",
      " |          Place legend on axis subplots.\n",
      " |      style : list or dict\n",
      " |          The matplotlib line style per column.\n",
      " |      logx : bool or 'sym', default False\n",
      " |          Use log scaling or symlog scaling on x axis.\n",
      " |          .. versionchanged:: 0.25.0\n",
      " |      \n",
      " |      logy : bool or 'sym' default False\n",
      " |          Use log scaling or symlog scaling on y axis.\n",
      " |          .. versionchanged:: 0.25.0\n",
      " |      \n",
      " |      loglog : bool or 'sym', default False\n",
      " |          Use log scaling or symlog scaling on both x and y axes.\n",
      " |          .. versionchanged:: 0.25.0\n",
      " |      \n",
      " |      xticks : sequence\n",
      " |          Values to use for the xticks.\n",
      " |      yticks : sequence\n",
      " |          Values to use for the yticks.\n",
      " |      xlim : 2-tuple/list\n",
      " |          Set the x limits of the current axes.\n",
      " |      ylim : 2-tuple/list\n",
      " |          Set the y limits of the current axes.\n",
      " |      xlabel : label, optional\n",
      " |          Name to use for the xlabel on x-axis. Default uses index name as xlabel, or the\n",
      " |          x-column name for planar plots.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |      \n",
      " |             Now applicable to planar plots (`scatter`, `hexbin`).\n",
      " |      \n",
      " |      ylabel : label, optional\n",
      " |          Name to use for the ylabel on y-axis. Default will show no ylabel, or the\n",
      " |          y-column name for planar plots.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |      \n",
      " |             Now applicable to planar plots (`scatter`, `hexbin`).\n",
      " |      \n",
      " |      rot : int, default None\n",
      " |          Rotation for ticks (xticks for vertical, yticks for horizontal\n",
      " |          plots).\n",
      " |      fontsize : int, default None\n",
      " |          Font size for xticks and yticks.\n",
      " |      colormap : str or matplotlib colormap object, default None\n",
      " |          Colormap to select colors from. If string, load colormap with that\n",
      " |          name from matplotlib.\n",
      " |      colorbar : bool, optional\n",
      " |          If True, plot colorbar (only relevant for 'scatter' and 'hexbin'\n",
      " |          plots).\n",
      " |      position : float\n",
      " |          Specify relative alignments for bar plot layout.\n",
      " |          From 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5\n",
      " |          (center).\n",
      " |      table : bool, Series or DataFrame, default False\n",
      " |          If True, draw a table using the data in the DataFrame and the data\n",
      " |          will be transposed to meet matplotlib's default layout.\n",
      " |          If a Series or DataFrame is passed, use passed data to draw a\n",
      " |          table.\n",
      " |      yerr : DataFrame, Series, array-like, dict and str\n",
      " |          See :ref:`Plotting with Error Bars <visualization.errorbars>` for\n",
      " |          detail.\n",
      " |      xerr : DataFrame, Series, array-like, dict and str\n",
      " |          Equivalent to yerr.\n",
      " |      stacked : bool, default False in line and bar plots, and True in area plot\n",
      " |          If True, create stacked plot.\n",
      " |      sort_columns : bool, default False\n",
      " |          Sort column names to determine plot ordering.\n",
      " |      secondary_y : bool or sequence, default False\n",
      " |          Whether to plot on the secondary y-axis if a list/tuple, which\n",
      " |          columns to plot on secondary y-axis.\n",
      " |      mark_right : bool, default True\n",
      " |          When using a secondary_y axis, automatically mark the column\n",
      " |          labels with \"(right)\" in the legend.\n",
      " |      include_bool : bool, default is False\n",
      " |          If True, boolean values can be plotted.\n",
      " |      backend : str, default None\n",
      " |          Backend to use instead of the backend specified in the option\n",
      " |          ``plotting.backend``. For instance, 'matplotlib'. Alternatively, to\n",
      " |          specify the ``plotting.backend`` for the whole session, set\n",
      " |          ``pd.options.plotting.backend``.\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      **kwargs\n",
      " |          Options to pass to matplotlib plotting method.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      :class:`matplotlib.axes.Axes` or numpy.ndarray of them\n",
      " |          If the backend is not the default matplotlib one, the return value\n",
      " |          will be the object returned by the backend.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      - See matplotlib documentation online for more on this subject\n",
      " |      - If `kind` = 'bar' or 'barh', you can specify relative alignments\n",
      " |        for bar plot layout by `position` keyword.\n",
      " |        From 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5\n",
      " |        (center)\n",
      " |  \n",
      " |  \n",
      " |  sparse = <class 'pandas.core.arrays.sparse.accessor.SparseFrameAccesso...\n",
      " |      DataFrame accessor for sparse data.\n",
      " |      \n",
      " |      .. versionadded:: 0.25.0\n",
      " |  \n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.generic.NDFrame:\n",
      " |  \n",
      " |  __abs__(self: 'NDFrameT') -> 'NDFrameT'\n",
      " |  \n",
      " |  __array__(self, dtype: 'npt.DTypeLike | None' = None) -> 'np.ndarray'\n",
      " |  \n",
      " |  __array_ufunc__(self, ufunc: 'np.ufunc', method: 'str', *inputs: 'Any', **kwargs: 'Any')\n",
      " |  \n",
      " |  __array_wrap__(self, result: 'np.ndarray', context: 'tuple[Callable, tuple[Any, ...], int] | None' = None)\n",
      " |      Gets called after a ufunc and other functions.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      result: np.ndarray\n",
      " |          The result of the ufunc or other function called on the NumPy array\n",
      " |          returned by __array__\n",
      " |      context: tuple of (func, tuple, int)\n",
      " |          This parameter is returned by ufuncs as a 3-element tuple: (name of the\n",
      " |          ufunc, arguments of the ufunc, domain of the ufunc), but is not set by\n",
      " |          other numpy functions.q\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Series implements __array_ufunc_ so this not called for ufunc on Series.\n",
      " |  \n",
      " |  __bool__ = __nonzero__(self)\n",
      " |  \n",
      " |  __contains__(self, key) -> 'bool_t'\n",
      " |      True if the key is in the info axis\n",
      " |  \n",
      " |  __copy__(self: 'NDFrameT', deep: 'bool_t' = True) -> 'NDFrameT'\n",
      " |  \n",
      " |  __deepcopy__(self: 'NDFrameT', memo=None) -> 'NDFrameT'\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      memo, default None\n",
      " |          Standard signature. Unused\n",
      " |  \n",
      " |  __delitem__(self, key) -> 'None'\n",
      " |      Delete item\n",
      " |  \n",
      " |  __finalize__(self: 'NDFrameT', other, method: 'str | None' = None, **kwargs) -> 'NDFrameT'\n",
      " |      Propagate metadata from other to self.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : the object from which to get the attributes that we are going\n",
      " |          to propagate\n",
      " |      method : str, optional\n",
      " |          A passed method name providing context on where ``__finalize__``\n",
      " |          was called.\n",
      " |      \n",
      " |          .. warning::\n",
      " |      \n",
      " |             The value passed as `method` are not currently considered\n",
      " |             stable across pandas releases.\n",
      " |  \n",
      " |  __getattr__(self, name: 'str')\n",
      " |      After regular attribute access, try looking up the name\n",
      " |      This allows simpler access to columns for interactive use.\n",
      " |  \n",
      " |  __getstate__(self) -> 'dict[str, Any]'\n",
      " |  \n",
      " |  __iadd__(self, other)\n",
      " |  \n",
      " |  __iand__(self, other)\n",
      " |  \n",
      " |  __ifloordiv__(self, other)\n",
      " |  \n",
      " |  __imod__(self, other)\n",
      " |  \n",
      " |  __imul__(self, other)\n",
      " |  \n",
      " |  __invert__(self)\n",
      " |  \n",
      " |  __ior__(self, other)\n",
      " |  \n",
      " |  __ipow__(self, other)\n",
      " |  \n",
      " |  __isub__(self, other)\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Iterate over info axis.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      iterator\n",
      " |          Info axis as iterator.\n",
      " |  \n",
      " |  __itruediv__(self, other)\n",
      " |  \n",
      " |  __ixor__(self, other)\n",
      " |  \n",
      " |  __neg__(self)\n",
      " |  \n",
      " |  __nonzero__(self)\n",
      " |  \n",
      " |  __pos__(self)\n",
      " |  \n",
      " |  __round__(self: 'NDFrameT', decimals: 'int' = 0) -> 'NDFrameT'\n",
      " |  \n",
      " |  __setattr__(self, name: 'str', value) -> 'None'\n",
      " |      After regular attribute access, try setting the name\n",
      " |      This allows simpler access to columns for interactive use.\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  abs(self: 'NDFrameT') -> 'NDFrameT'\n",
      " |      Return a Series/DataFrame with absolute numeric value of each element.\n",
      " |      \n",
      " |      This function only applies to elements that are all numeric.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      abs\n",
      " |          Series/DataFrame containing the absolute value of each element.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.absolute : Calculate the absolute value element-wise.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For ``complex`` inputs, ``1.2 + 1j``, the absolute value is\n",
      " |      :math:`\\sqrt{ a^2 + b^2 }`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Absolute numeric values in a Series.\n",
      " |      \n",
      " |      >>> s = pd.Series([-1.10, 2, -3.33, 4])\n",
      " |      >>> s.abs()\n",
      " |      0    1.10\n",
      " |      1    2.00\n",
      " |      2    3.33\n",
      " |      3    4.00\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Absolute numeric values in a Series with complex numbers.\n",
      " |      \n",
      " |      >>> s = pd.Series([1.2 + 1j])\n",
      " |      >>> s.abs()\n",
      " |      0    1.56205\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Absolute numeric values in a Series with a Timedelta element.\n",
      " |      \n",
      " |      >>> s = pd.Series([pd.Timedelta('1 days')])\n",
      " |      >>> s.abs()\n",
      " |      0   1 days\n",
      " |      dtype: timedelta64[ns]\n",
      " |      \n",
      " |      Select rows with data closest to certain value using argsort (from\n",
      " |      `StackOverflow <https://stackoverflow.com/a/17758115>`__).\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'a': [4, 5, 6, 7],\n",
      " |      ...     'b': [10, 20, 30, 40],\n",
      " |      ...     'c': [100, 50, -30, -50]\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |           a    b    c\n",
      " |      0    4   10  100\n",
      " |      1    5   20   50\n",
      " |      2    6   30  -30\n",
      " |      3    7   40  -50\n",
      " |      >>> df.loc[(df.c - 43).abs().argsort()]\n",
      " |           a    b    c\n",
      " |      1    5   20   50\n",
      " |      0    4   10  100\n",
      " |      2    6   30  -30\n",
      " |      3    7   40  -50\n",
      " |  \n",
      " |  add_prefix(self: 'NDFrameT', prefix: 'str') -> 'NDFrameT'\n",
      " |      Prefix labels with string `prefix`.\n",
      " |      \n",
      " |      For Series, the row labels are prefixed.\n",
      " |      For DataFrame, the column labels are prefixed.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      prefix : str\n",
      " |          The string to add before each label.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          New Series or DataFrame with updated labels.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.add_suffix: Suffix row labels with string `suffix`.\n",
      " |      DataFrame.add_suffix: Suffix column labels with string `suffix`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.add_prefix('item_')\n",
      " |      item_0    1\n",
      " |      item_1    2\n",
      " |      item_2    3\n",
      " |      item_3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3, 4], 'B': [3, 4, 5, 6]})\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  1  3\n",
      " |      1  2  4\n",
      " |      2  3  5\n",
      " |      3  4  6\n",
      " |      \n",
      " |      >>> df.add_prefix('col_')\n",
      " |           col_A  col_B\n",
      " |      0       1       3\n",
      " |      1       2       4\n",
      " |      2       3       5\n",
      " |      3       4       6\n",
      " |  \n",
      " |  add_suffix(self: 'NDFrameT', suffix: 'str') -> 'NDFrameT'\n",
      " |      Suffix labels with string `suffix`.\n",
      " |      \n",
      " |      For Series, the row labels are suffixed.\n",
      " |      For DataFrame, the column labels are suffixed.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      suffix : str\n",
      " |          The string to add after each label.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          New Series or DataFrame with updated labels.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.add_prefix: Prefix row labels with string `prefix`.\n",
      " |      DataFrame.add_prefix: Prefix column labels with string `prefix`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.add_suffix('_item')\n",
      " |      0_item    1\n",
      " |      1_item    2\n",
      " |      2_item    3\n",
      " |      3_item    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3, 4], 'B': [3, 4, 5, 6]})\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  1  3\n",
      " |      1  2  4\n",
      " |      2  3  5\n",
      " |      3  4  6\n",
      " |      \n",
      " |      >>> df.add_suffix('_col')\n",
      " |           A_col  B_col\n",
      " |      0       1       3\n",
      " |      1       2       4\n",
      " |      2       3       5\n",
      " |      3       4       6\n",
      " |  \n",
      " |  asof(self, where, subset=None)\n",
      " |      Return the last row(s) without any NaNs before `where`.\n",
      " |      \n",
      " |      The last row (for each element in `where`, if list) without any\n",
      " |      NaN is taken.\n",
      " |      In case of a :class:`~pandas.DataFrame`, the last row without NaN\n",
      " |      considering only the subset of columns (if not `None`)\n",
      " |      \n",
      " |      If there is no good value, NaN is returned for a Series or\n",
      " |      a Series of NaN values for a DataFrame\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      where : date or array-like of dates\n",
      " |          Date(s) before which the last row(s) are returned.\n",
      " |      subset : str or array-like of str, default `None`\n",
      " |          For DataFrame, if not `None`, only use these columns to\n",
      " |          check for NaNs.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar, Series, or DataFrame\n",
      " |      \n",
      " |          The return can be:\n",
      " |      \n",
      " |          * scalar : when `self` is a Series and `where` is a scalar\n",
      " |          * Series: when `self` is a Series and `where` is an array-like,\n",
      " |            or when `self` is a DataFrame and `where` is a scalar\n",
      " |          * DataFrame : when `self` is a DataFrame and `where` is an\n",
      " |            array-like\n",
      " |      \n",
      " |          Return scalar, Series, or DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      merge_asof : Perform an asof merge. Similar to left join.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Dates are assumed to be sorted. Raises if this is not the case.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      A Series and a scalar `where`.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, np.nan, 4], index=[10, 20, 30, 40])\n",
      " |      >>> s\n",
      " |      10    1.0\n",
      " |      20    2.0\n",
      " |      30    NaN\n",
      " |      40    4.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.asof(20)\n",
      " |      2.0\n",
      " |      \n",
      " |      For a sequence `where`, a Series is returned. The first value is\n",
      " |      NaN, because the first element of `where` is before the first\n",
      " |      index value.\n",
      " |      \n",
      " |      >>> s.asof([5, 20])\n",
      " |      5     NaN\n",
      " |      20    2.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Missing values are not considered. The following is ``2.0``, not\n",
      " |      NaN, even though NaN is at the index location for ``30``.\n",
      " |      \n",
      " |      >>> s.asof(30)\n",
      " |      2.0\n",
      " |      \n",
      " |      Take all columns into consideration\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'a': [10, 20, 30, 40, 50],\n",
      " |      ...                    'b': [None, None, None, None, 500]},\n",
      " |      ...                   index=pd.DatetimeIndex(['2018-02-27 09:01:00',\n",
      " |      ...                                           '2018-02-27 09:02:00',\n",
      " |      ...                                           '2018-02-27 09:03:00',\n",
      " |      ...                                           '2018-02-27 09:04:00',\n",
      " |      ...                                           '2018-02-27 09:05:00']))\n",
      " |      >>> df.asof(pd.DatetimeIndex(['2018-02-27 09:03:30',\n",
      " |      ...                           '2018-02-27 09:04:30']))\n",
      " |                            a   b\n",
      " |      2018-02-27 09:03:30 NaN NaN\n",
      " |      2018-02-27 09:04:30 NaN NaN\n",
      " |      \n",
      " |      Take a single column into consideration\n",
      " |      \n",
      " |      >>> df.asof(pd.DatetimeIndex(['2018-02-27 09:03:30',\n",
      " |      ...                           '2018-02-27 09:04:30']),\n",
      " |      ...         subset=['a'])\n",
      " |                               a   b\n",
      " |      2018-02-27 09:03:30   30.0 NaN\n",
      " |      2018-02-27 09:04:30   40.0 NaN\n",
      " |  \n",
      " |  astype(self: 'NDFrameT', dtype, copy: 'bool_t' = True, errors: 'str' = 'raise') -> 'NDFrameT'\n",
      " |      Cast a pandas object to a specified dtype ``dtype``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dtype : data type, or dict of column name -> data type\n",
      " |          Use a numpy.dtype or Python type to cast entire pandas object to\n",
      " |          the same type. Alternatively, use {col: dtype, ...}, where col is a\n",
      " |          column label and dtype is a numpy.dtype or Python type to cast one\n",
      " |          or more of the DataFrame's columns to column-specific types.\n",
      " |      copy : bool, default True\n",
      " |          Return a copy when ``copy=True`` (be very careful setting\n",
      " |          ``copy=False`` as changes to values then may propagate to other\n",
      " |          pandas objects).\n",
      " |      errors : {'raise', 'ignore'}, default 'raise'\n",
      " |          Control raising of exceptions on invalid data for provided dtype.\n",
      " |      \n",
      " |          - ``raise`` : allow exceptions to be raised\n",
      " |          - ``ignore`` : suppress exceptions. On error return original object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      casted : same type as caller\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      to_datetime : Convert argument to datetime.\n",
      " |      to_timedelta : Convert argument to timedelta.\n",
      " |      to_numeric : Convert argument to a numeric type.\n",
      " |      numpy.ndarray.astype : Cast a numpy array to a specified type.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      .. deprecated:: 1.3.0\n",
      " |      \n",
      " |          Using ``astype`` to convert from timezone-naive dtype to\n",
      " |          timezone-aware dtype is deprecated and will raise in a\n",
      " |          future version.  Use :meth:`Series.dt.tz_localize` instead.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Create a DataFrame:\n",
      " |      \n",
      " |      >>> d = {'col1': [1, 2], 'col2': [3, 4]}\n",
      " |      >>> df = pd.DataFrame(data=d)\n",
      " |      >>> df.dtypes\n",
      " |      col1    int64\n",
      " |      col2    int64\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Cast all columns to int32:\n",
      " |      \n",
      " |      >>> df.astype('int32').dtypes\n",
      " |      col1    int32\n",
      " |      col2    int32\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Cast col1 to int32 using a dictionary:\n",
      " |      \n",
      " |      >>> df.astype({'col1': 'int32'}).dtypes\n",
      " |      col1    int32\n",
      " |      col2    int64\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Create a series:\n",
      " |      \n",
      " |      >>> ser = pd.Series([1, 2], dtype='int32')\n",
      " |      >>> ser\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: int32\n",
      " |      >>> ser.astype('int64')\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Convert to categorical type:\n",
      " |      \n",
      " |      >>> ser.astype('category')\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: category\n",
      " |      Categories (2, int64): [1, 2]\n",
      " |      \n",
      " |      Convert to ordered categorical type with custom ordering:\n",
      " |      \n",
      " |      >>> from pandas.api.types import CategoricalDtype\n",
      " |      >>> cat_dtype = CategoricalDtype(\n",
      " |      ...     categories=[2, 1], ordered=True)\n",
      " |      >>> ser.astype(cat_dtype)\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: category\n",
      " |      Categories (2, int64): [2 < 1]\n",
      " |      \n",
      " |      Note that using ``copy=False`` and changing data on a new\n",
      " |      pandas object may propagate changes:\n",
      " |      \n",
      " |      >>> s1 = pd.Series([1, 2])\n",
      " |      >>> s2 = s1.astype('int64', copy=False)\n",
      " |      >>> s2[0] = 10\n",
      " |      >>> s1  # note that s1[0] has changed too\n",
      " |      0    10\n",
      " |      1     2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Create a series of dates:\n",
      " |      \n",
      " |      >>> ser_date = pd.Series(pd.date_range('20200101', periods=3))\n",
      " |      >>> ser_date\n",
      " |      0   2020-01-01\n",
      " |      1   2020-01-02\n",
      " |      2   2020-01-03\n",
      " |      dtype: datetime64[ns]\n",
      " |  \n",
      " |  at_time(self: 'NDFrameT', time, asof: 'bool_t' = False, axis=None) -> 'NDFrameT'\n",
      " |      Select values at particular time of day (e.g., 9:30AM).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      time : datetime.time or str\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      between_time : Select values between particular times of the day.\n",
      " |      first : Select initial periods of time series based on a date offset.\n",
      " |      last : Select final periods of time series based on a date offset.\n",
      " |      DatetimeIndex.indexer_at_time : Get just the index locations for\n",
      " |          values at particular time of the day.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='12H')\n",
      " |      >>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)\n",
      " |      >>> ts\n",
      " |                           A\n",
      " |      2018-04-09 00:00:00  1\n",
      " |      2018-04-09 12:00:00  2\n",
      " |      2018-04-10 00:00:00  3\n",
      " |      2018-04-10 12:00:00  4\n",
      " |      \n",
      " |      >>> ts.at_time('12:00')\n",
      " |                           A\n",
      " |      2018-04-09 12:00:00  2\n",
      " |      2018-04-10 12:00:00  4\n",
      " |  \n",
      " |  backfill = bfill(self: 'NDFrameT', axis: 'None | Axis' = None, inplace: 'bool_t' = False, limit: 'None | int' = None, downcast=None) -> 'NDFrameT | None'\n",
      " |      Synonym for :meth:`DataFrame.fillna` with ``method='bfill'``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame or None\n",
      " |          Object with missing values filled or None if ``inplace=True``.\n",
      " |  \n",
      " |  between_time(self: 'NDFrameT', start_time, end_time, include_start: 'bool_t | lib.NoDefault' = <no_default>, include_end: 'bool_t | lib.NoDefault' = <no_default>, inclusive: 'str | None' = None, axis=None) -> 'NDFrameT'\n",
      " |      Select values between particular times of the day (e.g., 9:00-9:30 AM).\n",
      " |      \n",
      " |      By setting ``start_time`` to be later than ``end_time``,\n",
      " |      you can get the times that are *not* between the two times.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      start_time : datetime.time or str\n",
      " |          Initial time as a time filter limit.\n",
      " |      end_time : datetime.time or str\n",
      " |          End time as a time filter limit.\n",
      " |      include_start : bool, default True\n",
      " |          Whether the start time needs to be included in the result.\n",
      " |      \n",
      " |          .. deprecated:: 1.4.0\n",
      " |             Arguments `include_start` and `include_end` have been deprecated\n",
      " |             to standardize boundary inputs. Use `inclusive` instead, to set\n",
      " |             each bound as closed or open.\n",
      " |      include_end : bool, default True\n",
      " |          Whether the end time needs to be included in the result.\n",
      " |      \n",
      " |          .. deprecated:: 1.4.0\n",
      " |             Arguments `include_start` and `include_end` have been deprecated\n",
      " |             to standardize boundary inputs. Use `inclusive` instead, to set\n",
      " |             each bound as closed or open.\n",
      " |      inclusive : {\"both\", \"neither\", \"left\", \"right\"}, default \"both\"\n",
      " |          Include boundaries; whether to set each bound as closed or open.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Determine range time on index or columns value.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Data from the original object filtered to the specified dates range.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      at_time : Select values at a particular time of the day.\n",
      " |      first : Select initial periods of time series based on a date offset.\n",
      " |      last : Select final periods of time series based on a date offset.\n",
      " |      DatetimeIndex.indexer_between_time : Get just the index locations for\n",
      " |          values between particular times of the day.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='1D20min')\n",
      " |      >>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)\n",
      " |      >>> ts\n",
      " |                           A\n",
      " |      2018-04-09 00:00:00  1\n",
      " |      2018-04-10 00:20:00  2\n",
      " |      2018-04-11 00:40:00  3\n",
      " |      2018-04-12 01:00:00  4\n",
      " |      \n",
      " |      >>> ts.between_time('0:15', '0:45')\n",
      " |                           A\n",
      " |      2018-04-10 00:20:00  2\n",
      " |      2018-04-11 00:40:00  3\n",
      " |      \n",
      " |      You get the times that are *not* between two times by setting\n",
      " |      ``start_time`` later than ``end_time``:\n",
      " |      \n",
      " |      >>> ts.between_time('0:45', '0:15')\n",
      " |                           A\n",
      " |      2018-04-09 00:00:00  1\n",
      " |      2018-04-12 01:00:00  4\n",
      " |  \n",
      " |  bool(self)\n",
      " |      Return the bool of a single element Series or DataFrame.\n",
      " |      \n",
      " |      This must be a boolean scalar value, either True or False. It will raise a\n",
      " |      ValueError if the Series or DataFrame does not have exactly 1 element, or that\n",
      " |      element is not boolean (integer values 0 and 1 will also raise an exception).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |          The value in the Series or DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.astype : Change the data type of a Series, including to boolean.\n",
      " |      DataFrame.astype : Change the data type of a DataFrame, including to boolean.\n",
      " |      numpy.bool_ : NumPy boolean data type, used by pandas for boolean values.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The method will only work for single element objects with a boolean value:\n",
      " |      \n",
      " |      >>> pd.Series([True]).bool()\n",
      " |      True\n",
      " |      >>> pd.Series([False]).bool()\n",
      " |      False\n",
      " |      \n",
      " |      >>> pd.DataFrame({'col': [True]}).bool()\n",
      " |      True\n",
      " |      >>> pd.DataFrame({'col': [False]}).bool()\n",
      " |      False\n",
      " |  \n",
      " |  convert_dtypes(self: 'NDFrameT', infer_objects: 'bool_t' = True, convert_string: 'bool_t' = True, convert_integer: 'bool_t' = True, convert_boolean: 'bool_t' = True, convert_floating: 'bool_t' = True) -> 'NDFrameT'\n",
      " |      Convert columns to best possible dtypes using dtypes supporting ``pd.NA``.\n",
      " |      \n",
      " |      .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      infer_objects : bool, default True\n",
      " |          Whether object dtypes should be converted to the best possible types.\n",
      " |      convert_string : bool, default True\n",
      " |          Whether object dtypes should be converted to ``StringDtype()``.\n",
      " |      convert_integer : bool, default True\n",
      " |          Whether, if possible, conversion can be done to integer extension types.\n",
      " |      convert_boolean : bool, defaults True\n",
      " |          Whether object dtypes should be converted to ``BooleanDtypes()``.\n",
      " |      convert_floating : bool, defaults True\n",
      " |          Whether, if possible, conversion can be done to floating extension types.\n",
      " |          If `convert_integer` is also True, preference will be give to integer\n",
      " |          dtypes if the floats can be faithfully casted to integers.\n",
      " |      \n",
      " |          .. versionadded:: 1.2.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Copy of input object with new dtype.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      infer_objects : Infer dtypes of objects.\n",
      " |      to_datetime : Convert argument to datetime.\n",
      " |      to_timedelta : Convert argument to timedelta.\n",
      " |      to_numeric : Convert argument to a numeric type.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      By default, ``convert_dtypes`` will attempt to convert a Series (or each\n",
      " |      Series in a DataFrame) to dtypes that support ``pd.NA``. By using the options\n",
      " |      ``convert_string``, ``convert_integer``, ``convert_boolean`` and\n",
      " |      ``convert_boolean``, it is possible to turn off individual conversions\n",
      " |      to ``StringDtype``, the integer extension types, ``BooleanDtype``\n",
      " |      or floating extension types, respectively.\n",
      " |      \n",
      " |      For object-dtyped columns, if ``infer_objects`` is ``True``, use the inference\n",
      " |      rules as during normal Series/DataFrame construction.  Then, if possible,\n",
      " |      convert to ``StringDtype``, ``BooleanDtype`` or an appropriate integer\n",
      " |      or floating extension type, otherwise leave as ``object``.\n",
      " |      \n",
      " |      If the dtype is integer, convert to an appropriate integer extension type.\n",
      " |      \n",
      " |      If the dtype is numeric, and consists of all integers, convert to an\n",
      " |      appropriate integer extension type. Otherwise, convert to an\n",
      " |      appropriate floating extension type.\n",
      " |      \n",
      " |      .. versionchanged:: 1.2\n",
      " |          Starting with pandas 1.2, this method also converts float columns\n",
      " |          to the nullable floating extension type.\n",
      " |      \n",
      " |      In the future, as new dtypes are added that support ``pd.NA``, the results\n",
      " |      of this method will change to support those new dtypes.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(\n",
      " |      ...     {\n",
      " |      ...         \"a\": pd.Series([1, 2, 3], dtype=np.dtype(\"int32\")),\n",
      " |      ...         \"b\": pd.Series([\"x\", \"y\", \"z\"], dtype=np.dtype(\"O\")),\n",
      " |      ...         \"c\": pd.Series([True, False, np.nan], dtype=np.dtype(\"O\")),\n",
      " |      ...         \"d\": pd.Series([\"h\", \"i\", np.nan], dtype=np.dtype(\"O\")),\n",
      " |      ...         \"e\": pd.Series([10, np.nan, 20], dtype=np.dtype(\"float\")),\n",
      " |      ...         \"f\": pd.Series([np.nan, 100.5, 200], dtype=np.dtype(\"float\")),\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      \n",
      " |      Start with a DataFrame with default dtypes.\n",
      " |      \n",
      " |      >>> df\n",
      " |         a  b      c    d     e      f\n",
      " |      0  1  x   True    h  10.0    NaN\n",
      " |      1  2  y  False    i   NaN  100.5\n",
      " |      2  3  z    NaN  NaN  20.0  200.0\n",
      " |      \n",
      " |      >>> df.dtypes\n",
      " |      a      int32\n",
      " |      b     object\n",
      " |      c     object\n",
      " |      d     object\n",
      " |      e    float64\n",
      " |      f    float64\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Convert the DataFrame to use best possible dtypes.\n",
      " |      \n",
      " |      >>> dfn = df.convert_dtypes()\n",
      " |      >>> dfn\n",
      " |         a  b      c     d     e      f\n",
      " |      0  1  x   True     h    10   <NA>\n",
      " |      1  2  y  False     i  <NA>  100.5\n",
      " |      2  3  z   <NA>  <NA>    20  200.0\n",
      " |      \n",
      " |      >>> dfn.dtypes\n",
      " |      a      Int32\n",
      " |      b     string\n",
      " |      c    boolean\n",
      " |      d     string\n",
      " |      e      Int64\n",
      " |      f    Float64\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Start with a Series of strings and missing data represented by ``np.nan``.\n",
      " |      \n",
      " |      >>> s = pd.Series([\"a\", \"b\", np.nan])\n",
      " |      >>> s\n",
      " |      0      a\n",
      " |      1      b\n",
      " |      2    NaN\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Obtain a Series with dtype ``StringDtype``.\n",
      " |      \n",
      " |      >>> s.convert_dtypes()\n",
      " |      0       a\n",
      " |      1       b\n",
      " |      2    <NA>\n",
      " |      dtype: string\n",
      " |  \n",
      " |  copy(self: 'NDFrameT', deep: 'bool_t' = True) -> 'NDFrameT'\n",
      " |      Make a copy of this object's indices and data.\n",
      " |      \n",
      " |      When ``deep=True`` (default), a new object will be created with a\n",
      " |      copy of the calling object's data and indices. Modifications to\n",
      " |      the data or indices of the copy will not be reflected in the\n",
      " |      original object (see notes below).\n",
      " |      \n",
      " |      When ``deep=False``, a new object will be created without copying\n",
      " |      the calling object's data or index (only references to the data\n",
      " |      and index are copied). Any changes to the data of the original\n",
      " |      will be reflected in the shallow copy (and vice versa).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default True\n",
      " |          Make a deep copy, including a copy of the data and the indices.\n",
      " |          With ``deep=False`` neither the indices nor the data are copied.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      copy : Series or DataFrame\n",
      " |          Object type matches caller.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      When ``deep=True``, data is copied but actual Python objects\n",
      " |      will not be copied recursively, only the reference to the object.\n",
      " |      This is in contrast to `copy.deepcopy` in the Standard Library,\n",
      " |      which recursively copies object data (see examples below).\n",
      " |      \n",
      " |      While ``Index`` objects are copied when ``deep=True``, the underlying\n",
      " |      numpy array is not copied for performance reasons. Since ``Index`` is\n",
      " |      immutable, the underlying data can be safely shared and a copy\n",
      " |      is not needed.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2], index=[\"a\", \"b\"])\n",
      " |      >>> s\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s_copy = s.copy()\n",
      " |      >>> s_copy\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      **Shallow copy versus default (deep) copy:**\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2], index=[\"a\", \"b\"])\n",
      " |      >>> deep = s.copy()\n",
      " |      >>> shallow = s.copy(deep=False)\n",
      " |      \n",
      " |      Shallow copy shares data and index with original.\n",
      " |      \n",
      " |      >>> s is shallow\n",
      " |      False\n",
      " |      >>> s.values is shallow.values and s.index is shallow.index\n",
      " |      True\n",
      " |      \n",
      " |      Deep copy has own copy of data and index.\n",
      " |      \n",
      " |      >>> s is deep\n",
      " |      False\n",
      " |      >>> s.values is deep.values or s.index is deep.index\n",
      " |      False\n",
      " |      \n",
      " |      Updates to the data shared by shallow copy and original is reflected\n",
      " |      in both; deep copy remains unchanged.\n",
      " |      \n",
      " |      >>> s[0] = 3\n",
      " |      >>> shallow[1] = 4\n",
      " |      >>> s\n",
      " |      a    3\n",
      " |      b    4\n",
      " |      dtype: int64\n",
      " |      >>> shallow\n",
      " |      a    3\n",
      " |      b    4\n",
      " |      dtype: int64\n",
      " |      >>> deep\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Note that when copying an object containing Python objects, a deep copy\n",
      " |      will copy the data, but will not do so recursively. Updating a nested\n",
      " |      data object will be reflected in the deep copy.\n",
      " |      \n",
      " |      >>> s = pd.Series([[1, 2], [3, 4]])\n",
      " |      >>> deep = s.copy()\n",
      " |      >>> s[0][0] = 10\n",
      " |      >>> s\n",
      " |      0    [10, 2]\n",
      " |      1     [3, 4]\n",
      " |      dtype: object\n",
      " |      >>> deep\n",
      " |      0    [10, 2]\n",
      " |      1     [3, 4]\n",
      " |      dtype: object\n",
      " |  \n",
      " |  describe(self: 'NDFrameT', percentiles=None, include=None, exclude=None, datetime_is_numeric=False) -> 'NDFrameT'\n",
      " |      Generate descriptive statistics.\n",
      " |      \n",
      " |      Descriptive statistics include those that summarize the central\n",
      " |      tendency, dispersion and shape of a\n",
      " |      dataset's distribution, excluding ``NaN`` values.\n",
      " |      \n",
      " |      Analyzes both numeric and object series, as well\n",
      " |      as ``DataFrame`` column sets of mixed data types. The output\n",
      " |      will vary depending on what is provided. Refer to the notes\n",
      " |      below for more detail.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      percentiles : list-like of numbers, optional\n",
      " |          The percentiles to include in the output. All should\n",
      " |          fall between 0 and 1. The default is\n",
      " |          ``[.25, .5, .75]``, which returns the 25th, 50th, and\n",
      " |          75th percentiles.\n",
      " |      include : 'all', list-like of dtypes or None (default), optional\n",
      " |          A white list of data types to include in the result. Ignored\n",
      " |          for ``Series``. Here are the options:\n",
      " |      \n",
      " |          - 'all' : All columns of the input will be included in the output.\n",
      " |          - A list-like of dtypes : Limits the results to the\n",
      " |            provided data types.\n",
      " |            To limit the result to numeric types submit\n",
      " |            ``numpy.number``. To limit it instead to object columns submit\n",
      " |            the ``numpy.object`` data type. Strings\n",
      " |            can also be used in the style of\n",
      " |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
      " |            select pandas categorical columns, use ``'category'``\n",
      " |          - None (default) : The result will include all numeric columns.\n",
      " |      exclude : list-like of dtypes or None (default), optional,\n",
      " |          A black list of data types to omit from the result. Ignored\n",
      " |          for ``Series``. Here are the options:\n",
      " |      \n",
      " |          - A list-like of dtypes : Excludes the provided data types\n",
      " |            from the result. To exclude numeric types submit\n",
      " |            ``numpy.number``. To exclude object columns submit the data\n",
      " |            type ``numpy.object``. Strings can also be used in the style of\n",
      " |            ``select_dtypes`` (e.g. ``df.describe(exclude=['O'])``). To\n",
      " |            exclude pandas categorical columns, use ``'category'``\n",
      " |          - None (default) : The result will exclude nothing.\n",
      " |      datetime_is_numeric : bool, default False\n",
      " |          Whether to treat datetime dtypes as numeric. This affects statistics\n",
      " |          calculated for the column. For DataFrame input, this also\n",
      " |          controls whether datetime columns are included by default.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Summary statistics of the Series or Dataframe provided.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.count: Count number of non-NA/null observations.\n",
      " |      DataFrame.max: Maximum of the values in the object.\n",
      " |      DataFrame.min: Minimum of the values in the object.\n",
      " |      DataFrame.mean: Mean of the values.\n",
      " |      DataFrame.std: Standard deviation of the observations.\n",
      " |      DataFrame.select_dtypes: Subset of a DataFrame including/excluding\n",
      " |          columns based on their dtype.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For numeric data, the result's index will include ``count``,\n",
      " |      ``mean``, ``std``, ``min``, ``max`` as well as lower, ``50`` and\n",
      " |      upper percentiles. By default the lower percentile is ``25`` and the\n",
      " |      upper percentile is ``75``. The ``50`` percentile is the\n",
      " |      same as the median.\n",
      " |      \n",
      " |      For object data (e.g. strings or timestamps), the result's index\n",
      " |      will include ``count``, ``unique``, ``top``, and ``freq``. The ``top``\n",
      " |      is the most common value. The ``freq`` is the most common value's\n",
      " |      frequency. Timestamps also include the ``first`` and ``last`` items.\n",
      " |      \n",
      " |      If multiple object values have the highest count, then the\n",
      " |      ``count`` and ``top`` results will be arbitrarily chosen from\n",
      " |      among those with the highest count.\n",
      " |      \n",
      " |      For mixed data types provided via a ``DataFrame``, the default is to\n",
      " |      return only an analysis of numeric columns. If the dataframe consists\n",
      " |      only of object and categorical data without any numeric columns, the\n",
      " |      default is to return an analysis of both the object and categorical\n",
      " |      columns. If ``include='all'`` is provided as an option, the result\n",
      " |      will include a union of attributes of each type.\n",
      " |      \n",
      " |      The `include` and `exclude` parameters can be used to limit\n",
      " |      which columns in a ``DataFrame`` are analyzed for the output.\n",
      " |      The parameters are ignored when analyzing a ``Series``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Describing a numeric ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.describe()\n",
      " |      count    3.0\n",
      " |      mean     2.0\n",
      " |      std      1.0\n",
      " |      min      1.0\n",
      " |      25%      1.5\n",
      " |      50%      2.0\n",
      " |      75%      2.5\n",
      " |      max      3.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Describing a categorical ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series(['a', 'a', 'b', 'c'])\n",
      " |      >>> s.describe()\n",
      " |      count     4\n",
      " |      unique    3\n",
      " |      top       a\n",
      " |      freq      2\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Describing a timestamp ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series([\n",
      " |      ...   np.datetime64(\"2000-01-01\"),\n",
      " |      ...   np.datetime64(\"2010-01-01\"),\n",
      " |      ...   np.datetime64(\"2010-01-01\")\n",
      " |      ... ])\n",
      " |      >>> s.describe(datetime_is_numeric=True)\n",
      " |      count                      3\n",
      " |      mean     2006-09-01 08:00:00\n",
      " |      min      2000-01-01 00:00:00\n",
      " |      25%      2004-12-31 12:00:00\n",
      " |      50%      2010-01-01 00:00:00\n",
      " |      75%      2010-01-01 00:00:00\n",
      " |      max      2010-01-01 00:00:00\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Describing a ``DataFrame``. By default only numeric fields\n",
      " |      are returned.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'categorical': pd.Categorical(['d','e','f']),\n",
      " |      ...                    'numeric': [1, 2, 3],\n",
      " |      ...                    'object': ['a', 'b', 'c']\n",
      " |      ...                   })\n",
      " |      >>> df.describe()\n",
      " |             numeric\n",
      " |      count      3.0\n",
      " |      mean       2.0\n",
      " |      std        1.0\n",
      " |      min        1.0\n",
      " |      25%        1.5\n",
      " |      50%        2.0\n",
      " |      75%        2.5\n",
      " |      max        3.0\n",
      " |      \n",
      " |      Describing all columns of a ``DataFrame`` regardless of data type.\n",
      " |      \n",
      " |      >>> df.describe(include='all')  # doctest: +SKIP\n",
      " |             categorical  numeric object\n",
      " |      count            3      3.0      3\n",
      " |      unique           3      NaN      3\n",
      " |      top              f      NaN      a\n",
      " |      freq             1      NaN      1\n",
      " |      mean           NaN      2.0    NaN\n",
      " |      std            NaN      1.0    NaN\n",
      " |      min            NaN      1.0    NaN\n",
      " |      25%            NaN      1.5    NaN\n",
      " |      50%            NaN      2.0    NaN\n",
      " |      75%            NaN      2.5    NaN\n",
      " |      max            NaN      3.0    NaN\n",
      " |      \n",
      " |      Describing a column from a ``DataFrame`` by accessing it as\n",
      " |      an attribute.\n",
      " |      \n",
      " |      >>> df.numeric.describe()\n",
      " |      count    3.0\n",
      " |      mean     2.0\n",
      " |      std      1.0\n",
      " |      min      1.0\n",
      " |      25%      1.5\n",
      " |      50%      2.0\n",
      " |      75%      2.5\n",
      " |      max      3.0\n",
      " |      Name: numeric, dtype: float64\n",
      " |      \n",
      " |      Including only numeric columns in a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=[np.number])\n",
      " |             numeric\n",
      " |      count      3.0\n",
      " |      mean       2.0\n",
      " |      std        1.0\n",
      " |      min        1.0\n",
      " |      25%        1.5\n",
      " |      50%        2.0\n",
      " |      75%        2.5\n",
      " |      max        3.0\n",
      " |      \n",
      " |      Including only string columns in a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=[object])  # doctest: +SKIP\n",
      " |             object\n",
      " |      count       3\n",
      " |      unique      3\n",
      " |      top         a\n",
      " |      freq        1\n",
      " |      \n",
      " |      Including only categorical columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=['category'])\n",
      " |             categorical\n",
      " |      count            3\n",
      " |      unique           3\n",
      " |      top              d\n",
      " |      freq             1\n",
      " |      \n",
      " |      Excluding numeric columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(exclude=[np.number])  # doctest: +SKIP\n",
      " |             categorical object\n",
      " |      count            3      3\n",
      " |      unique           3      3\n",
      " |      top              f      a\n",
      " |      freq             1      1\n",
      " |      \n",
      " |      Excluding object columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(exclude=[object])  # doctest: +SKIP\n",
      " |             categorical  numeric\n",
      " |      count            3      3.0\n",
      " |      unique           3      NaN\n",
      " |      top              f      NaN\n",
      " |      freq             1      NaN\n",
      " |      mean           NaN      2.0\n",
      " |      std            NaN      1.0\n",
      " |      min            NaN      1.0\n",
      " |      25%            NaN      1.5\n",
      " |      50%            NaN      2.0\n",
      " |      75%            NaN      2.5\n",
      " |      max            NaN      3.0\n",
      " |  \n",
      " |  droplevel(self: 'NDFrameT', level, axis=0) -> 'NDFrameT'\n",
      " |      Return Series/DataFrame with requested index / column level(s) removed.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, str, or list-like\n",
      " |          If a string is given, must be the name of a level\n",
      " |          If list-like, elements must be names or positional indexes\n",
      " |          of levels.\n",
      " |      \n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Axis along which the level(s) is removed:\n",
      " |      \n",
      " |          * 0 or 'index': remove level(s) in column.\n",
      " |          * 1 or 'columns': remove level(s) in row.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame\n",
      " |          Series/DataFrame with requested index / column level(s) removed.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([\n",
      " |      ...     [1, 2, 3, 4],\n",
      " |      ...     [5, 6, 7, 8],\n",
      " |      ...     [9, 10, 11, 12]\n",
      " |      ... ]).set_index([0, 1]).rename_axis(['a', 'b'])\n",
      " |      \n",
      " |      >>> df.columns = pd.MultiIndex.from_tuples([\n",
      " |      ...     ('c', 'e'), ('d', 'f')\n",
      " |      ... ], names=['level_1', 'level_2'])\n",
      " |      \n",
      " |      >>> df\n",
      " |      level_1   c   d\n",
      " |      level_2   e   f\n",
      " |      a b\n",
      " |      1 2      3   4\n",
      " |      5 6      7   8\n",
      " |      9 10    11  12\n",
      " |      \n",
      " |      >>> df.droplevel('a')\n",
      " |      level_1   c   d\n",
      " |      level_2   e   f\n",
      " |      b\n",
      " |      2        3   4\n",
      " |      6        7   8\n",
      " |      10      11  12\n",
      " |      \n",
      " |      >>> df.droplevel('level_2', axis=1)\n",
      " |      level_1   c   d\n",
      " |      a b\n",
      " |      1 2      3   4\n",
      " |      5 6      7   8\n",
      " |      9 10    11  12\n",
      " |  \n",
      " |  equals(self, other: 'object') -> 'bool_t'\n",
      " |      Test whether two objects contain the same elements.\n",
      " |      \n",
      " |      This function allows two Series or DataFrames to be compared against\n",
      " |      each other to see if they have the same shape and elements. NaNs in\n",
      " |      the same location are considered equal.\n",
      " |      \n",
      " |      The row/column index do not need to have the same type, as long\n",
      " |      as the values are considered equal. Corresponding columns must be of\n",
      " |      the same dtype.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or DataFrame\n",
      " |          The other Series or DataFrame to be compared with the first.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |          True if all elements are the same in both objects, False\n",
      " |          otherwise.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.eq : Compare two Series objects of the same length\n",
      " |          and return a Series where each element is True if the element\n",
      " |          in each Series is equal, False otherwise.\n",
      " |      DataFrame.eq : Compare two DataFrame objects of the same shape and\n",
      " |          return a DataFrame where each element is True if the respective\n",
      " |          element in each DataFrame is equal, False otherwise.\n",
      " |      testing.assert_series_equal : Raises an AssertionError if left and\n",
      " |          right are not equal. Provides an easy interface to ignore\n",
      " |          inequality in dtypes, indexes and precision among others.\n",
      " |      testing.assert_frame_equal : Like assert_series_equal, but targets\n",
      " |          DataFrames.\n",
      " |      numpy.array_equal : Return True if two arrays have the same shape\n",
      " |          and elements, False otherwise.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({1: [10], 2: [20]})\n",
      " |      >>> df\n",
      " |          1   2\n",
      " |      0  10  20\n",
      " |      \n",
      " |      DataFrames df and exactly_equal have the same types and values for\n",
      " |      their elements and column labels, which will return True.\n",
      " |      \n",
      " |      >>> exactly_equal = pd.DataFrame({1: [10], 2: [20]})\n",
      " |      >>> exactly_equal\n",
      " |          1   2\n",
      " |      0  10  20\n",
      " |      >>> df.equals(exactly_equal)\n",
      " |      True\n",
      " |      \n",
      " |      DataFrames df and different_column_type have the same element\n",
      " |      types and values, but have different types for the column labels,\n",
      " |      which will still return True.\n",
      " |      \n",
      " |      >>> different_column_type = pd.DataFrame({1.0: [10], 2.0: [20]})\n",
      " |      >>> different_column_type\n",
      " |         1.0  2.0\n",
      " |      0   10   20\n",
      " |      >>> df.equals(different_column_type)\n",
      " |      True\n",
      " |      \n",
      " |      DataFrames df and different_data_type have different types for the\n",
      " |      same values for their elements, and will return False even though\n",
      " |      their column labels are the same values and types.\n",
      " |      \n",
      " |      >>> different_data_type = pd.DataFrame({1: [10.0], 2: [20.0]})\n",
      " |      >>> different_data_type\n",
      " |            1     2\n",
      " |      0  10.0  20.0\n",
      " |      >>> df.equals(different_data_type)\n",
      " |      False\n",
      " |  \n",
      " |  ewm(self, com: 'float | None' = None, span: 'float | None' = None, halflife: 'float | TimedeltaConvertibleTypes | None' = None, alpha: 'float | None' = None, min_periods: 'int | None' = 0, adjust: 'bool_t' = True, ignore_na: 'bool_t' = False, axis: 'Axis' = 0, times: 'str | np.ndarray | DataFrame | Series | None' = None, method: 'str' = 'single') -> 'ExponentialMovingWindow'\n",
      " |      Provide exponentially weighted (EW) calculations.\n",
      " |      \n",
      " |      Exactly one parameter: ``com``, ``span``, ``halflife``, or ``alpha`` must be\n",
      " |      provided.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      com : float, optional\n",
      " |          Specify decay in terms of center of mass\n",
      " |      \n",
      " |          :math:`\\alpha = 1 / (1 + com)`, for :math:`com \\geq 0`.\n",
      " |      \n",
      " |      span : float, optional\n",
      " |          Specify decay in terms of span\n",
      " |      \n",
      " |          :math:`\\alpha = 2 / (span + 1)`, for :math:`span \\geq 1`.\n",
      " |      \n",
      " |      halflife : float, str, timedelta, optional\n",
      " |          Specify decay in terms of half-life\n",
      " |      \n",
      " |          :math:`\\alpha = 1 - \\exp\\left(-\\ln(2) / halflife\\right)`, for\n",
      " |          :math:`halflife > 0`.\n",
      " |      \n",
      " |          If ``times`` is specified, the time unit (str or timedelta) over which an\n",
      " |          observation decays to half its value. Only applicable to ``mean()``,\n",
      " |          and halflife value will not apply to the other functions.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      alpha : float, optional\n",
      " |          Specify smoothing factor :math:`\\alpha` directly\n",
      " |      \n",
      " |          :math:`0 < \\alpha \\leq 1`.\n",
      " |      \n",
      " |      min_periods : int, default 0\n",
      " |          Minimum number of observations in window required to have a value;\n",
      " |          otherwise, result is ``np.nan``.\n",
      " |      \n",
      " |      adjust : bool, default True\n",
      " |          Divide by decaying adjustment factor in beginning periods to account\n",
      " |          for imbalance in relative weightings (viewing EWMA as a moving average).\n",
      " |      \n",
      " |          - When ``adjust=True`` (default), the EW function is calculated using weights\n",
      " |            :math:`w_i = (1 - \\alpha)^i`. For example, the EW moving average of the series\n",
      " |            [:math:`x_0, x_1, ..., x_t`] would be:\n",
      " |      \n",
      " |          .. math::\n",
      " |              y_t = \\frac{x_t + (1 - \\alpha)x_{t-1} + (1 - \\alpha)^2 x_{t-2} + ... + (1 -\n",
      " |              \\alpha)^t x_0}{1 + (1 - \\alpha) + (1 - \\alpha)^2 + ... + (1 - \\alpha)^t}\n",
      " |      \n",
      " |          - When ``adjust=False``, the exponentially weighted function is calculated\n",
      " |            recursively:\n",
      " |      \n",
      " |          .. math::\n",
      " |              \\begin{split}\n",
      " |                  y_0 &= x_0\\\\\n",
      " |                  y_t &= (1 - \\alpha) y_{t-1} + \\alpha x_t,\n",
      " |              \\end{split}\n",
      " |      ignore_na : bool, default False\n",
      " |          Ignore missing values when calculating weights.\n",
      " |      \n",
      " |          - When ``ignore_na=False`` (default), weights are based on absolute positions.\n",
      " |            For example, the weights of :math:`x_0` and :math:`x_2` used in calculating\n",
      " |            the final weighted average of [:math:`x_0`, None, :math:`x_2`] are\n",
      " |            :math:`(1-\\alpha)^2` and :math:`1` if ``adjust=True``, and\n",
      " |            :math:`(1-\\alpha)^2` and :math:`\\alpha` if ``adjust=False``.\n",
      " |      \n",
      " |          - When ``ignore_na=True``, weights are based\n",
      " |            on relative positions. For example, the weights of :math:`x_0` and :math:`x_2`\n",
      " |            used in calculating the final weighted average of\n",
      " |            [:math:`x_0`, None, :math:`x_2`] are :math:`1-\\alpha` and :math:`1` if\n",
      " |            ``adjust=True``, and :math:`1-\\alpha` and :math:`\\alpha` if ``adjust=False``.\n",
      " |      \n",
      " |      axis : {0, 1}, default 0\n",
      " |          If ``0`` or ``'index'``, calculate across the rows.\n",
      " |      \n",
      " |          If ``1`` or ``'columns'``, calculate across the columns.\n",
      " |      \n",
      " |      times : str, np.ndarray, Series, default None\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |          Only applicable to ``mean()``.\n",
      " |      \n",
      " |          Times corresponding to the observations. Must be monotonically increasing and\n",
      " |          ``datetime64[ns]`` dtype.\n",
      " |      \n",
      " |          If 1-D array like, a sequence with the same shape as the observations.\n",
      " |      \n",
      " |          .. deprecated:: 1.4.0\n",
      " |              If str, the name of the column in the DataFrame representing the times.\n",
      " |      \n",
      " |      method : str {'single', 'table'}, default 'single'\n",
      " |          .. versionadded:: 1.4.0\n",
      " |      \n",
      " |          Execute the rolling operation per single column or row (``'single'``)\n",
      " |          or over the entire object (``'table'``).\n",
      " |      \n",
      " |          This argument is only implemented when specifying ``engine='numba'``\n",
      " |          in the method call.\n",
      " |      \n",
      " |          Only applicable to ``mean()``\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ``ExponentialMovingWindow`` subclass\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      rolling : Provides rolling window calculations.\n",
      " |      expanding : Provides expanding transformations.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See :ref:`Windowing Operations <window.exponentially_weighted>`\n",
      " |      for further usage details and examples.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      " |      >>> df\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  2.0\n",
      " |      3  NaN\n",
      " |      4  4.0\n",
      " |      \n",
      " |      >>> df.ewm(com=0.5).mean()\n",
      " |                B\n",
      " |      0  0.000000\n",
      " |      1  0.750000\n",
      " |      2  1.615385\n",
      " |      3  1.615385\n",
      " |      4  3.670213\n",
      " |      >>> df.ewm(alpha=2 / 3).mean()\n",
      " |                B\n",
      " |      0  0.000000\n",
      " |      1  0.750000\n",
      " |      2  1.615385\n",
      " |      3  1.615385\n",
      " |      4  3.670213\n",
      " |      \n",
      " |      **adjust**\n",
      " |      \n",
      " |      >>> df.ewm(com=0.5, adjust=True).mean()\n",
      " |                B\n",
      " |      0  0.000000\n",
      " |      1  0.750000\n",
      " |      2  1.615385\n",
      " |      3  1.615385\n",
      " |      4  3.670213\n",
      " |      >>> df.ewm(com=0.5, adjust=False).mean()\n",
      " |                B\n",
      " |      0  0.000000\n",
      " |      1  0.666667\n",
      " |      2  1.555556\n",
      " |      3  1.555556\n",
      " |      4  3.650794\n",
      " |      \n",
      " |      **ignore_na**\n",
      " |      \n",
      " |      >>> df.ewm(com=0.5, ignore_na=True).mean()\n",
      " |                B\n",
      " |      0  0.000000\n",
      " |      1  0.750000\n",
      " |      2  1.615385\n",
      " |      3  1.615385\n",
      " |      4  3.225000\n",
      " |      >>> df.ewm(com=0.5, ignore_na=False).mean()\n",
      " |                B\n",
      " |      0  0.000000\n",
      " |      1  0.750000\n",
      " |      2  1.615385\n",
      " |      3  1.615385\n",
      " |      4  3.670213\n",
      " |      \n",
      " |      **times**\n",
      " |      \n",
      " |      Exponentially weighted mean with weights calculated with a timedelta ``halflife``\n",
      " |      relative to ``times``.\n",
      " |      \n",
      " |      >>> times = ['2020-01-01', '2020-01-03', '2020-01-10', '2020-01-15', '2020-01-17']\n",
      " |      >>> df.ewm(halflife='4 days', times=pd.DatetimeIndex(times)).mean()\n",
      " |                B\n",
      " |      0  0.000000\n",
      " |      1  0.585786\n",
      " |      2  1.523889\n",
      " |      3  1.523889\n",
      " |      4  3.233686\n",
      " |  \n",
      " |  expanding(self, min_periods: 'int' = 1, center: 'bool_t | None' = None, axis: 'Axis' = 0, method: 'str' = 'single') -> 'Expanding'\n",
      " |      Provide expanding window calculations.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      min_periods : int, default 1\n",
      " |          Minimum number of observations in window required to have a value;\n",
      " |          otherwise, result is ``np.nan``.\n",
      " |      \n",
      " |      center : bool, default False\n",
      " |          If False, set the window labels as the right edge of the window index.\n",
      " |      \n",
      " |          If True, set the window labels as the center of the window index.\n",
      " |      \n",
      " |          .. deprecated:: 1.1.0\n",
      " |      \n",
      " |      axis : int or str, default 0\n",
      " |          If ``0`` or ``'index'``, roll across the rows.\n",
      " |      \n",
      " |          If ``1`` or ``'columns'``, roll across the columns.\n",
      " |      \n",
      " |      method : str {'single', 'table'}, default 'single'\n",
      " |          Execute the rolling operation per single column or row (``'single'``)\n",
      " |          or over the entire object (``'table'``).\n",
      " |      \n",
      " |          This argument is only implemented when specifying ``engine='numba'``\n",
      " |          in the method call.\n",
      " |      \n",
      " |          .. versionadded:: 1.3.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ``Expanding`` subclass\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      rolling : Provides rolling window calculations.\n",
      " |      ewm : Provides exponential weighted functions.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See :ref:`Windowing Operations <window.expanding>` for further usage details\n",
      " |      and examples.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"B\": [0, 1, 2, np.nan, 4]})\n",
      " |      >>> df\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  2.0\n",
      " |      3  NaN\n",
      " |      4  4.0\n",
      " |      \n",
      " |      **min_periods**\n",
      " |      \n",
      " |      Expanding sum with 1 vs 3 observations needed to calculate a value.\n",
      " |      \n",
      " |      >>> df.expanding(1).sum()\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  3.0\n",
      " |      4  7.0\n",
      " |      >>> df.expanding(3).sum()\n",
      " |           B\n",
      " |      0  NaN\n",
      " |      1  NaN\n",
      " |      2  3.0\n",
      " |      3  3.0\n",
      " |      4  7.0\n",
      " |  \n",
      " |  filter(self: 'NDFrameT', items=None, like: 'str | None' = None, regex: 'str | None' = None, axis=None) -> 'NDFrameT'\n",
      " |      Subset the dataframe rows or columns according to the specified index labels.\n",
      " |      \n",
      " |      Note that this routine does not filter a dataframe on its\n",
      " |      contents. The filter is applied to the labels of the index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      items : list-like\n",
      " |          Keep labels from axis which are in items.\n",
      " |      like : str\n",
      " |          Keep labels from axis for which \"like in label == True\".\n",
      " |      regex : str (regular expression)\n",
      " |          Keep labels from axis for which re.search(regex, label) == True.\n",
      " |      axis : {0 or ‘index’, 1 or ‘columns’, None}, default None\n",
      " |          The axis to filter on, expressed either as an index (int)\n",
      " |          or axis name (str). By default this is the info axis,\n",
      " |          'index' for Series, 'columns' for DataFrame.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as input object\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Access a group of rows and columns\n",
      " |          by label(s) or a boolean array.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The ``items``, ``like``, and ``regex`` parameters are\n",
      " |      enforced to be mutually exclusive.\n",
      " |      \n",
      " |      ``axis`` defaults to the info axis that is used when indexing\n",
      " |      with ``[]``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(np.array(([1, 2, 3], [4, 5, 6])),\n",
      " |      ...                   index=['mouse', 'rabbit'],\n",
      " |      ...                   columns=['one', 'two', 'three'])\n",
      " |      >>> df\n",
      " |              one  two  three\n",
      " |      mouse     1    2      3\n",
      " |      rabbit    4    5      6\n",
      " |      \n",
      " |      >>> # select columns by name\n",
      " |      >>> df.filter(items=['one', 'three'])\n",
      " |               one  three\n",
      " |      mouse     1      3\n",
      " |      rabbit    4      6\n",
      " |      \n",
      " |      >>> # select columns by regular expression\n",
      " |      >>> df.filter(regex='e$', axis=1)\n",
      " |               one  three\n",
      " |      mouse     1      3\n",
      " |      rabbit    4      6\n",
      " |      \n",
      " |      >>> # select rows containing 'bbi'\n",
      " |      >>> df.filter(like='bbi', axis=0)\n",
      " |               one  two  three\n",
      " |      rabbit    4    5      6\n",
      " |  \n",
      " |  first(self: 'NDFrameT', offset) -> 'NDFrameT'\n",
      " |      Select initial periods of time series data based on a date offset.\n",
      " |      \n",
      " |      When having a DataFrame with dates as index, this function can\n",
      " |      select the first few rows based on a date offset.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      offset : str, DateOffset or dateutil.relativedelta\n",
      " |          The offset length of the data that will be selected. For instance,\n",
      " |          '1M' will display all the rows having their index within the first month.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          A subset of the caller.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      last : Select final periods of time series based on a date offset.\n",
      " |      at_time : Select values at a particular time of the day.\n",
      " |      between_time : Select values between particular times of the day.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='2D')\n",
      " |      >>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)\n",
      " |      >>> ts\n",
      " |                  A\n",
      " |      2018-04-09  1\n",
      " |      2018-04-11  2\n",
      " |      2018-04-13  3\n",
      " |      2018-04-15  4\n",
      " |      \n",
      " |      Get the rows for the first 3 days:\n",
      " |      \n",
      " |      >>> ts.first('3D')\n",
      " |                  A\n",
      " |      2018-04-09  1\n",
      " |      2018-04-11  2\n",
      " |      \n",
      " |      Notice the data for 3 first calendar days were returned, not the first\n",
      " |      3 days observed in the dataset, and therefore data for 2018-04-13 was\n",
      " |      not returned.\n",
      " |  \n",
      " |  first_valid_index(self) -> 'Hashable | None'\n",
      " |      Return index for first non-NA value or None, if no non-NA value is found.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar : type of index\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If all elements are non-NA/null, returns None.\n",
      " |      Also returns None for empty Series/DataFrame.\n",
      " |  \n",
      " |  get(self, key, default=None)\n",
      " |      Get item from object for given key (ex: DataFrame column).\n",
      " |      \n",
      " |      Returns default value if not found.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : object\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      value : same type as items contained in object\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(\n",
      " |      ...     [\n",
      " |      ...         [24.3, 75.7, \"high\"],\n",
      " |      ...         [31, 87.8, \"high\"],\n",
      " |      ...         [22, 71.6, \"medium\"],\n",
      " |      ...         [35, 95, \"medium\"],\n",
      " |      ...     ],\n",
      " |      ...     columns=[\"temp_celsius\", \"temp_fahrenheit\", \"windspeed\"],\n",
      " |      ...     index=pd.date_range(start=\"2014-02-12\", end=\"2014-02-15\", freq=\"D\"),\n",
      " |      ... )\n",
      " |      \n",
      " |      >>> df\n",
      " |                  temp_celsius  temp_fahrenheit windspeed\n",
      " |      2014-02-12          24.3             75.7      high\n",
      " |      2014-02-13          31.0             87.8      high\n",
      " |      2014-02-14          22.0             71.6    medium\n",
      " |      2014-02-15          35.0             95.0    medium\n",
      " |      \n",
      " |      >>> df.get([\"temp_celsius\", \"windspeed\"])\n",
      " |                  temp_celsius windspeed\n",
      " |      2014-02-12          24.3      high\n",
      " |      2014-02-13          31.0      high\n",
      " |      2014-02-14          22.0    medium\n",
      " |      2014-02-15          35.0    medium\n",
      " |      \n",
      " |      If the key isn't found, the default value will be used.\n",
      " |      \n",
      " |      >>> df.get([\"temp_celsius\", \"temp_kelvin\"], default=\"default_value\")\n",
      " |      'default_value'\n",
      " |  \n",
      " |  head(self: 'NDFrameT', n: 'int' = 5) -> 'NDFrameT'\n",
      " |      Return the first `n` rows.\n",
      " |      \n",
      " |      This function returns the first `n` rows for the object based\n",
      " |      on position. It is useful for quickly testing if your object\n",
      " |      has the right type of data in it.\n",
      " |      \n",
      " |      For negative values of `n`, this function returns all rows except\n",
      " |      the last `n` rows, equivalent to ``df[:-n]``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, default 5\n",
      " |          Number of rows to select.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as caller\n",
      " |          The first `n` rows of the caller object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.tail: Returns the last `n` rows.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'animal': ['alligator', 'bee', 'falcon', 'lion',\n",
      " |      ...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})\n",
      " |      >>> df\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |      5     parrot\n",
      " |      6      shark\n",
      " |      7      whale\n",
      " |      8      zebra\n",
      " |      \n",
      " |      Viewing the first 5 lines\n",
      " |      \n",
      " |      >>> df.head()\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |      \n",
      " |      Viewing the first `n` lines (three in this case)\n",
      " |      \n",
      " |      >>> df.head(3)\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      \n",
      " |      For negative values of `n`\n",
      " |      \n",
      " |      >>> df.head(-3)\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |      5     parrot\n",
      " |  \n",
      " |  infer_objects(self: 'NDFrameT') -> 'NDFrameT'\n",
      " |      Attempt to infer better dtypes for object columns.\n",
      " |      \n",
      " |      Attempts soft conversion of object-dtyped\n",
      " |      columns, leaving non-object and unconvertible\n",
      " |      columns unchanged. The inference rules are the\n",
      " |      same as during normal Series/DataFrame construction.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      converted : same type as input object\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      to_datetime : Convert argument to datetime.\n",
      " |      to_timedelta : Convert argument to timedelta.\n",
      " |      to_numeric : Convert argument to numeric type.\n",
      " |      convert_dtypes : Convert argument to best possible dtype.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"A\": [\"a\", 1, 2, 3]})\n",
      " |      >>> df = df.iloc[1:]\n",
      " |      >>> df\n",
      " |         A\n",
      " |      1  1\n",
      " |      2  2\n",
      " |      3  3\n",
      " |      \n",
      " |      >>> df.dtypes\n",
      " |      A    object\n",
      " |      dtype: object\n",
      " |      \n",
      " |      >>> df.infer_objects().dtypes\n",
      " |      A    int64\n",
      " |      dtype: object\n",
      " |  \n",
      " |  keys(self)\n",
      " |      Get the 'info axis' (see Indexing for more).\n",
      " |      \n",
      " |      This is index for Series, columns for DataFrame.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Index\n",
      " |          Info axis.\n",
      " |  \n",
      " |  last(self: 'NDFrameT', offset) -> 'NDFrameT'\n",
      " |      Select final periods of time series data based on a date offset.\n",
      " |      \n",
      " |      For a DataFrame with a sorted DatetimeIndex, this function\n",
      " |      selects the last few rows based on a date offset.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      offset : str, DateOffset, dateutil.relativedelta\n",
      " |          The offset length of the data that will be selected. For instance,\n",
      " |          '3D' will display all the rows having their index within the last 3 days.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          A subset of the caller.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      first : Select initial periods of time series based on a date offset.\n",
      " |      at_time : Select values at a particular time of the day.\n",
      " |      between_time : Select values between particular times of the day.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='2D')\n",
      " |      >>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)\n",
      " |      >>> ts\n",
      " |                  A\n",
      " |      2018-04-09  1\n",
      " |      2018-04-11  2\n",
      " |      2018-04-13  3\n",
      " |      2018-04-15  4\n",
      " |      \n",
      " |      Get the rows for the last 3 days:\n",
      " |      \n",
      " |      >>> ts.last('3D')\n",
      " |                  A\n",
      " |      2018-04-13  3\n",
      " |      2018-04-15  4\n",
      " |      \n",
      " |      Notice the data for 3 last calendar days were returned, not the last\n",
      " |      3 observed days in the dataset, and therefore data for 2018-04-11 was\n",
      " |      not returned.\n",
      " |  \n",
      " |  last_valid_index(self) -> 'Hashable | None'\n",
      " |      Return index for last non-NA value or None, if no non-NA value is found.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar : type of index\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If all elements are non-NA/null, returns None.\n",
      " |      Also returns None for empty Series/DataFrame.\n",
      " |  \n",
      " |  pad = ffill(self: 'NDFrameT', axis: 'None | Axis' = None, inplace: 'bool_t' = False, limit: 'None | int' = None, downcast=None) -> 'NDFrameT | None'\n",
      " |      Synonym for :meth:`DataFrame.fillna` with ``method='ffill'``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame or None\n",
      " |          Object with missing values filled or None if ``inplace=True``.\n",
      " |  \n",
      " |  pct_change(self: 'NDFrameT', periods=1, fill_method='pad', limit=None, freq=None, **kwargs) -> 'NDFrameT'\n",
      " |      Percentage change between the current and a prior element.\n",
      " |      \n",
      " |      Computes the percentage change from the immediately previous row by\n",
      " |      default. This is useful in comparing the percentage of change in a time\n",
      " |      series of elements.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int, default 1\n",
      " |          Periods to shift for forming percent change.\n",
      " |      fill_method : str, default 'pad'\n",
      " |          How to handle NAs before computing percent changes.\n",
      " |      limit : int, default None\n",
      " |          The number of consecutive NAs to fill before stopping.\n",
      " |      freq : DateOffset, timedelta, or str, optional\n",
      " |          Increment to use from time series API (e.g. 'M' or BDay()).\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments are passed into\n",
      " |          `DataFrame.shift` or `Series.shift`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      chg : Series or DataFrame\n",
      " |          The same type as the calling object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.diff : Compute the difference of two elements in a Series.\n",
      " |      DataFrame.diff : Compute the difference of two elements in a DataFrame.\n",
      " |      Series.shift : Shift the index by some number of periods.\n",
      " |      DataFrame.shift : Shift the index by some number of periods.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([90, 91, 85])\n",
      " |      >>> s\n",
      " |      0    90\n",
      " |      1    91\n",
      " |      2    85\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.pct_change()\n",
      " |      0         NaN\n",
      " |      1    0.011111\n",
      " |      2   -0.065934\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.pct_change(periods=2)\n",
      " |      0         NaN\n",
      " |      1         NaN\n",
      " |      2   -0.055556\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See the percentage change in a Series where filling NAs with last\n",
      " |      valid observation forward to next valid.\n",
      " |      \n",
      " |      >>> s = pd.Series([90, 91, None, 85])\n",
      " |      >>> s\n",
      " |      0    90.0\n",
      " |      1    91.0\n",
      " |      2     NaN\n",
      " |      3    85.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.pct_change(fill_method='ffill')\n",
      " |      0         NaN\n",
      " |      1    0.011111\n",
      " |      2    0.000000\n",
      " |      3   -0.065934\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      Percentage change in French franc, Deutsche Mark, and Italian lira from\n",
      " |      1980-01-01 to 1980-03-01.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'FR': [4.0405, 4.0963, 4.3149],\n",
      " |      ...     'GR': [1.7246, 1.7482, 1.8519],\n",
      " |      ...     'IT': [804.74, 810.01, 860.13]},\n",
      " |      ...     index=['1980-01-01', '1980-02-01', '1980-03-01'])\n",
      " |      >>> df\n",
      " |                      FR      GR      IT\n",
      " |      1980-01-01  4.0405  1.7246  804.74\n",
      " |      1980-02-01  4.0963  1.7482  810.01\n",
      " |      1980-03-01  4.3149  1.8519  860.13\n",
      " |      \n",
      " |      >>> df.pct_change()\n",
      " |                        FR        GR        IT\n",
      " |      1980-01-01       NaN       NaN       NaN\n",
      " |      1980-02-01  0.013810  0.013684  0.006549\n",
      " |      1980-03-01  0.053365  0.059318  0.061876\n",
      " |      \n",
      " |      Percentage of change in GOOG and APPL stock volume. Shows computing\n",
      " |      the percentage change between columns.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     '2016': [1769950, 30586265],\n",
      " |      ...     '2015': [1500923, 40912316],\n",
      " |      ...     '2014': [1371819, 41403351]},\n",
      " |      ...     index=['GOOG', 'APPL'])\n",
      " |      >>> df\n",
      " |                2016      2015      2014\n",
      " |      GOOG   1769950   1500923   1371819\n",
      " |      APPL  30586265  40912316  41403351\n",
      " |      \n",
      " |      >>> df.pct_change(axis='columns', periods=-1)\n",
      " |                2016      2015  2014\n",
      " |      GOOG  0.179241  0.094112   NaN\n",
      " |      APPL -0.252395 -0.011860   NaN\n",
      " |  \n",
      " |  pipe(self, func: 'Callable[..., T] | tuple[Callable[..., T], str]', *args, **kwargs) -> 'T'\n",
      " |      Apply chainable functions that expect Series or DataFrames.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function\n",
      " |          Function to apply to the Series/DataFrame.\n",
      " |          ``args``, and ``kwargs`` are passed into ``func``.\n",
      " |          Alternatively a ``(callable, data_keyword)`` tuple where\n",
      " |          ``data_keyword`` is a string indicating the keyword of\n",
      " |          ``callable`` that expects the Series/DataFrame.\n",
      " |      args : iterable, optional\n",
      " |          Positional arguments passed into ``func``.\n",
      " |      kwargs : mapping, optional\n",
      " |          A dictionary of keyword arguments passed into ``func``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      object : the return type of ``func``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.apply : Apply a function along input axis of DataFrame.\n",
      " |      DataFrame.applymap : Apply a function elementwise on a whole DataFrame.\n",
      " |      Series.map : Apply a mapping correspondence on a\n",
      " |          :class:`~pandas.Series`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Use ``.pipe`` when chaining together functions that expect\n",
      " |      Series, DataFrames or GroupBy objects. Instead of writing\n",
      " |      \n",
      " |      >>> func(g(h(df), arg1=a), arg2=b, arg3=c)  # doctest: +SKIP\n",
      " |      \n",
      " |      You can write\n",
      " |      \n",
      " |      >>> (df.pipe(h)\n",
      " |      ...    .pipe(g, arg1=a)\n",
      " |      ...    .pipe(func, arg2=b, arg3=c)\n",
      " |      ... )  # doctest: +SKIP\n",
      " |      \n",
      " |      If you have a function that takes the data as (say) the second\n",
      " |      argument, pass a tuple indicating which keyword expects the\n",
      " |      data. For example, suppose ``f`` takes its data as ``arg2``:\n",
      " |      \n",
      " |      >>> (df.pipe(h)\n",
      " |      ...    .pipe(g, arg1=a)\n",
      " |      ...    .pipe((func, 'arg2'), arg1=a, arg3=c)\n",
      " |      ...  )  # doctest: +SKIP\n",
      " |  \n",
      " |  rank(self: 'NDFrameT', axis=0, method: 'str' = 'average', numeric_only: 'bool_t | None | lib.NoDefault' = <no_default>, na_option: 'str' = 'keep', ascending: 'bool_t' = True, pct: 'bool_t' = False) -> 'NDFrameT'\n",
      " |      Compute numerical data ranks (1 through n) along axis.\n",
      " |      \n",
      " |      By default, equal values are assigned a rank that is the average of the\n",
      " |      ranks of those values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Index to direct ranking.\n",
      " |      method : {'average', 'min', 'max', 'first', 'dense'}, default 'average'\n",
      " |          How to rank the group of records that have the same value (i.e. ties):\n",
      " |      \n",
      " |          * average: average rank of the group\n",
      " |          * min: lowest rank in the group\n",
      " |          * max: highest rank in the group\n",
      " |          * first: ranks assigned in order they appear in the array\n",
      " |          * dense: like 'min', but rank always increases by 1 between groups.\n",
      " |      \n",
      " |      numeric_only : bool, optional\n",
      " |          For DataFrame objects, rank only numeric columns if set to True.\n",
      " |      na_option : {'keep', 'top', 'bottom'}, default 'keep'\n",
      " |          How to rank NaN values:\n",
      " |      \n",
      " |          * keep: assign NaN rank to NaN values\n",
      " |          * top: assign lowest rank to NaN values\n",
      " |          * bottom: assign highest rank to NaN values\n",
      " |      \n",
      " |      ascending : bool, default True\n",
      " |          Whether or not the elements should be ranked in ascending order.\n",
      " |      pct : bool, default False\n",
      " |          Whether or not to display the returned rankings in percentile\n",
      " |          form.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as caller\n",
      " |          Return a Series or DataFrame with data ranks as values.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.groupby.GroupBy.rank : Rank of values within each group.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(data={'Animal': ['cat', 'penguin', 'dog',\n",
      " |      ...                                    'spider', 'snake'],\n",
      " |      ...                         'Number_legs': [4, 2, 4, 8, np.nan]})\n",
      " |      >>> df\n",
      " |          Animal  Number_legs\n",
      " |      0      cat          4.0\n",
      " |      1  penguin          2.0\n",
      " |      2      dog          4.0\n",
      " |      3   spider          8.0\n",
      " |      4    snake          NaN\n",
      " |      \n",
      " |      The following example shows how the method behaves with the above\n",
      " |      parameters:\n",
      " |      \n",
      " |      * default_rank: this is the default behaviour obtained without using\n",
      " |        any parameter.\n",
      " |      * max_rank: setting ``method = 'max'`` the records that have the\n",
      " |        same values are ranked using the highest rank (e.g.: since 'cat'\n",
      " |        and 'dog' are both in the 2nd and 3rd position, rank 3 is assigned.)\n",
      " |      * NA_bottom: choosing ``na_option = 'bottom'``, if there are records\n",
      " |        with NaN values they are placed at the bottom of the ranking.\n",
      " |      * pct_rank: when setting ``pct = True``, the ranking is expressed as\n",
      " |        percentile rank.\n",
      " |      \n",
      " |      >>> df['default_rank'] = df['Number_legs'].rank()\n",
      " |      >>> df['max_rank'] = df['Number_legs'].rank(method='max')\n",
      " |      >>> df['NA_bottom'] = df['Number_legs'].rank(na_option='bottom')\n",
      " |      >>> df['pct_rank'] = df['Number_legs'].rank(pct=True)\n",
      " |      >>> df\n",
      " |          Animal  Number_legs  default_rank  max_rank  NA_bottom  pct_rank\n",
      " |      0      cat          4.0           2.5       3.0        2.5     0.625\n",
      " |      1  penguin          2.0           1.0       1.0        1.0     0.250\n",
      " |      2      dog          4.0           2.5       3.0        2.5     0.625\n",
      " |      3   spider          8.0           4.0       4.0        4.0     1.000\n",
      " |      4    snake          NaN           NaN       NaN        5.0       NaN\n",
      " |  \n",
      " |  reindex_like(self: 'NDFrameT', other, method: 'str | None' = None, copy: 'bool_t' = True, limit=None, tolerance=None) -> 'NDFrameT'\n",
      " |      Return an object with matching indices as other object.\n",
      " |      \n",
      " |      Conform the object to the same index on all axes. Optional\n",
      " |      filling logic, placing NaN in locations having no value\n",
      " |      in the previous index. A new object is produced unless the\n",
      " |      new index is equivalent to the current one and copy=False.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Object of the same data type\n",
      " |          Its row and column indices are used to define the new indices\n",
      " |          of this object.\n",
      " |      method : {None, 'backfill'/'bfill', 'pad'/'ffill', 'nearest'}\n",
      " |          Method to use for filling holes in reindexed DataFrame.\n",
      " |          Please note: this is only applicable to DataFrames/Series with a\n",
      " |          monotonically increasing/decreasing index.\n",
      " |      \n",
      " |          * None (default): don't fill gaps\n",
      " |          * pad / ffill: propagate last valid observation forward to next\n",
      " |            valid\n",
      " |          * backfill / bfill: use next valid observation to fill gap\n",
      " |          * nearest: use nearest valid observations to fill gap.\n",
      " |      \n",
      " |      copy : bool, default True\n",
      " |          Return a new object, even if the passed indexes are the same.\n",
      " |      limit : int, default None\n",
      " |          Maximum number of consecutive labels to fill for inexact matches.\n",
      " |      tolerance : optional\n",
      " |          Maximum distance between original and new labels for inexact\n",
      " |          matches. The values of the index at the matching locations must\n",
      " |          satisfy the equation ``abs(index[indexer] - target) <= tolerance``.\n",
      " |      \n",
      " |          Tolerance may be a scalar value, which applies the same tolerance\n",
      " |          to all values, or list-like, which applies variable tolerance per\n",
      " |          element. List-like includes list, tuple, array, Series, and must be\n",
      " |          the same size as the index and its dtype must exactly match the\n",
      " |          index's type.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Same type as caller, but with changed indices on each axis.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.set_index : Set row labels.\n",
      " |      DataFrame.reset_index : Remove row labels or move them to new columns.\n",
      " |      DataFrame.reindex : Change to new indices or expand indices.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Same as calling\n",
      " |      ``.reindex(index=other.index, columns=other.columns,...)``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df1 = pd.DataFrame([[24.3, 75.7, 'high'],\n",
      " |      ...                     [31, 87.8, 'high'],\n",
      " |      ...                     [22, 71.6, 'medium'],\n",
      " |      ...                     [35, 95, 'medium']],\n",
      " |      ...                    columns=['temp_celsius', 'temp_fahrenheit',\n",
      " |      ...                             'windspeed'],\n",
      " |      ...                    index=pd.date_range(start='2014-02-12',\n",
      " |      ...                                        end='2014-02-15', freq='D'))\n",
      " |      \n",
      " |      >>> df1\n",
      " |                  temp_celsius  temp_fahrenheit windspeed\n",
      " |      2014-02-12          24.3             75.7      high\n",
      " |      2014-02-13          31.0             87.8      high\n",
      " |      2014-02-14          22.0             71.6    medium\n",
      " |      2014-02-15          35.0             95.0    medium\n",
      " |      \n",
      " |      >>> df2 = pd.DataFrame([[28, 'low'],\n",
      " |      ...                     [30, 'low'],\n",
      " |      ...                     [35.1, 'medium']],\n",
      " |      ...                    columns=['temp_celsius', 'windspeed'],\n",
      " |      ...                    index=pd.DatetimeIndex(['2014-02-12', '2014-02-13',\n",
      " |      ...                                            '2014-02-15']))\n",
      " |      \n",
      " |      >>> df2\n",
      " |                  temp_celsius windspeed\n",
      " |      2014-02-12          28.0       low\n",
      " |      2014-02-13          30.0       low\n",
      " |      2014-02-15          35.1    medium\n",
      " |      \n",
      " |      >>> df2.reindex_like(df1)\n",
      " |                  temp_celsius  temp_fahrenheit windspeed\n",
      " |      2014-02-12          28.0              NaN       low\n",
      " |      2014-02-13          30.0              NaN       low\n",
      " |      2014-02-14           NaN              NaN       NaN\n",
      " |      2014-02-15          35.1              NaN    medium\n",
      " |  \n",
      " |  rename_axis(self, mapper=None, index=None, columns=None, axis=None, copy=True, inplace=False)\n",
      " |      Set the name of the axis for the index or columns.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      mapper : scalar, list-like, optional\n",
      " |          Value to set the axis name attribute.\n",
      " |      index, columns : scalar, list-like, dict-like or function, optional\n",
      " |          A scalar, list-like, dict-like or functions transformations to\n",
      " |          apply to that axis' values.\n",
      " |          Note that the ``columns`` parameter is not allowed if the\n",
      " |          object is a Series. This parameter only apply for DataFrame\n",
      " |          type objects.\n",
      " |      \n",
      " |          Use either ``mapper`` and ``axis`` to\n",
      " |          specify the axis to target with ``mapper``, or ``index``\n",
      " |          and/or ``columns``.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to rename.\n",
      " |      copy : bool, default True\n",
      " |          Also copy underlying data.\n",
      " |      inplace : bool, default False\n",
      " |          Modifies the object directly, instead of creating a new Series\n",
      " |          or DataFrame.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series, DataFrame, or None\n",
      " |          The same type as the caller or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.rename : Alter Series index labels or name.\n",
      " |      DataFrame.rename : Alter DataFrame index labels or name.\n",
      " |      Index.rename : Set new names on index.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      ``DataFrame.rename_axis`` supports two calling conventions\n",
      " |      \n",
      " |      * ``(index=index_mapper, columns=columns_mapper, ...)``\n",
      " |      * ``(mapper, axis={'index', 'columns'}, ...)``\n",
      " |      \n",
      " |      The first calling convention will only modify the names of\n",
      " |      the index and/or the names of the Index object that is the columns.\n",
      " |      In this case, the parameter ``copy`` is ignored.\n",
      " |      \n",
      " |      The second calling convention will modify the names of the\n",
      " |      corresponding index if mapper is a list or a scalar.\n",
      " |      However, if mapper is dict-like or a function, it will use the\n",
      " |      deprecated behavior of modifying the axis *labels*.\n",
      " |      \n",
      " |      We *highly* recommend using keyword arguments to clarify your\n",
      " |      intent.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([\"dog\", \"cat\", \"monkey\"])\n",
      " |      >>> s\n",
      " |      0       dog\n",
      " |      1       cat\n",
      " |      2    monkey\n",
      " |      dtype: object\n",
      " |      >>> s.rename_axis(\"animal\")\n",
      " |      animal\n",
      " |      0    dog\n",
      " |      1    cat\n",
      " |      2    monkey\n",
      " |      dtype: object\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"num_legs\": [4, 4, 2],\n",
      " |      ...                    \"num_arms\": [0, 0, 2]},\n",
      " |      ...                   [\"dog\", \"cat\", \"monkey\"])\n",
      " |      >>> df\n",
      " |              num_legs  num_arms\n",
      " |      dog            4         0\n",
      " |      cat            4         0\n",
      " |      monkey         2         2\n",
      " |      >>> df = df.rename_axis(\"animal\")\n",
      " |      >>> df\n",
      " |              num_legs  num_arms\n",
      " |      animal\n",
      " |      dog            4         0\n",
      " |      cat            4         0\n",
      " |      monkey         2         2\n",
      " |      >>> df = df.rename_axis(\"limbs\", axis=\"columns\")\n",
      " |      >>> df\n",
      " |      limbs   num_legs  num_arms\n",
      " |      animal\n",
      " |      dog            4         0\n",
      " |      cat            4         0\n",
      " |      monkey         2         2\n",
      " |      \n",
      " |      **MultiIndex**\n",
      " |      \n",
      " |      >>> df.index = pd.MultiIndex.from_product([['mammal'],\n",
      " |      ...                                        ['dog', 'cat', 'monkey']],\n",
      " |      ...                                       names=['type', 'name'])\n",
      " |      >>> df\n",
      " |      limbs          num_legs  num_arms\n",
      " |      type   name\n",
      " |      mammal dog            4         0\n",
      " |             cat            4         0\n",
      " |             monkey         2         2\n",
      " |      \n",
      " |      >>> df.rename_axis(index={'type': 'class'})\n",
      " |      limbs          num_legs  num_arms\n",
      " |      class  name\n",
      " |      mammal dog            4         0\n",
      " |             cat            4         0\n",
      " |             monkey         2         2\n",
      " |      \n",
      " |      >>> df.rename_axis(columns=str.upper)\n",
      " |      LIMBS          num_legs  num_arms\n",
      " |      type   name\n",
      " |      mammal dog            4         0\n",
      " |             cat            4         0\n",
      " |             monkey         2         2\n",
      " |  \n",
      " |  rolling(self, window: 'int | timedelta | BaseOffset | BaseIndexer', min_periods: 'int | None' = None, center: 'bool_t' = False, win_type: 'str | None' = None, on: 'str | None' = None, axis: 'Axis' = 0, closed: 'str | None' = None, method: 'str' = 'single')\n",
      " |      Provide rolling window calculations.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      window : int, offset, or BaseIndexer subclass\n",
      " |          Size of the moving window.\n",
      " |      \n",
      " |          If an integer, the fixed number of observations used for\n",
      " |          each window.\n",
      " |      \n",
      " |          If an offset, the time period of each window. Each\n",
      " |          window will be a variable sized based on the observations included in\n",
      " |          the time-period. This is only valid for datetimelike indexes.\n",
      " |          To learn more about the offsets & frequency strings, please see `this link\n",
      " |          <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\n",
      " |      \n",
      " |          If a BaseIndexer subclass, the window boundaries\n",
      " |          based on the defined ``get_window_bounds`` method. Additional rolling\n",
      " |          keyword arguments, namely ``min_periods``, ``center``, and\n",
      " |          ``closed`` will be passed to ``get_window_bounds``.\n",
      " |      \n",
      " |      min_periods : int, default None\n",
      " |          Minimum number of observations in window required to have a value;\n",
      " |          otherwise, result is ``np.nan``.\n",
      " |      \n",
      " |          For a window that is specified by an offset, ``min_periods`` will default to 1.\n",
      " |      \n",
      " |          For a window that is specified by an integer, ``min_periods`` will default\n",
      " |          to the size of the window.\n",
      " |      \n",
      " |      center : bool, default False\n",
      " |          If False, set the window labels as the right edge of the window index.\n",
      " |      \n",
      " |          If True, set the window labels as the center of the window index.\n",
      " |      \n",
      " |      win_type : str, default None\n",
      " |          If ``None``, all points are evenly weighted.\n",
      " |      \n",
      " |          If a string, it must be a valid `scipy.signal window function\n",
      " |          <https://docs.scipy.org/doc/scipy/reference/signal.windows.html#module-scipy.signal.windows>`__.\n",
      " |      \n",
      " |          Certain Scipy window types require additional parameters to be passed\n",
      " |          in the aggregation function. The additional parameters must match\n",
      " |          the keywords specified in the Scipy window type method signature.\n",
      " |      \n",
      " |      on : str, optional\n",
      " |          For a DataFrame, a column label or Index level on which\n",
      " |          to calculate the rolling window, rather than the DataFrame's index.\n",
      " |      \n",
      " |          Provided integer column is ignored and excluded from result since\n",
      " |          an integer index is not used to calculate the rolling window.\n",
      " |      \n",
      " |      axis : int or str, default 0\n",
      " |          If ``0`` or ``'index'``, roll across the rows.\n",
      " |      \n",
      " |          If ``1`` or ``'columns'``, roll across the columns.\n",
      " |      \n",
      " |      closed : str, default None\n",
      " |          If ``'right'``, the first point in the window is excluded from calculations.\n",
      " |      \n",
      " |          If ``'left'``, the last point in the window is excluded from calculations.\n",
      " |      \n",
      " |          If ``'both'``, the no points in the window are excluded from calculations.\n",
      " |      \n",
      " |          If ``'neither'``, the first and last points in the window are excluded\n",
      " |          from calculations.\n",
      " |      \n",
      " |          Default ``None`` (``'right'``).\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |      \n",
      " |              The closed parameter with fixed windows is now supported.\n",
      " |      \n",
      " |      method : str {'single', 'table'}, default 'single'\n",
      " |      \n",
      " |          .. versionadded:: 1.3.0\n",
      " |      \n",
      " |          Execute the rolling operation per single column or row (``'single'``)\n",
      " |          or over the entire object (``'table'``).\n",
      " |      \n",
      " |          This argument is only implemented when specifying ``engine='numba'``\n",
      " |          in the method call.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ``Window`` subclass if a ``win_type`` is passed\n",
      " |      \n",
      " |      ``Rolling`` subclass if ``win_type`` is not passed\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      expanding : Provides expanding transformations.\n",
      " |      ewm : Provides exponential weighted functions.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See :ref:`Windowing Operations <window.generic>` for further usage details\n",
      " |      and examples.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      " |      >>> df\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  2.0\n",
      " |      3  NaN\n",
      " |      4  4.0\n",
      " |      \n",
      " |      **window**\n",
      " |      \n",
      " |      Rolling sum with a window length of 2 observations.\n",
      " |      \n",
      " |      >>> df.rolling(2).sum()\n",
      " |           B\n",
      " |      0  NaN\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  NaN\n",
      " |      4  NaN\n",
      " |      \n",
      " |      Rolling sum with a window span of 2 seconds.\n",
      " |      \n",
      " |      >>> df_time = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]},\n",
      " |      ...                        index = [pd.Timestamp('20130101 09:00:00'),\n",
      " |      ...                                 pd.Timestamp('20130101 09:00:02'),\n",
      " |      ...                                 pd.Timestamp('20130101 09:00:03'),\n",
      " |      ...                                 pd.Timestamp('20130101 09:00:05'),\n",
      " |      ...                                 pd.Timestamp('20130101 09:00:06')])\n",
      " |      \n",
      " |      >>> df_time\n",
      " |                             B\n",
      " |      2013-01-01 09:00:00  0.0\n",
      " |      2013-01-01 09:00:02  1.0\n",
      " |      2013-01-01 09:00:03  2.0\n",
      " |      2013-01-01 09:00:05  NaN\n",
      " |      2013-01-01 09:00:06  4.0\n",
      " |      \n",
      " |      >>> df_time.rolling('2s').sum()\n",
      " |                             B\n",
      " |      2013-01-01 09:00:00  0.0\n",
      " |      2013-01-01 09:00:02  1.0\n",
      " |      2013-01-01 09:00:03  3.0\n",
      " |      2013-01-01 09:00:05  NaN\n",
      " |      2013-01-01 09:00:06  4.0\n",
      " |      \n",
      " |      Rolling sum with forward looking windows with 2 observations.\n",
      " |      \n",
      " |      >>> indexer = pd.api.indexers.FixedForwardWindowIndexer(window_size=2)\n",
      " |      >>> df.rolling(window=indexer, min_periods=1).sum()\n",
      " |           B\n",
      " |      0  1.0\n",
      " |      1  3.0\n",
      " |      2  2.0\n",
      " |      3  4.0\n",
      " |      4  4.0\n",
      " |      \n",
      " |      **min_periods**\n",
      " |      \n",
      " |      Rolling sum with a window length of 2 observations, but only needs a minimum of 1\n",
      " |      observation to calculate a value.\n",
      " |      \n",
      " |      >>> df.rolling(2, min_periods=1).sum()\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  2.0\n",
      " |      4  4.0\n",
      " |      \n",
      " |      **center**\n",
      " |      \n",
      " |      Rolling sum with the result assigned to the center of the window index.\n",
      " |      \n",
      " |      >>> df.rolling(3, min_periods=1, center=True).sum()\n",
      " |           B\n",
      " |      0  1.0\n",
      " |      1  3.0\n",
      " |      2  3.0\n",
      " |      3  6.0\n",
      " |      4  4.0\n",
      " |      \n",
      " |      >>> df.rolling(3, min_periods=1, center=False).sum()\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  3.0\n",
      " |      4  6.0\n",
      " |      \n",
      " |      **win_type**\n",
      " |      \n",
      " |      Rolling sum with a window length of 2, using the Scipy ``'gaussian'``\n",
      " |      window type. ``std`` is required in the aggregation function.\n",
      " |      \n",
      " |      >>> df.rolling(2, win_type='gaussian').sum(std=3)\n",
      " |                B\n",
      " |      0       NaN\n",
      " |      1  0.986207\n",
      " |      2  2.958621\n",
      " |      3       NaN\n",
      " |      4       NaN\n",
      " |  \n",
      " |  sample(self: 'NDFrameT', n: 'int | None' = None, frac: 'float | None' = None, replace: 'bool_t' = False, weights=None, random_state: 'RandomState | None' = None, axis: 'Axis | None' = None, ignore_index: 'bool_t' = False) -> 'NDFrameT'\n",
      " |      Return a random sample of items from an axis of object.\n",
      " |      \n",
      " |      You can use `random_state` for reproducibility.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, optional\n",
      " |          Number of items from axis to return. Cannot be used with `frac`.\n",
      " |          Default = 1 if `frac` = None.\n",
      " |      frac : float, optional\n",
      " |          Fraction of axis items to return. Cannot be used with `n`.\n",
      " |      replace : bool, default False\n",
      " |          Allow or disallow sampling of the same row more than once.\n",
      " |      weights : str or ndarray-like, optional\n",
      " |          Default 'None' results in equal probability weighting.\n",
      " |          If passed a Series, will align with target object on index. Index\n",
      " |          values in weights not found in sampled object will be ignored and\n",
      " |          index values in sampled object not in weights will be assigned\n",
      " |          weights of zero.\n",
      " |          If called on a DataFrame, will accept the name of a column\n",
      " |          when axis = 0.\n",
      " |          Unless weights are a Series, weights must be same length as axis\n",
      " |          being sampled.\n",
      " |          If weights do not sum to 1, they will be normalized to sum to 1.\n",
      " |          Missing values in the weights column will be treated as zero.\n",
      " |          Infinite values not allowed.\n",
      " |      random_state : int, array-like, BitGenerator, np.random.RandomState, np.random.Generator, optional\n",
      " |          If int, array-like, or BitGenerator, seed for random number generator.\n",
      " |          If np.random.RandomState or np.random.Generator, use as given.\n",
      " |      \n",
      " |          .. versionchanged:: 1.1.0\n",
      " |      \n",
      " |              array-like and BitGenerator object now passed to np.random.RandomState()\n",
      " |              as seed\n",
      " |      \n",
      " |          .. versionchanged:: 1.4.0\n",
      " |      \n",
      " |              np.random.Generator objects now accepted\n",
      " |      \n",
      " |      axis : {0 or ‘index’, 1 or ‘columns’, None}, default None\n",
      " |          Axis to sample. Accepts axis number or name. Default is stat axis\n",
      " |          for given data type (0 for Series and DataFrames).\n",
      " |      ignore_index : bool, default False\n",
      " |          If True, the resulting index will be labeled 0, 1, …, n - 1.\n",
      " |      \n",
      " |          .. versionadded:: 1.3.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          A new object of same type as caller containing `n` items randomly\n",
      " |          sampled from the caller object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrameGroupBy.sample: Generates random samples from each group of a\n",
      " |          DataFrame object.\n",
      " |      SeriesGroupBy.sample: Generates random samples from each group of a\n",
      " |          Series object.\n",
      " |      numpy.random.choice: Generates a random sample from a given 1-D numpy\n",
      " |          array.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If `frac` > 1, `replacement` should be set to `True`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'num_legs': [2, 4, 8, 0],\n",
      " |      ...                    'num_wings': [2, 0, 0, 0],\n",
      " |      ...                    'num_specimen_seen': [10, 2, 1, 8]},\n",
      " |      ...                   index=['falcon', 'dog', 'spider', 'fish'])\n",
      " |      >>> df\n",
      " |              num_legs  num_wings  num_specimen_seen\n",
      " |      falcon         2          2                 10\n",
      " |      dog            4          0                  2\n",
      " |      spider         8          0                  1\n",
      " |      fish           0          0                  8\n",
      " |      \n",
      " |      Extract 3 random elements from the ``Series`` ``df['num_legs']``:\n",
      " |      Note that we use `random_state` to ensure the reproducibility of\n",
      " |      the examples.\n",
      " |      \n",
      " |      >>> df['num_legs'].sample(n=3, random_state=1)\n",
      " |      fish      0\n",
      " |      spider    8\n",
      " |      falcon    2\n",
      " |      Name: num_legs, dtype: int64\n",
      " |      \n",
      " |      A random 50% sample of the ``DataFrame`` with replacement:\n",
      " |      \n",
      " |      >>> df.sample(frac=0.5, replace=True, random_state=1)\n",
      " |            num_legs  num_wings  num_specimen_seen\n",
      " |      dog          4          0                  2\n",
      " |      fish         0          0                  8\n",
      " |      \n",
      " |      An upsample sample of the ``DataFrame`` with replacement:\n",
      " |      Note that `replace` parameter has to be `True` for `frac` parameter > 1.\n",
      " |      \n",
      " |      >>> df.sample(frac=2, replace=True, random_state=1)\n",
      " |              num_legs  num_wings  num_specimen_seen\n",
      " |      dog            4          0                  2\n",
      " |      fish           0          0                  8\n",
      " |      falcon         2          2                 10\n",
      " |      falcon         2          2                 10\n",
      " |      fish           0          0                  8\n",
      " |      dog            4          0                  2\n",
      " |      fish           0          0                  8\n",
      " |      dog            4          0                  2\n",
      " |      \n",
      " |      Using a DataFrame column as weights. Rows with larger value in the\n",
      " |      `num_specimen_seen` column are more likely to be sampled.\n",
      " |      \n",
      " |      >>> df.sample(n=2, weights='num_specimen_seen', random_state=1)\n",
      " |              num_legs  num_wings  num_specimen_seen\n",
      " |      falcon         2          2                 10\n",
      " |      fish           0          0                  8\n",
      " |  \n",
      " |  set_flags(self: 'NDFrameT', *, copy: 'bool_t' = False, allows_duplicate_labels: 'bool_t | None' = None) -> 'NDFrameT'\n",
      " |      Return a new object with updated flags.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      allows_duplicate_labels : bool, optional\n",
      " |          Whether the returned object allows duplicate labels.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          The same type as the caller.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.attrs : Global metadata applying to this dataset.\n",
      " |      DataFrame.flags : Global flags applying to this object.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method returns a new object that's a view on the same data\n",
      " |      as the input. Mutating the input or the output values will be reflected\n",
      " |      in the other.\n",
      " |      \n",
      " |      This method is intended to be used in method chains.\n",
      " |      \n",
      " |      \"Flags\" differ from \"metadata\". Flags reflect properties of the\n",
      " |      pandas object (the Series or DataFrame). Metadata refer to properties\n",
      " |      of the dataset, and should be stored in :attr:`DataFrame.attrs`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2]})\n",
      " |      >>> df.flags.allows_duplicate_labels\n",
      " |      True\n",
      " |      >>> df2 = df.set_flags(allows_duplicate_labels=False)\n",
      " |      >>> df2.flags.allows_duplicate_labels\n",
      " |      False\n",
      " |  \n",
      " |  slice_shift(self: 'NDFrameT', periods: 'int' = 1, axis=0) -> 'NDFrameT'\n",
      " |      Equivalent to `shift` without copying data.\n",
      " |      The shifted data will not include the dropped periods and the\n",
      " |      shifted axis will be smaller than the original.\n",
      " |      \n",
      " |      .. deprecated:: 1.2.0\n",
      " |          slice_shift is deprecated,\n",
      " |          use DataFrame/Series.shift instead.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to move, can be positive or negative.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      shifted : same type as caller\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      While the `slice_shift` is faster than `shift`, you may pay for it\n",
      " |      later during alignment.\n",
      " |  \n",
      " |  squeeze(self, axis=None)\n",
      " |      Squeeze 1 dimensional axis objects into scalars.\n",
      " |      \n",
      " |      Series or DataFrames with a single element are squeezed to a scalar.\n",
      " |      DataFrames with a single column or a single row are squeezed to a\n",
      " |      Series. Otherwise the object is unchanged.\n",
      " |      \n",
      " |      This method is most useful when you don't know if your\n",
      " |      object is a Series or DataFrame, but you do know it has just a single\n",
      " |      column. In that case you can safely call `squeeze` to ensure you have a\n",
      " |      Series.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default None\n",
      " |          A specific axis to squeeze. By default, all length-1 axes are\n",
      " |          squeezed.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame, Series, or scalar\n",
      " |          The projection after squeezing `axis` or all the axes.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.iloc : Integer-location based indexing for selecting scalars.\n",
      " |      DataFrame.iloc : Integer-location based indexing for selecting Series.\n",
      " |      Series.to_frame : Inverse of DataFrame.squeeze for a\n",
      " |          single-column DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> primes = pd.Series([2, 3, 5, 7])\n",
      " |      \n",
      " |      Slicing might produce a Series with a single value:\n",
      " |      \n",
      " |      >>> even_primes = primes[primes % 2 == 0]\n",
      " |      >>> even_primes\n",
      " |      0    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> even_primes.squeeze()\n",
      " |      2\n",
      " |      \n",
      " |      Squeezing objects with more than one value in every axis does nothing:\n",
      " |      \n",
      " |      >>> odd_primes = primes[primes % 2 == 1]\n",
      " |      >>> odd_primes\n",
      " |      1    3\n",
      " |      2    5\n",
      " |      3    7\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> odd_primes.squeeze()\n",
      " |      1    3\n",
      " |      2    5\n",
      " |      3    7\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Squeezing is even more effective when used with DataFrames.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2], [3, 4]], columns=['a', 'b'])\n",
      " |      >>> df\n",
      " |         a  b\n",
      " |      0  1  2\n",
      " |      1  3  4\n",
      " |      \n",
      " |      Slicing a single column will produce a DataFrame with the columns\n",
      " |      having only one value:\n",
      " |      \n",
      " |      >>> df_a = df[['a']]\n",
      " |      >>> df_a\n",
      " |         a\n",
      " |      0  1\n",
      " |      1  3\n",
      " |      \n",
      " |      So the columns can be squeezed down, resulting in a Series:\n",
      " |      \n",
      " |      >>> df_a.squeeze('columns')\n",
      " |      0    1\n",
      " |      1    3\n",
      " |      Name: a, dtype: int64\n",
      " |      \n",
      " |      Slicing a single row from a single column will produce a single\n",
      " |      scalar DataFrame:\n",
      " |      \n",
      " |      >>> df_0a = df.loc[df.index < 1, ['a']]\n",
      " |      >>> df_0a\n",
      " |         a\n",
      " |      0  1\n",
      " |      \n",
      " |      Squeezing the rows produces a single scalar Series:\n",
      " |      \n",
      " |      >>> df_0a.squeeze('rows')\n",
      " |      a    1\n",
      " |      Name: 0, dtype: int64\n",
      " |      \n",
      " |      Squeezing all axes will project directly into a scalar:\n",
      " |      \n",
      " |      >>> df_0a.squeeze()\n",
      " |      1\n",
      " |  \n",
      " |  swapaxes(self: 'NDFrameT', axis1, axis2, copy=True) -> 'NDFrameT'\n",
      " |      Interchange axes and swap values axes appropriately.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : same as input\n",
      " |  \n",
      " |  tail(self: 'NDFrameT', n: 'int' = 5) -> 'NDFrameT'\n",
      " |      Return the last `n` rows.\n",
      " |      \n",
      " |      This function returns last `n` rows from the object based on\n",
      " |      position. It is useful for quickly verifying data, for example,\n",
      " |      after sorting or appending rows.\n",
      " |      \n",
      " |      For negative values of `n`, this function returns all rows except\n",
      " |      the first `n` rows, equivalent to ``df[n:]``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, default 5\n",
      " |          Number of rows to select.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      type of caller\n",
      " |          The last `n` rows of the caller object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.head : The first `n` rows of the caller object.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'animal': ['alligator', 'bee', 'falcon', 'lion',\n",
      " |      ...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})\n",
      " |      >>> df\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |      5     parrot\n",
      " |      6      shark\n",
      " |      7      whale\n",
      " |      8      zebra\n",
      " |      \n",
      " |      Viewing the last 5 lines\n",
      " |      \n",
      " |      >>> df.tail()\n",
      " |         animal\n",
      " |      4  monkey\n",
      " |      5  parrot\n",
      " |      6   shark\n",
      " |      7   whale\n",
      " |      8   zebra\n",
      " |      \n",
      " |      Viewing the last `n` lines (three in this case)\n",
      " |      \n",
      " |      >>> df.tail(3)\n",
      " |        animal\n",
      " |      6  shark\n",
      " |      7  whale\n",
      " |      8  zebra\n",
      " |      \n",
      " |      For negative values of `n`\n",
      " |      \n",
      " |      >>> df.tail(-3)\n",
      " |         animal\n",
      " |      3    lion\n",
      " |      4  monkey\n",
      " |      5  parrot\n",
      " |      6   shark\n",
      " |      7   whale\n",
      " |      8   zebra\n",
      " |  \n",
      " |  take(self: 'NDFrameT', indices, axis=0, is_copy: 'bool_t | None' = None, **kwargs) -> 'NDFrameT'\n",
      " |      Return the elements in the given *positional* indices along an axis.\n",
      " |      \n",
      " |      This means that we are not indexing according to actual values in\n",
      " |      the index attribute of the object. We are indexing according to the\n",
      " |      actual position of the element in the object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      indices : array-like\n",
      " |          An array of ints indicating which positions to take.\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          The axis on which to select elements. ``0`` means that we are\n",
      " |          selecting rows, ``1`` means that we are selecting columns.\n",
      " |      is_copy : bool\n",
      " |          Before pandas 1.0, ``is_copy=False`` can be specified to ensure\n",
      " |          that the return value is an actual copy. Starting with pandas 1.0,\n",
      " |          ``take`` always returns a copy, and the keyword is therefore\n",
      " |          deprecated.\n",
      " |      \n",
      " |          .. deprecated:: 1.0.0\n",
      " |      **kwargs\n",
      " |          For compatibility with :meth:`numpy.take`. Has no effect on the\n",
      " |          output.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      taken : same type as caller\n",
      " |          An array-like containing the elements taken from the object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Select a subset of a DataFrame by labels.\n",
      " |      DataFrame.iloc : Select a subset of a DataFrame by positions.\n",
      " |      numpy.take : Take elements from an array along an axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('falcon', 'bird', 389.0),\n",
      " |      ...                    ('parrot', 'bird', 24.0),\n",
      " |      ...                    ('lion', 'mammal', 80.5),\n",
      " |      ...                    ('monkey', 'mammal', np.nan)],\n",
      " |      ...                   columns=['name', 'class', 'max_speed'],\n",
      " |      ...                   index=[0, 2, 3, 1])\n",
      " |      >>> df\n",
      " |           name   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      2  parrot    bird       24.0\n",
      " |      3    lion  mammal       80.5\n",
      " |      1  monkey  mammal        NaN\n",
      " |      \n",
      " |      Take elements at positions 0 and 3 along the axis 0 (default).\n",
      " |      \n",
      " |      Note how the actual indices selected (0 and 1) do not correspond to\n",
      " |      our selected indices 0 and 3. That's because we are selecting the 0th\n",
      " |      and 3rd rows, not rows whose indices equal 0 and 3.\n",
      " |      \n",
      " |      >>> df.take([0, 3])\n",
      " |           name   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      1  monkey  mammal        NaN\n",
      " |      \n",
      " |      Take elements at indices 1 and 2 along the axis 1 (column selection).\n",
      " |      \n",
      " |      >>> df.take([1, 2], axis=1)\n",
      " |          class  max_speed\n",
      " |      0    bird      389.0\n",
      " |      2    bird       24.0\n",
      " |      3  mammal       80.5\n",
      " |      1  mammal        NaN\n",
      " |      \n",
      " |      We may take elements using negative integers for positive indices,\n",
      " |      starting from the end of the object, just like with Python lists.\n",
      " |      \n",
      " |      >>> df.take([-1, -2])\n",
      " |           name   class  max_speed\n",
      " |      1  monkey  mammal        NaN\n",
      " |      3    lion  mammal       80.5\n",
      " |  \n",
      " |  to_clipboard(self, excel: 'bool_t' = True, sep: 'str | None' = None, **kwargs) -> 'None'\n",
      " |      Copy object to the system clipboard.\n",
      " |      \n",
      " |      Write a text representation of object to the system clipboard.\n",
      " |      This can be pasted into Excel, for example.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      excel : bool, default True\n",
      " |          Produce output in a csv format for easy pasting into excel.\n",
      " |      \n",
      " |          - True, use the provided separator for csv pasting.\n",
      " |          - False, write a string representation of the object to the clipboard.\n",
      " |      \n",
      " |      sep : str, default ``'\\t'``\n",
      " |          Field delimiter.\n",
      " |      **kwargs\n",
      " |          These parameters will be passed to DataFrame.to_csv.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.to_csv : Write a DataFrame to a comma-separated values\n",
      " |          (csv) file.\n",
      " |      read_clipboard : Read text from clipboard and pass to read_csv.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Requirements for your platform.\n",
      " |      \n",
      " |        - Linux : `xclip`, or `xsel` (with `PyQt4` modules)\n",
      " |        - Windows : none\n",
      " |        - macOS : none\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Copy the contents of a DataFrame to the clipboard.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2, 3], [4, 5, 6]], columns=['A', 'B', 'C'])\n",
      " |      \n",
      " |      >>> df.to_clipboard(sep=',')  # doctest: +SKIP\n",
      " |      ... # Wrote the following to the system clipboard:\n",
      " |      ... # ,A,B,C\n",
      " |      ... # 0,1,2,3\n",
      " |      ... # 1,4,5,6\n",
      " |      \n",
      " |      We can omit the index by passing the keyword `index` and setting\n",
      " |      it to false.\n",
      " |      \n",
      " |      >>> df.to_clipboard(sep=',', index=False)  # doctest: +SKIP\n",
      " |      ... # Wrote the following to the system clipboard:\n",
      " |      ... # A,B,C\n",
      " |      ... # 1,2,3\n",
      " |      ... # 4,5,6\n",
      " |  \n",
      " |  to_csv(self, path_or_buf: 'FilePath | WriteBuffer[bytes] | WriteBuffer[str] | None' = None, sep: 'str' = ',', na_rep: 'str' = '', float_format: 'str | None' = None, columns: 'Sequence[Hashable] | None' = None, header: 'bool_t | list[str]' = True, index: 'bool_t' = True, index_label: 'IndexLabel | None' = None, mode: 'str' = 'w', encoding: 'str | None' = None, compression: 'CompressionOptions' = 'infer', quoting: 'int | None' = None, quotechar: 'str' = '\"', line_terminator: 'str | None' = None, chunksize: 'int | None' = None, date_format: 'str | None' = None, doublequote: 'bool_t' = True, escapechar: 'str | None' = None, decimal: 'str' = '.', errors: 'str' = 'strict', storage_options: 'StorageOptions' = None) -> 'str | None'\n",
      " |      Write object to a comma-separated values (csv) file.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buf : str, path object, file-like object, or None, default None\n",
      " |          String, path object (implementing os.PathLike[str]), or file-like\n",
      " |          object implementing a write() function. If None, the result is\n",
      " |          returned as a string. If a non-binary file object is passed, it should\n",
      " |          be opened with `newline=''`, disabling universal newlines. If a binary\n",
      " |          file object is passed, `mode` might need to contain a `'b'`.\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |      \n",
      " |             Support for binary file objects was introduced.\n",
      " |      \n",
      " |      sep : str, default ','\n",
      " |          String of length 1. Field delimiter for the output file.\n",
      " |      na_rep : str, default ''\n",
      " |          Missing data representation.\n",
      " |      float_format : str, default None\n",
      " |          Format string for floating point numbers.\n",
      " |      columns : sequence, optional\n",
      " |          Columns to write.\n",
      " |      header : bool or list of str, default True\n",
      " |          Write out the column names. If a list of strings is given it is\n",
      " |          assumed to be aliases for the column names.\n",
      " |      index : bool, default True\n",
      " |          Write row names (index).\n",
      " |      index_label : str or sequence, or False, default None\n",
      " |          Column label for index column(s) if desired. If None is given, and\n",
      " |          `header` and `index` are True, then the index names are used. A\n",
      " |          sequence should be given if the object uses MultiIndex. If\n",
      " |          False do not print fields for index names. Use index_label=False\n",
      " |          for easier importing in R.\n",
      " |      mode : str\n",
      " |          Python write mode, default 'w'.\n",
      " |      encoding : str, optional\n",
      " |          A string representing the encoding to use in the output file,\n",
      " |          defaults to 'utf-8'. `encoding` is not supported if `path_or_buf`\n",
      " |          is a non-binary file object.\n",
      " |      compression : str or dict, default 'infer'\n",
      " |          For on-the-fly compression of the output data. If 'infer' and '%s'\n",
      " |          path-like, then detect compression from the following extensions: '.gz',\n",
      " |          '.bz2', '.zip', '.xz', or '.zst' (otherwise no compression). Set to\n",
      " |          ``None`` for no compression. Can also be a dict with key ``'method'`` set\n",
      " |          to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``} and other\n",
      " |          key-value pairs are forwarded to ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
      " |          ``bz2.BZ2File``, or ``zstandard.ZstdDecompressor``, respectively. As an\n",
      " |          example, the following could be passed for faster compression and to create\n",
      " |          a reproducible gzip archive:\n",
      " |          ``compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}``.\n",
      " |      \n",
      " |          .. versionchanged:: 1.0.0\n",
      " |      \n",
      " |             May now be a dict with key 'method' as compression mode\n",
      " |             and other entries as additional compression options if\n",
      " |             compression mode is 'zip'.\n",
      " |      \n",
      " |          .. versionchanged:: 1.1.0\n",
      " |      \n",
      " |             Passing compression options as keys in dict is\n",
      " |             supported for compression modes 'gzip', 'bz2', 'zstd', and 'zip'.\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |      \n",
      " |              Compression is supported for binary file objects.\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |      \n",
      " |              Previous versions forwarded dict entries for 'gzip' to\n",
      " |              `gzip.open` instead of `gzip.GzipFile` which prevented\n",
      " |              setting `mtime`.\n",
      " |      \n",
      " |      quoting : optional constant from csv module\n",
      " |          Defaults to csv.QUOTE_MINIMAL. If you have set a `float_format`\n",
      " |          then floats are converted to strings and thus csv.QUOTE_NONNUMERIC\n",
      " |          will treat them as non-numeric.\n",
      " |      quotechar : str, default '\\\"'\n",
      " |          String of length 1. Character used to quote fields.\n",
      " |      line_terminator : str, optional\n",
      " |          The newline character or character sequence to use in the output\n",
      " |          file. Defaults to `os.linesep`, which depends on the OS in which\n",
      " |          this method is called ('\\\\n' for linux, '\\\\r\\\\n' for Windows, i.e.).\n",
      " |      chunksize : int or None\n",
      " |          Rows to write at a time.\n",
      " |      date_format : str, default None\n",
      " |          Format string for datetime objects.\n",
      " |      doublequote : bool, default True\n",
      " |          Control quoting of `quotechar` inside a field.\n",
      " |      escapechar : str, default None\n",
      " |          String of length 1. Character used to escape `sep` and `quotechar`\n",
      " |          when appropriate.\n",
      " |      decimal : str, default '.'\n",
      " |          Character recognized as decimal separator. E.g. use ',' for\n",
      " |          European data.\n",
      " |      errors : str, default 'strict'\n",
      " |          Specifies how encoding and decoding errors are to be handled.\n",
      " |          See the errors argument for :func:`open` for a full list\n",
      " |          of options.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib`` as header options. For other URLs (e.g.\n",
      " |          starting with \"s3://\", and \"gcs://\") the key-value pairs are forwarded to\n",
      " |          ``fsspec``. Please see ``fsspec`` and ``urllib`` for more details.\n",
      " |      \n",
      " |          .. versionadded:: 1.2.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      None or str\n",
      " |          If path_or_buf is None, returns the resulting csv format as a\n",
      " |          string. Otherwise returns None.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_csv : Load a CSV file into a DataFrame.\n",
      " |      to_excel : Write DataFrame to an Excel file.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'name': ['Raphael', 'Donatello'],\n",
      " |      ...                    'mask': ['red', 'purple'],\n",
      " |      ...                    'weapon': ['sai', 'bo staff']})\n",
      " |      >>> df.to_csv(index=False)\n",
      " |      'name,mask,weapon\\nRaphael,red,sai\\nDonatello,purple,bo staff\\n'\n",
      " |      \n",
      " |      Create 'out.zip' containing 'out.csv'\n",
      " |      \n",
      " |      >>> compression_opts = dict(method='zip',\n",
      " |      ...                         archive_name='out.csv')  # doctest: +SKIP\n",
      " |      >>> df.to_csv('out.zip', index=False,\n",
      " |      ...           compression=compression_opts)  # doctest: +SKIP\n",
      " |      \n",
      " |      To write a csv file to a new folder or nested folder you will first\n",
      " |      need to create it using either Pathlib or os:\n",
      " |      \n",
      " |      >>> from pathlib import Path  # doctest: +SKIP\n",
      " |      >>> filepath = Path('folder/subfolder/out.csv')  # doctest: +SKIP\n",
      " |      >>> filepath.parent.mkdir(parents=True, exist_ok=True)  # doctest: +SKIP\n",
      " |      >>> df.to_csv(filepath)  # doctest: +SKIP\n",
      " |      \n",
      " |      >>> import os  # doctest: +SKIP\n",
      " |      >>> os.makedirs('folder/subfolder', exist_ok=True)  # doctest: +SKIP\n",
      " |      >>> df.to_csv('folder/subfolder/out.csv')  # doctest: +SKIP\n",
      " |  \n",
      " |  to_excel(self, excel_writer, sheet_name: 'str' = 'Sheet1', na_rep: 'str' = '', float_format: 'str | None' = None, columns=None, header=True, index=True, index_label=None, startrow=0, startcol=0, engine=None, merge_cells=True, encoding=None, inf_rep='inf', verbose=True, freeze_panes=None, storage_options: 'StorageOptions' = None) -> 'None'\n",
      " |      Write object to an Excel sheet.\n",
      " |      \n",
      " |      To write a single object to an Excel .xlsx file it is only necessary to\n",
      " |      specify a target file name. To write to multiple sheets it is necessary to\n",
      " |      create an `ExcelWriter` object with a target file name, and specify a sheet\n",
      " |      in the file to write to.\n",
      " |      \n",
      " |      Multiple sheets may be written to by specifying unique `sheet_name`.\n",
      " |      With all data written to the file it is necessary to save the changes.\n",
      " |      Note that creating an `ExcelWriter` object with a file name that already\n",
      " |      exists will result in the contents of the existing file being erased.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      excel_writer : path-like, file-like, or ExcelWriter object\n",
      " |          File path or existing ExcelWriter.\n",
      " |      sheet_name : str, default 'Sheet1'\n",
      " |          Name of sheet which will contain DataFrame.\n",
      " |      na_rep : str, default ''\n",
      " |          Missing data representation.\n",
      " |      float_format : str, optional\n",
      " |          Format string for floating point numbers. For example\n",
      " |          ``float_format=\"%.2f\"`` will format 0.1234 to 0.12.\n",
      " |      columns : sequence or list of str, optional\n",
      " |          Columns to write.\n",
      " |      header : bool or list of str, default True\n",
      " |          Write out the column names. If a list of string is given it is\n",
      " |          assumed to be aliases for the column names.\n",
      " |      index : bool, default True\n",
      " |          Write row names (index).\n",
      " |      index_label : str or sequence, optional\n",
      " |          Column label for index column(s) if desired. If not specified, and\n",
      " |          `header` and `index` are True, then the index names are used. A\n",
      " |          sequence should be given if the DataFrame uses MultiIndex.\n",
      " |      startrow : int, default 0\n",
      " |          Upper left cell row to dump data frame.\n",
      " |      startcol : int, default 0\n",
      " |          Upper left cell column to dump data frame.\n",
      " |      engine : str, optional\n",
      " |          Write engine to use, 'openpyxl' or 'xlsxwriter'. You can also set this\n",
      " |          via the options ``io.excel.xlsx.writer``, ``io.excel.xls.writer``, and\n",
      " |          ``io.excel.xlsm.writer``.\n",
      " |      \n",
      " |          .. deprecated:: 1.2.0\n",
      " |      \n",
      " |              As the `xlwt <https://pypi.org/project/xlwt/>`__ package is no longer\n",
      " |              maintained, the ``xlwt`` engine will be removed in a future version\n",
      " |              of pandas.\n",
      " |      \n",
      " |      merge_cells : bool, default True\n",
      " |          Write MultiIndex and Hierarchical Rows as merged cells.\n",
      " |      encoding : str, optional\n",
      " |          Encoding of the resulting excel file. Only necessary for xlwt,\n",
      " |          other writers support unicode natively.\n",
      " |      inf_rep : str, default 'inf'\n",
      " |          Representation for infinity (there is no native representation for\n",
      " |          infinity in Excel).\n",
      " |      verbose : bool, default True\n",
      " |          Display more information in the error logs.\n",
      " |      freeze_panes : tuple of int (length 2), optional\n",
      " |          Specifies the one-based bottommost row and rightmost column that\n",
      " |          is to be frozen.\n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib`` as header options. For other URLs (e.g.\n",
      " |          starting with \"s3://\", and \"gcs://\") the key-value pairs are forwarded to\n",
      " |          ``fsspec``. Please see ``fsspec`` and ``urllib`` for more details.\n",
      " |      \n",
      " |          .. versionadded:: 1.2.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      to_csv : Write DataFrame to a comma-separated values (csv) file.\n",
      " |      ExcelWriter : Class for writing DataFrame objects into excel sheets.\n",
      " |      read_excel : Read an Excel file into a pandas DataFrame.\n",
      " |      read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For compatibility with :meth:`~DataFrame.to_csv`,\n",
      " |      to_excel serializes lists and dicts to strings before writing.\n",
      " |      \n",
      " |      Once a workbook has been saved it is not possible to write further\n",
      " |      data without rewriting the whole workbook.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Create, write to and save a workbook:\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame([['a', 'b'], ['c', 'd']],\n",
      " |      ...                    index=['row 1', 'row 2'],\n",
      " |      ...                    columns=['col 1', 'col 2'])\n",
      " |      >>> df1.to_excel(\"output.xlsx\")  # doctest: +SKIP\n",
      " |      \n",
      " |      To specify the sheet name:\n",
      " |      \n",
      " |      >>> df1.to_excel(\"output.xlsx\",\n",
      " |      ...              sheet_name='Sheet_name_1')  # doctest: +SKIP\n",
      " |      \n",
      " |      If you wish to write to more than one sheet in the workbook, it is\n",
      " |      necessary to specify an ExcelWriter object:\n",
      " |      \n",
      " |      >>> df2 = df1.copy()\n",
      " |      >>> with pd.ExcelWriter('output.xlsx') as writer:  # doctest: +SKIP\n",
      " |      ...     df1.to_excel(writer, sheet_name='Sheet_name_1')\n",
      " |      ...     df2.to_excel(writer, sheet_name='Sheet_name_2')\n",
      " |      \n",
      " |      ExcelWriter can also be used to append to an existing Excel file:\n",
      " |      \n",
      " |      >>> with pd.ExcelWriter('output.xlsx',\n",
      " |      ...                     mode='a') as writer:  # doctest: +SKIP\n",
      " |      ...     df.to_excel(writer, sheet_name='Sheet_name_3')\n",
      " |      \n",
      " |      To set the library that is used to write the Excel file,\n",
      " |      you can pass the `engine` keyword (the default engine is\n",
      " |      automatically chosen depending on the file extension):\n",
      " |      \n",
      " |      >>> df1.to_excel('output1.xlsx', engine='xlsxwriter')  # doctest: +SKIP\n",
      " |  \n",
      " |  to_hdf(self, path_or_buf, key: 'str', mode: 'str' = 'a', complevel: 'int | None' = None, complib: 'str | None' = None, append: 'bool_t' = False, format: 'str | None' = None, index: 'bool_t' = True, min_itemsize: 'int | dict[str, int] | None' = None, nan_rep=None, dropna: 'bool_t | None' = None, data_columns: 'Literal[True] | list[str] | None' = None, errors: 'str' = 'strict', encoding: 'str' = 'UTF-8') -> 'None'\n",
      " |      Write the contained data to an HDF5 file using HDFStore.\n",
      " |      \n",
      " |      Hierarchical Data Format (HDF) is self-describing, allowing an\n",
      " |      application to interpret the structure and contents of a file with\n",
      " |      no outside information. One HDF file can hold a mix of related objects\n",
      " |      which can be accessed as a group or as individual objects.\n",
      " |      \n",
      " |      In order to add another DataFrame or Series to an existing HDF file\n",
      " |      please use append mode and a different a key.\n",
      " |      \n",
      " |      .. warning::\n",
      " |      \n",
      " |         One can store a subclass of ``DataFrame`` or ``Series`` to HDF5,\n",
      " |         but the type of the subclass is lost upon storing.\n",
      " |      \n",
      " |      For more information see the :ref:`user guide <io.hdf5>`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buf : str or pandas.HDFStore\n",
      " |          File path or HDFStore object.\n",
      " |      key : str\n",
      " |          Identifier for the group in the store.\n",
      " |      mode : {'a', 'w', 'r+'}, default 'a'\n",
      " |          Mode to open file:\n",
      " |      \n",
      " |          - 'w': write, a new file is created (an existing file with\n",
      " |            the same name would be deleted).\n",
      " |          - 'a': append, an existing file is opened for reading and\n",
      " |            writing, and if the file does not exist it is created.\n",
      " |          - 'r+': similar to 'a', but the file must already exist.\n",
      " |      complevel : {0-9}, default None\n",
      " |          Specifies a compression level for data.\n",
      " |          A value of 0 or None disables compression.\n",
      " |      complib : {'zlib', 'lzo', 'bzip2', 'blosc'}, default 'zlib'\n",
      " |          Specifies the compression library to be used.\n",
      " |          As of v0.20.2 these additional compressors for Blosc are supported\n",
      " |          (default if no compressor specified: 'blosc:blosclz'):\n",
      " |          {'blosc:blosclz', 'blosc:lz4', 'blosc:lz4hc', 'blosc:snappy',\n",
      " |          'blosc:zlib', 'blosc:zstd'}.\n",
      " |          Specifying a compression library which is not available issues\n",
      " |          a ValueError.\n",
      " |      append : bool, default False\n",
      " |          For Table formats, append the input data to the existing.\n",
      " |      format : {'fixed', 'table', None}, default 'fixed'\n",
      " |          Possible values:\n",
      " |      \n",
      " |          - 'fixed': Fixed format. Fast writing/reading. Not-appendable,\n",
      " |            nor searchable.\n",
      " |          - 'table': Table format. Write as a PyTables Table structure\n",
      " |            which may perform worse but allow more flexible operations\n",
      " |            like searching / selecting subsets of the data.\n",
      " |          - If None, pd.get_option('io.hdf.default_format') is checked,\n",
      " |            followed by fallback to \"fixed\".\n",
      " |      errors : str, default 'strict'\n",
      " |          Specifies how encoding and decoding errors are to be handled.\n",
      " |          See the errors argument for :func:`open` for a full list\n",
      " |          of options.\n",
      " |      encoding : str, default \"UTF-8\"\n",
      " |      min_itemsize : dict or int, optional\n",
      " |          Map column names to minimum string sizes for columns.\n",
      " |      nan_rep : Any, optional\n",
      " |          How to represent null values as str.\n",
      " |          Not allowed with append=True.\n",
      " |      data_columns : list of columns or True, optional\n",
      " |          List of columns to create as indexed data columns for on-disk\n",
      " |          queries, or True to use all columns. By default only the axes\n",
      " |          of the object are indexed. See :ref:`io.hdf5-query-data-columns`.\n",
      " |          Applicable only to format='table'.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_hdf : Read from HDF file.\n",
      " |      DataFrame.to_parquet : Write a DataFrame to the binary parquet format.\n",
      " |      DataFrame.to_sql : Write to a SQL table.\n",
      " |      DataFrame.to_feather : Write out feather-format for DataFrames.\n",
      " |      DataFrame.to_csv : Write out to a csv file.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]},\n",
      " |      ...                   index=['a', 'b', 'c'])  # doctest: +SKIP\n",
      " |      >>> df.to_hdf('data.h5', key='df', mode='w')  # doctest: +SKIP\n",
      " |      \n",
      " |      We can add another object to the same file:\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3, 4])  # doctest: +SKIP\n",
      " |      >>> s.to_hdf('data.h5', key='s')  # doctest: +SKIP\n",
      " |      \n",
      " |      Reading from HDF file:\n",
      " |      \n",
      " |      >>> pd.read_hdf('data.h5', 'df')  # doctest: +SKIP\n",
      " |      A  B\n",
      " |      a  1  4\n",
      " |      b  2  5\n",
      " |      c  3  6\n",
      " |      >>> pd.read_hdf('data.h5', 's')  # doctest: +SKIP\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  to_json(self, path_or_buf: 'FilePath | WriteBuffer[bytes] | WriteBuffer[str] | None' = None, orient: 'str | None' = None, date_format: 'str | None' = None, double_precision: 'int' = 10, force_ascii: 'bool_t' = True, date_unit: 'str' = 'ms', default_handler: 'Callable[[Any], JSONSerializable] | None' = None, lines: 'bool_t' = False, compression: 'CompressionOptions' = 'infer', index: 'bool_t' = True, indent: 'int | None' = None, storage_options: 'StorageOptions' = None) -> 'str | None'\n",
      " |      Convert the object to a JSON string.\n",
      " |      \n",
      " |      Note NaN's and None will be converted to null and datetime objects\n",
      " |      will be converted to UNIX timestamps.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buf : str, path object, file-like object, or None, default None\n",
      " |          String, path object (implementing os.PathLike[str]), or file-like\n",
      " |          object implementing a write() function. If None, the result is\n",
      " |          returned as a string.\n",
      " |      orient : str\n",
      " |          Indication of expected JSON string format.\n",
      " |      \n",
      " |          * Series:\n",
      " |      \n",
      " |              - default is 'index'\n",
      " |              - allowed values are: {'split', 'records', 'index', 'table'}.\n",
      " |      \n",
      " |          * DataFrame:\n",
      " |      \n",
      " |              - default is 'columns'\n",
      " |              - allowed values are: {'split', 'records', 'index', 'columns',\n",
      " |                'values', 'table'}.\n",
      " |      \n",
      " |          * The format of the JSON string:\n",
      " |      \n",
      " |              - 'split' : dict like {'index' -> [index], 'columns' -> [columns],\n",
      " |                'data' -> [values]}\n",
      " |              - 'records' : list like [{column -> value}, ... , {column -> value}]\n",
      " |              - 'index' : dict like {index -> {column -> value}}\n",
      " |              - 'columns' : dict like {column -> {index -> value}}\n",
      " |              - 'values' : just the values array\n",
      " |              - 'table' : dict like {'schema': {schema}, 'data': {data}}\n",
      " |      \n",
      " |              Describing the data, where data component is like ``orient='records'``.\n",
      " |      \n",
      " |      date_format : {None, 'epoch', 'iso'}\n",
      " |          Type of date conversion. 'epoch' = epoch milliseconds,\n",
      " |          'iso' = ISO8601. The default depends on the `orient`. For\n",
      " |          ``orient='table'``, the default is 'iso'. For all other orients,\n",
      " |          the default is 'epoch'.\n",
      " |      double_precision : int, default 10\n",
      " |          The number of decimal places to use when encoding\n",
      " |          floating point values.\n",
      " |      force_ascii : bool, default True\n",
      " |          Force encoded string to be ASCII.\n",
      " |      date_unit : str, default 'ms' (milliseconds)\n",
      " |          The time unit to encode to, governs timestamp and ISO8601\n",
      " |          precision.  One of 's', 'ms', 'us', 'ns' for second, millisecond,\n",
      " |          microsecond, and nanosecond respectively.\n",
      " |      default_handler : callable, default None\n",
      " |          Handler to call if object cannot otherwise be converted to a\n",
      " |          suitable format for JSON. Should receive a single argument which is\n",
      " |          the object to convert and return a serialisable object.\n",
      " |      lines : bool, default False\n",
      " |          If 'orient' is 'records' write out line-delimited json format. Will\n",
      " |          throw ValueError if incorrect 'orient' since others are not\n",
      " |          list-like.\n",
      " |      compression : str or dict, default 'infer'\n",
      " |          For on-the-fly compression of the output data. If 'infer' and 'path_or_buf'\n",
      " |          path-like, then detect compression from the following extensions: '.gz',\n",
      " |          '.bz2', '.zip', '.xz', or '.zst' (otherwise no compression). Set to\n",
      " |          ``None`` for no compression. Can also be a dict with key ``'method'`` set\n",
      " |          to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``} and other\n",
      " |          key-value pairs are forwarded to ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
      " |          ``bz2.BZ2File``, or ``zstandard.ZstdDecompressor``, respectively. As an\n",
      " |          example, the following could be passed for faster compression and to create\n",
      " |          a reproducible gzip archive:\n",
      " |          ``compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}``.\n",
      " |      \n",
      " |          .. versionchanged:: 1.4.0 Zstandard support.\n",
      " |      \n",
      " |      index : bool, default True\n",
      " |          Whether to include the index values in the JSON string. Not\n",
      " |          including the index (``index=False``) is only supported when\n",
      " |          orient is 'split' or 'table'.\n",
      " |      indent : int, optional\n",
      " |         Length of whitespace used to indent each record.\n",
      " |      \n",
      " |         .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib`` as header options. For other URLs (e.g.\n",
      " |          starting with \"s3://\", and \"gcs://\") the key-value pairs are forwarded to\n",
      " |          ``fsspec``. Please see ``fsspec`` and ``urllib`` for more details.\n",
      " |      \n",
      " |          .. versionadded:: 1.2.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      None or str\n",
      " |          If path_or_buf is None, returns the resulting json format as a\n",
      " |          string. Otherwise returns None.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_json : Convert a JSON string to pandas object.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The behavior of ``indent=0`` varies from the stdlib, which does not\n",
      " |      indent the output but does insert newlines. Currently, ``indent=0``\n",
      " |      and the default ``indent=None`` are equivalent in pandas, though this\n",
      " |      may change in a future release.\n",
      " |      \n",
      " |      ``orient='table'`` contains a 'pandas_version' field under 'schema'.\n",
      " |      This stores the version of `pandas` used in the latest revision of the\n",
      " |      schema.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import json\n",
      " |      >>> df = pd.DataFrame(\n",
      " |      ...     [[\"a\", \"b\"], [\"c\", \"d\"]],\n",
      " |      ...     index=[\"row 1\", \"row 2\"],\n",
      " |      ...     columns=[\"col 1\", \"col 2\"],\n",
      " |      ... )\n",
      " |      \n",
      " |      >>> result = df.to_json(orient=\"split\")\n",
      " |      >>> parsed = json.loads(result)\n",
      " |      >>> json.dumps(parsed, indent=4)  # doctest: +SKIP\n",
      " |      {\n",
      " |          \"columns\": [\n",
      " |              \"col 1\",\n",
      " |              \"col 2\"\n",
      " |          ],\n",
      " |          \"index\": [\n",
      " |              \"row 1\",\n",
      " |              \"row 2\"\n",
      " |          ],\n",
      " |          \"data\": [\n",
      " |              [\n",
      " |                  \"a\",\n",
      " |                  \"b\"\n",
      " |              ],\n",
      " |              [\n",
      " |                  \"c\",\n",
      " |                  \"d\"\n",
      " |              ]\n",
      " |          ]\n",
      " |      }\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'records'`` formatted JSON.\n",
      " |      Note that index labels are not preserved with this encoding.\n",
      " |      \n",
      " |      >>> result = df.to_json(orient=\"records\")\n",
      " |      >>> parsed = json.loads(result)\n",
      " |      >>> json.dumps(parsed, indent=4)  # doctest: +SKIP\n",
      " |      [\n",
      " |          {\n",
      " |              \"col 1\": \"a\",\n",
      " |              \"col 2\": \"b\"\n",
      " |          },\n",
      " |          {\n",
      " |              \"col 1\": \"c\",\n",
      " |              \"col 2\": \"d\"\n",
      " |          }\n",
      " |      ]\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'index'`` formatted JSON:\n",
      " |      \n",
      " |      >>> result = df.to_json(orient=\"index\")\n",
      " |      >>> parsed = json.loads(result)\n",
      " |      >>> json.dumps(parsed, indent=4)  # doctest: +SKIP\n",
      " |      {\n",
      " |          \"row 1\": {\n",
      " |              \"col 1\": \"a\",\n",
      " |              \"col 2\": \"b\"\n",
      " |          },\n",
      " |          \"row 2\": {\n",
      " |              \"col 1\": \"c\",\n",
      " |              \"col 2\": \"d\"\n",
      " |          }\n",
      " |      }\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'columns'`` formatted JSON:\n",
      " |      \n",
      " |      >>> result = df.to_json(orient=\"columns\")\n",
      " |      >>> parsed = json.loads(result)\n",
      " |      >>> json.dumps(parsed, indent=4)  # doctest: +SKIP\n",
      " |      {\n",
      " |          \"col 1\": {\n",
      " |              \"row 1\": \"a\",\n",
      " |              \"row 2\": \"c\"\n",
      " |          },\n",
      " |          \"col 2\": {\n",
      " |              \"row 1\": \"b\",\n",
      " |              \"row 2\": \"d\"\n",
      " |          }\n",
      " |      }\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'values'`` formatted JSON:\n",
      " |      \n",
      " |      >>> result = df.to_json(orient=\"values\")\n",
      " |      >>> parsed = json.loads(result)\n",
      " |      >>> json.dumps(parsed, indent=4)  # doctest: +SKIP\n",
      " |      [\n",
      " |          [\n",
      " |              \"a\",\n",
      " |              \"b\"\n",
      " |          ],\n",
      " |          [\n",
      " |              \"c\",\n",
      " |              \"d\"\n",
      " |          ]\n",
      " |      ]\n",
      " |      \n",
      " |      Encoding with Table Schema:\n",
      " |      \n",
      " |      >>> result = df.to_json(orient=\"table\")\n",
      " |      >>> parsed = json.loads(result)\n",
      " |      >>> json.dumps(parsed, indent=4)  # doctest: +SKIP\n",
      " |      {\n",
      " |          \"schema\": {\n",
      " |              \"fields\": [\n",
      " |                  {\n",
      " |                      \"name\": \"index\",\n",
      " |                      \"type\": \"string\"\n",
      " |                  },\n",
      " |                  {\n",
      " |                      \"name\": \"col 1\",\n",
      " |                      \"type\": \"string\"\n",
      " |                  },\n",
      " |                  {\n",
      " |                      \"name\": \"col 2\",\n",
      " |                      \"type\": \"string\"\n",
      " |                  }\n",
      " |              ],\n",
      " |              \"primaryKey\": [\n",
      " |                  \"index\"\n",
      " |              ],\n",
      " |              \"pandas_version\": \"1.4.0\"\n",
      " |          },\n",
      " |          \"data\": [\n",
      " |              {\n",
      " |                  \"index\": \"row 1\",\n",
      " |                  \"col 1\": \"a\",\n",
      " |                  \"col 2\": \"b\"\n",
      " |              },\n",
      " |              {\n",
      " |                  \"index\": \"row 2\",\n",
      " |                  \"col 1\": \"c\",\n",
      " |                  \"col 2\": \"d\"\n",
      " |              }\n",
      " |          ]\n",
      " |      }\n",
      " |  \n",
      " |  to_latex(self, buf=None, columns=None, col_space=None, header=True, index=True, na_rep='NaN', formatters=None, float_format=None, sparsify=None, index_names=True, bold_rows=False, column_format=None, longtable=None, escape=None, encoding=None, decimal='.', multicolumn=None, multicolumn_format=None, multirow=None, caption=None, label=None, position=None)\n",
      " |      Render object to a LaTeX tabular, longtable, or nested table.\n",
      " |      \n",
      " |      Requires ``\\usepackage{booktabs}``.  The output can be copy/pasted\n",
      " |      into a main LaTeX document or read from an external file\n",
      " |      with ``\\input{table.tex}``.\n",
      " |      \n",
      " |      .. versionchanged:: 1.0.0\n",
      " |         Added caption and label arguments.\n",
      " |      \n",
      " |      .. versionchanged:: 1.2.0\n",
      " |         Added position argument, changed meaning of caption argument.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      buf : str, Path or StringIO-like, optional, default None\n",
      " |          Buffer to write to. If None, the output is returned as a string.\n",
      " |      columns : list of label, optional\n",
      " |          The subset of columns to write. Writes all columns by default.\n",
      " |      col_space : int, optional\n",
      " |          The minimum width of each column.\n",
      " |      header : bool or list of str, default True\n",
      " |          Write out the column names. If a list of strings is given,\n",
      " |          it is assumed to be aliases for the column names.\n",
      " |      index : bool, default True\n",
      " |          Write row names (index).\n",
      " |      na_rep : str, default 'NaN'\n",
      " |          Missing data representation.\n",
      " |      formatters : list of functions or dict of {str: function}, optional\n",
      " |          Formatter functions to apply to columns' elements by position or\n",
      " |          name. The result of each function must be a unicode string.\n",
      " |          List must be of length equal to the number of columns.\n",
      " |      float_format : one-parameter function or str, optional, default None\n",
      " |          Formatter for floating point numbers. For example\n",
      " |          ``float_format=\"%.2f\"`` and ``float_format=\"{:0.2f}\".format`` will\n",
      " |          both result in 0.1234 being formatted as 0.12.\n",
      " |      sparsify : bool, optional\n",
      " |          Set to False for a DataFrame with a hierarchical index to print\n",
      " |          every multiindex key at each row. By default, the value will be\n",
      " |          read from the config module.\n",
      " |      index_names : bool, default True\n",
      " |          Prints the names of the indexes.\n",
      " |      bold_rows : bool, default False\n",
      " |          Make the row labels bold in the output.\n",
      " |      column_format : str, optional\n",
      " |          The columns format as specified in `LaTeX table format\n",
      " |          <https://en.wikibooks.org/wiki/LaTeX/Tables>`__ e.g. 'rcl' for 3\n",
      " |          columns. By default, 'l' will be used for all columns except\n",
      " |          columns of numbers, which default to 'r'.\n",
      " |      longtable : bool, optional\n",
      " |          By default, the value will be read from the pandas config\n",
      " |          module. Use a longtable environment instead of tabular. Requires\n",
      " |          adding a \\usepackage{longtable} to your LaTeX preamble.\n",
      " |      escape : bool, optional\n",
      " |          By default, the value will be read from the pandas config\n",
      " |          module. When set to False prevents from escaping latex special\n",
      " |          characters in column names.\n",
      " |      encoding : str, optional\n",
      " |          A string representing the encoding to use in the output file,\n",
      " |          defaults to 'utf-8'.\n",
      " |      decimal : str, default '.'\n",
      " |          Character recognized as decimal separator, e.g. ',' in Europe.\n",
      " |      multicolumn : bool, default True\n",
      " |          Use \\multicolumn to enhance MultiIndex columns.\n",
      " |          The default will be read from the config module.\n",
      " |      multicolumn_format : str, default 'l'\n",
      " |          The alignment for multicolumns, similar to `column_format`\n",
      " |          The default will be read from the config module.\n",
      " |      multirow : bool, default False\n",
      " |          Use \\multirow to enhance MultiIndex rows. Requires adding a\n",
      " |          \\usepackage{multirow} to your LaTeX preamble. Will print\n",
      " |          centered labels (instead of top-aligned) across the contained\n",
      " |          rows, separating groups via clines. The default will be read\n",
      " |          from the pandas config module.\n",
      " |      caption : str or tuple, optional\n",
      " |          Tuple (full_caption, short_caption),\n",
      " |          which results in ``\\caption[short_caption]{full_caption}``;\n",
      " |          if a single string is passed, no short caption will be set.\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |             Optionally allow caption to be a tuple ``(full_caption, short_caption)``.\n",
      " |      \n",
      " |      label : str, optional\n",
      " |          The LaTeX label to be placed inside ``\\label{}`` in the output.\n",
      " |          This is used with ``\\ref{}`` in the main ``.tex`` file.\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |      position : str, optional\n",
      " |          The LaTeX positional argument for tables, to be placed after\n",
      " |          ``\\begin{}`` in the output.\n",
      " |      \n",
      " |          .. versionadded:: 1.2.0\n",
      " |      \n",
      " |              Returns\n",
      " |              -------\n",
      " |              str or None\n",
      " |                  If buf is None, returns the result as a string. Otherwise returns\n",
      " |                  None.\n",
      " |          \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Styler.to_latex : Render a DataFrame to LaTeX with conditional formatting.\n",
      " |      DataFrame.to_string : Render a DataFrame to a console-friendly\n",
      " |          tabular output.\n",
      " |      DataFrame.to_html : Render a DataFrame as an HTML table.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(dict(name=['Raphael', 'Donatello'],\n",
      " |      ...                   mask=['red', 'purple'],\n",
      " |      ...                   weapon=['sai', 'bo staff']))\n",
      " |      >>> print(df.to_latex(index=False))  # doctest: +SKIP\n",
      " |      \\begin{tabular}{lll}\n",
      " |       \\toprule\n",
      " |             name &    mask &    weapon \\\\\n",
      " |       \\midrule\n",
      " |          Raphael &     red &       sai \\\\\n",
      " |        Donatello &  purple &  bo staff \\\\\n",
      " |      \\bottomrule\n",
      " |      \\end{tabular}\n",
      " |  \n",
      " |  to_pickle(self, path, compression: 'CompressionOptions' = 'infer', protocol: 'int' = 5, storage_options: 'StorageOptions' = None) -> 'None'\n",
      " |      Pickle (serialize) object to file.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : str\n",
      " |          File path where the pickled object will be stored.\n",
      " |      compression : str or dict, default 'infer'\n",
      " |          For on-the-fly compression of the output data. If 'infer' and 'path'\n",
      " |          path-like, then detect compression from the following extensions: '.gz',\n",
      " |          '.bz2', '.zip', '.xz', or '.zst' (otherwise no compression). Set to\n",
      " |          ``None`` for no compression. Can also be a dict with key ``'method'`` set\n",
      " |          to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``} and other\n",
      " |          key-value pairs are forwarded to ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
      " |          ``bz2.BZ2File``, or ``zstandard.ZstdDecompressor``, respectively. As an\n",
      " |          example, the following could be passed for faster compression and to create\n",
      " |          a reproducible gzip archive:\n",
      " |          ``compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}``.\n",
      " |      protocol : int\n",
      " |          Int which indicates which protocol should be used by the pickler,\n",
      " |          default HIGHEST_PROTOCOL (see [1]_ paragraph 12.1.2). The possible\n",
      " |          values are 0, 1, 2, 3, 4, 5. A negative value for the protocol\n",
      " |          parameter is equivalent to setting its value to HIGHEST_PROTOCOL.\n",
      " |      \n",
      " |          .. [1] https://docs.python.org/3/library/pickle.html.\n",
      " |      \n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib`` as header options. For other URLs (e.g.\n",
      " |          starting with \"s3://\", and \"gcs://\") the key-value pairs are forwarded to\n",
      " |          ``fsspec``. Please see ``fsspec`` and ``urllib`` for more details.\n",
      " |      \n",
      " |          .. versionadded:: 1.2.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_pickle : Load pickled pandas object (or any object) from file.\n",
      " |      DataFrame.to_hdf : Write DataFrame to an HDF5 file.\n",
      " |      DataFrame.to_sql : Write DataFrame to a SQL database.\n",
      " |      DataFrame.to_parquet : Write a DataFrame to the binary parquet format.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> original_df = pd.DataFrame({\"foo\": range(5), \"bar\": range(5, 10)})  # doctest: +SKIP\n",
      " |      >>> original_df  # doctest: +SKIP\n",
      " |         foo  bar\n",
      " |      0    0    5\n",
      " |      1    1    6\n",
      " |      2    2    7\n",
      " |      3    3    8\n",
      " |      4    4    9\n",
      " |      >>> original_df.to_pickle(\"./dummy.pkl\")  # doctest: +SKIP\n",
      " |      \n",
      " |      >>> unpickled_df = pd.read_pickle(\"./dummy.pkl\")  # doctest: +SKIP\n",
      " |      >>> unpickled_df  # doctest: +SKIP\n",
      " |         foo  bar\n",
      " |      0    0    5\n",
      " |      1    1    6\n",
      " |      2    2    7\n",
      " |      3    3    8\n",
      " |      4    4    9\n",
      " |  \n",
      " |  to_sql(self, name: 'str', con, schema=None, if_exists: 'str' = 'fail', index: 'bool_t' = True, index_label=None, chunksize=None, dtype: 'DtypeArg | None' = None, method=None) -> 'int | None'\n",
      " |      Write records stored in a DataFrame to a SQL database.\n",
      " |      \n",
      " |      Databases supported by SQLAlchemy [1]_ are supported. Tables can be\n",
      " |      newly created, appended to, or overwritten.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : str\n",
      " |          Name of SQL table.\n",
      " |      con : sqlalchemy.engine.(Engine or Connection) or sqlite3.Connection\n",
      " |          Using SQLAlchemy makes it possible to use any DB supported by that\n",
      " |          library. Legacy support is provided for sqlite3.Connection objects. The user\n",
      " |          is responsible for engine disposal and connection closure for the SQLAlchemy\n",
      " |          connectable See `here                 <https://docs.sqlalchemy.org/en/13/core/connections.html>`_.\n",
      " |      \n",
      " |      schema : str, optional\n",
      " |          Specify the schema (if database flavor supports this). If None, use\n",
      " |          default schema.\n",
      " |      if_exists : {'fail', 'replace', 'append'}, default 'fail'\n",
      " |          How to behave if the table already exists.\n",
      " |      \n",
      " |          * fail: Raise a ValueError.\n",
      " |          * replace: Drop the table before inserting new values.\n",
      " |          * append: Insert new values to the existing table.\n",
      " |      \n",
      " |      index : bool, default True\n",
      " |          Write DataFrame index as a column. Uses `index_label` as the column\n",
      " |          name in the table.\n",
      " |      index_label : str or sequence, default None\n",
      " |          Column label for index column(s). If None is given (default) and\n",
      " |          `index` is True, then the index names are used.\n",
      " |          A sequence should be given if the DataFrame uses MultiIndex.\n",
      " |      chunksize : int, optional\n",
      " |          Specify the number of rows in each batch to be written at a time.\n",
      " |          By default, all rows will be written at once.\n",
      " |      dtype : dict or scalar, optional\n",
      " |          Specifying the datatype for columns. If a dictionary is used, the\n",
      " |          keys should be the column names and the values should be the\n",
      " |          SQLAlchemy types or strings for the sqlite3 legacy mode. If a\n",
      " |          scalar is provided, it will be applied to all columns.\n",
      " |      method : {None, 'multi', callable}, optional\n",
      " |          Controls the SQL insertion clause used:\n",
      " |      \n",
      " |          * None : Uses standard SQL ``INSERT`` clause (one per row).\n",
      " |          * 'multi': Pass multiple values in a single ``INSERT`` clause.\n",
      " |          * callable with signature ``(pd_table, conn, keys, data_iter)``.\n",
      " |      \n",
      " |          Details and a sample callable implementation can be found in the\n",
      " |          section :ref:`insert method <io.sql.method>`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      None or int\n",
      " |          Number of rows affected by to_sql. None is returned if the callable\n",
      " |          passed into ``method`` does not return the number of rows.\n",
      " |      \n",
      " |          The number of returned rows affected is the sum of the ``rowcount``\n",
      " |          attribute of ``sqlite3.Cursor`` or SQLAlchemy connectable which may not\n",
      " |          reflect the exact number of written rows as stipulated in the\n",
      " |          `sqlite3 <https://docs.python.org/3/library/sqlite3.html#sqlite3.Cursor.rowcount>`__ or\n",
      " |          `SQLAlchemy <https://docs.sqlalchemy.org/en/14/core/connections.html#sqlalchemy.engine.BaseCursorResult.rowcount>`__.\n",
      " |      \n",
      " |          .. versionadded:: 1.4.0\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          When the table already exists and `if_exists` is 'fail' (the\n",
      " |          default).\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_sql : Read a DataFrame from a table.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Timezone aware datetime columns will be written as\n",
      " |      ``Timestamp with timezone`` type with SQLAlchemy if supported by the\n",
      " |      database. Otherwise, the datetimes will be stored as timezone unaware\n",
      " |      timestamps local to the original timezone.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] https://docs.sqlalchemy.org\n",
      " |      .. [2] https://www.python.org/dev/peps/pep-0249/\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Create an in-memory SQLite database.\n",
      " |      \n",
      " |      >>> from sqlalchemy import create_engine\n",
      " |      >>> engine = create_engine('sqlite://', echo=False)\n",
      " |      \n",
      " |      Create a table from scratch with 3 rows.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'name' : ['User 1', 'User 2', 'User 3']})\n",
      " |      >>> df\n",
      " |           name\n",
      " |      0  User 1\n",
      " |      1  User 2\n",
      " |      2  User 3\n",
      " |      \n",
      " |      >>> df.to_sql('users', con=engine)\n",
      " |      3\n",
      " |      >>> engine.execute(\"SELECT * FROM users\").fetchall()\n",
      " |      [(0, 'User 1'), (1, 'User 2'), (2, 'User 3')]\n",
      " |      \n",
      " |      An `sqlalchemy.engine.Connection` can also be passed to `con`:\n",
      " |      \n",
      " |      >>> with engine.begin() as connection:\n",
      " |      ...     df1 = pd.DataFrame({'name' : ['User 4', 'User 5']})\n",
      " |      ...     df1.to_sql('users', con=connection, if_exists='append')\n",
      " |      2\n",
      " |      \n",
      " |      This is allowed to support operations that require that the same\n",
      " |      DBAPI connection is used for the entire operation.\n",
      " |      \n",
      " |      >>> df2 = pd.DataFrame({'name' : ['User 6', 'User 7']})\n",
      " |      >>> df2.to_sql('users', con=engine, if_exists='append')\n",
      " |      2\n",
      " |      >>> engine.execute(\"SELECT * FROM users\").fetchall()\n",
      " |      [(0, 'User 1'), (1, 'User 2'), (2, 'User 3'),\n",
      " |       (0, 'User 4'), (1, 'User 5'), (0, 'User 6'),\n",
      " |       (1, 'User 7')]\n",
      " |      \n",
      " |      Overwrite the table with just ``df2``.\n",
      " |      \n",
      " |      >>> df2.to_sql('users', con=engine, if_exists='replace',\n",
      " |      ...            index_label='id')\n",
      " |      2\n",
      " |      >>> engine.execute(\"SELECT * FROM users\").fetchall()\n",
      " |      [(0, 'User 6'), (1, 'User 7')]\n",
      " |      \n",
      " |      Specify the dtype (especially useful for integers with missing values).\n",
      " |      Notice that while pandas is forced to store the data as floating point,\n",
      " |      the database supports nullable integers. When fetching the data with\n",
      " |      Python, we get back integer scalars.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, None, 2]})\n",
      " |      >>> df\n",
      " |           A\n",
      " |      0  1.0\n",
      " |      1  NaN\n",
      " |      2  2.0\n",
      " |      \n",
      " |      >>> from sqlalchemy.types import Integer\n",
      " |      >>> df.to_sql('integers', con=engine, index=False,\n",
      " |      ...           dtype={\"A\": Integer()})\n",
      " |      3\n",
      " |      \n",
      " |      >>> engine.execute(\"SELECT * FROM integers\").fetchall()\n",
      " |      [(1,), (None,), (2,)]\n",
      " |  \n",
      " |  to_xarray(self)\n",
      " |      Return an xarray object from the pandas object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      xarray.DataArray or xarray.Dataset\n",
      " |          Data in the pandas structure converted to Dataset if the object is\n",
      " |          a DataFrame, or a DataArray if the object is a Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.to_hdf : Write DataFrame to an HDF5 file.\n",
      " |      DataFrame.to_parquet : Write a DataFrame to the binary parquet format.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See the `xarray docs <https://xarray.pydata.org/en/stable/>`__\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('falcon', 'bird', 389.0, 2),\n",
      " |      ...                    ('parrot', 'bird', 24.0, 2),\n",
      " |      ...                    ('lion', 'mammal', 80.5, 4),\n",
      " |      ...                    ('monkey', 'mammal', np.nan, 4)],\n",
      " |      ...                   columns=['name', 'class', 'max_speed',\n",
      " |      ...                            'num_legs'])\n",
      " |      >>> df\n",
      " |           name   class  max_speed  num_legs\n",
      " |      0  falcon    bird      389.0         2\n",
      " |      1  parrot    bird       24.0         2\n",
      " |      2    lion  mammal       80.5         4\n",
      " |      3  monkey  mammal        NaN         4\n",
      " |      \n",
      " |      >>> df.to_xarray()\n",
      " |      <xarray.Dataset>\n",
      " |      Dimensions:    (index: 4)\n",
      " |      Coordinates:\n",
      " |        * index      (index) int64 0 1 2 3\n",
      " |      Data variables:\n",
      " |          name       (index) object 'falcon' 'parrot' 'lion' 'monkey'\n",
      " |          class      (index) object 'bird' 'bird' 'mammal' 'mammal'\n",
      " |          max_speed  (index) float64 389.0 24.0 80.5 nan\n",
      " |          num_legs   (index) int64 2 2 4 4\n",
      " |      \n",
      " |      >>> df['max_speed'].to_xarray()\n",
      " |      <xarray.DataArray 'max_speed' (index: 4)>\n",
      " |      array([389. ,  24. ,  80.5,   nan])\n",
      " |      Coordinates:\n",
      " |        * index    (index) int64 0 1 2 3\n",
      " |      \n",
      " |      >>> dates = pd.to_datetime(['2018-01-01', '2018-01-01',\n",
      " |      ...                         '2018-01-02', '2018-01-02'])\n",
      " |      >>> df_multiindex = pd.DataFrame({'date': dates,\n",
      " |      ...                               'animal': ['falcon', 'parrot',\n",
      " |      ...                                          'falcon', 'parrot'],\n",
      " |      ...                               'speed': [350, 18, 361, 15]})\n",
      " |      >>> df_multiindex = df_multiindex.set_index(['date', 'animal'])\n",
      " |      \n",
      " |      >>> df_multiindex\n",
      " |                         speed\n",
      " |      date       animal\n",
      " |      2018-01-01 falcon    350\n",
      " |                 parrot     18\n",
      " |      2018-01-02 falcon    361\n",
      " |                 parrot     15\n",
      " |      \n",
      " |      >>> df_multiindex.to_xarray()\n",
      " |      <xarray.Dataset>\n",
      " |      Dimensions:  (animal: 2, date: 2)\n",
      " |      Coordinates:\n",
      " |        * date     (date) datetime64[ns] 2018-01-01 2018-01-02\n",
      " |        * animal   (animal) object 'falcon' 'parrot'\n",
      " |      Data variables:\n",
      " |          speed    (date, animal) int64 350 18 361 15\n",
      " |  \n",
      " |  truncate(self: 'NDFrameT', before=None, after=None, axis=None, copy: 'bool_t' = True) -> 'NDFrameT'\n",
      " |      Truncate a Series or DataFrame before and after some index value.\n",
      " |      \n",
      " |      This is a useful shorthand for boolean indexing based on index\n",
      " |      values above or below certain thresholds.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      before : date, str, int\n",
      " |          Truncate all rows before this index value.\n",
      " |      after : date, str, int\n",
      " |          Truncate all rows after this index value.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, optional\n",
      " |          Axis to truncate. Truncates the index (rows) by default.\n",
      " |      copy : bool, default is True,\n",
      " |          Return a copy of the truncated section.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      type of caller\n",
      " |          The truncated Series or DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Select a subset of a DataFrame by label.\n",
      " |      DataFrame.iloc : Select a subset of a DataFrame by position.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If the index being truncated contains only datetime values,\n",
      " |      `before` and `after` may be specified as strings instead of\n",
      " |      Timestamps.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': ['a', 'b', 'c', 'd', 'e'],\n",
      " |      ...                    'B': ['f', 'g', 'h', 'i', 'j'],\n",
      " |      ...                    'C': ['k', 'l', 'm', 'n', 'o']},\n",
      " |      ...                   index=[1, 2, 3, 4, 5])\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |      1  a  f  k\n",
      " |      2  b  g  l\n",
      " |      3  c  h  m\n",
      " |      4  d  i  n\n",
      " |      5  e  j  o\n",
      " |      \n",
      " |      >>> df.truncate(before=2, after=4)\n",
      " |         A  B  C\n",
      " |      2  b  g  l\n",
      " |      3  c  h  m\n",
      " |      4  d  i  n\n",
      " |      \n",
      " |      The columns of a DataFrame can be truncated.\n",
      " |      \n",
      " |      >>> df.truncate(before=\"A\", after=\"B\", axis=\"columns\")\n",
      " |         A  B\n",
      " |      1  a  f\n",
      " |      2  b  g\n",
      " |      3  c  h\n",
      " |      4  d  i\n",
      " |      5  e  j\n",
      " |      \n",
      " |      For Series, only rows can be truncated.\n",
      " |      \n",
      " |      >>> df['A'].truncate(before=2, after=4)\n",
      " |      2    b\n",
      " |      3    c\n",
      " |      4    d\n",
      " |      Name: A, dtype: object\n",
      " |      \n",
      " |      The index values in ``truncate`` can be datetimes or string\n",
      " |      dates.\n",
      " |      \n",
      " |      >>> dates = pd.date_range('2016-01-01', '2016-02-01', freq='s')\n",
      " |      >>> df = pd.DataFrame(index=dates, data={'A': 1})\n",
      " |      >>> df.tail()\n",
      " |                           A\n",
      " |      2016-01-31 23:59:56  1\n",
      " |      2016-01-31 23:59:57  1\n",
      " |      2016-01-31 23:59:58  1\n",
      " |      2016-01-31 23:59:59  1\n",
      " |      2016-02-01 00:00:00  1\n",
      " |      \n",
      " |      >>> df.truncate(before=pd.Timestamp('2016-01-05'),\n",
      " |      ...             after=pd.Timestamp('2016-01-10')).tail()\n",
      " |                           A\n",
      " |      2016-01-09 23:59:56  1\n",
      " |      2016-01-09 23:59:57  1\n",
      " |      2016-01-09 23:59:58  1\n",
      " |      2016-01-09 23:59:59  1\n",
      " |      2016-01-10 00:00:00  1\n",
      " |      \n",
      " |      Because the index is a DatetimeIndex containing only dates, we can\n",
      " |      specify `before` and `after` as strings. They will be coerced to\n",
      " |      Timestamps before truncation.\n",
      " |      \n",
      " |      >>> df.truncate('2016-01-05', '2016-01-10').tail()\n",
      " |                           A\n",
      " |      2016-01-09 23:59:56  1\n",
      " |      2016-01-09 23:59:57  1\n",
      " |      2016-01-09 23:59:58  1\n",
      " |      2016-01-09 23:59:59  1\n",
      " |      2016-01-10 00:00:00  1\n",
      " |      \n",
      " |      Note that ``truncate`` assumes a 0 value for any unspecified time\n",
      " |      component (midnight). This differs from partial string slicing, which\n",
      " |      returns any partially matching dates.\n",
      " |      \n",
      " |      >>> df.loc['2016-01-05':'2016-01-10', :].tail()\n",
      " |                           A\n",
      " |      2016-01-10 23:59:55  1\n",
      " |      2016-01-10 23:59:56  1\n",
      " |      2016-01-10 23:59:57  1\n",
      " |      2016-01-10 23:59:58  1\n",
      " |      2016-01-10 23:59:59  1\n",
      " |  \n",
      " |  tshift(self: 'NDFrameT', periods: 'int' = 1, freq=None, axis: 'Axis' = 0) -> 'NDFrameT'\n",
      " |      Shift the time index, using the index's frequency if available.\n",
      " |      \n",
      " |      .. deprecated:: 1.1.0\n",
      " |          Use `shift` instead.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to move, can be positive or negative.\n",
      " |      freq : DateOffset, timedelta, or str, default None\n",
      " |          Increment to use from the tseries module\n",
      " |          or time rule expressed as a string (e.g. 'EOM').\n",
      " |      axis : {0 or ‘index’, 1 or ‘columns’, None}, default 0\n",
      " |          Corresponds to the axis that contains the Index.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      shifted : Series/DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If freq is not specified then tries to use the freq or inferred_freq\n",
      " |      attributes of the index. If neither of those attributes exist, a\n",
      " |      ValueError is thrown\n",
      " |  \n",
      " |  tz_convert(self: 'NDFrameT', tz, axis=0, level=None, copy: 'bool_t' = True) -> 'NDFrameT'\n",
      " |      Convert tz-aware axis to target time zone.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      tz : str or tzinfo object\n",
      " |      axis : the axis to convert\n",
      " |      level : int, str, default None\n",
      " |          If axis is a MultiIndex, convert a specific level. Otherwise\n",
      " |          must be None.\n",
      " |      copy : bool, default True\n",
      " |          Also make a copy of the underlying data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      {klass}\n",
      " |          Object with time zone converted axis.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the axis is tz-naive.\n",
      " |  \n",
      " |  tz_localize(self: 'NDFrameT', tz, axis=0, level=None, copy: 'bool_t' = True, ambiguous='raise', nonexistent: 'str' = 'raise') -> 'NDFrameT'\n",
      " |      Localize tz-naive index of a Series or DataFrame to target time zone.\n",
      " |      \n",
      " |      This operation localizes the Index. To localize the values in a\n",
      " |      timezone-naive Series, use :meth:`Series.dt.tz_localize`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      tz : str or tzinfo\n",
      " |      axis : the axis to localize\n",
      " |      level : int, str, default None\n",
      " |          If axis ia a MultiIndex, localize a specific level. Otherwise\n",
      " |          must be None.\n",
      " |      copy : bool, default True\n",
      " |          Also make a copy of the underlying data.\n",
      " |      ambiguous : 'infer', bool-ndarray, 'NaT', default 'raise'\n",
      " |          When clocks moved backward due to DST, ambiguous times may arise.\n",
      " |          For example in Central European Time (UTC+01), when going from\n",
      " |          03:00 DST to 02:00 non-DST, 02:30:00 local time occurs both at\n",
      " |          00:30:00 UTC and at 01:30:00 UTC. In such a situation, the\n",
      " |          `ambiguous` parameter dictates how ambiguous times should be\n",
      " |          handled.\n",
      " |      \n",
      " |          - 'infer' will attempt to infer fall dst-transition hours based on\n",
      " |            order\n",
      " |          - bool-ndarray where True signifies a DST time, False designates\n",
      " |            a non-DST time (note that this flag is only applicable for\n",
      " |            ambiguous times)\n",
      " |          - 'NaT' will return NaT where there are ambiguous times\n",
      " |          - 'raise' will raise an AmbiguousTimeError if there are ambiguous\n",
      " |            times.\n",
      " |      nonexistent : str, default 'raise'\n",
      " |          A nonexistent time does not exist in a particular timezone\n",
      " |          where clocks moved forward due to DST. Valid values are:\n",
      " |      \n",
      " |          - 'shift_forward' will shift the nonexistent time forward to the\n",
      " |            closest existing time\n",
      " |          - 'shift_backward' will shift the nonexistent time backward to the\n",
      " |            closest existing time\n",
      " |          - 'NaT' will return NaT where there are nonexistent times\n",
      " |          - timedelta objects will shift nonexistent times by the timedelta\n",
      " |          - 'raise' will raise an NonExistentTimeError if there are\n",
      " |            nonexistent times.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Same type as the input.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the TimeSeries is tz-aware and tz is not None.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Localize local times:\n",
      " |      \n",
      " |      >>> s = pd.Series([1],\n",
      " |      ...               index=pd.DatetimeIndex(['2018-09-15 01:30:00']))\n",
      " |      >>> s.tz_localize('CET')\n",
      " |      2018-09-15 01:30:00+02:00    1\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Be careful with DST changes. When there is sequential data, pandas\n",
      " |      can infer the DST time:\n",
      " |      \n",
      " |      >>> s = pd.Series(range(7),\n",
      " |      ...               index=pd.DatetimeIndex(['2018-10-28 01:30:00',\n",
      " |      ...                                       '2018-10-28 02:00:00',\n",
      " |      ...                                       '2018-10-28 02:30:00',\n",
      " |      ...                                       '2018-10-28 02:00:00',\n",
      " |      ...                                       '2018-10-28 02:30:00',\n",
      " |      ...                                       '2018-10-28 03:00:00',\n",
      " |      ...                                       '2018-10-28 03:30:00']))\n",
      " |      >>> s.tz_localize('CET', ambiguous='infer')\n",
      " |      2018-10-28 01:30:00+02:00    0\n",
      " |      2018-10-28 02:00:00+02:00    1\n",
      " |      2018-10-28 02:30:00+02:00    2\n",
      " |      2018-10-28 02:00:00+01:00    3\n",
      " |      2018-10-28 02:30:00+01:00    4\n",
      " |      2018-10-28 03:00:00+01:00    5\n",
      " |      2018-10-28 03:30:00+01:00    6\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      In some cases, inferring the DST is impossible. In such cases, you can\n",
      " |      pass an ndarray to the ambiguous parameter to set the DST explicitly\n",
      " |      \n",
      " |      >>> s = pd.Series(range(3),\n",
      " |      ...               index=pd.DatetimeIndex(['2018-10-28 01:20:00',\n",
      " |      ...                                       '2018-10-28 02:36:00',\n",
      " |      ...                                       '2018-10-28 03:46:00']))\n",
      " |      >>> s.tz_localize('CET', ambiguous=np.array([True, True, False]))\n",
      " |      2018-10-28 01:20:00+02:00    0\n",
      " |      2018-10-28 02:36:00+02:00    1\n",
      " |      2018-10-28 03:46:00+01:00    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      If the DST transition causes nonexistent times, you can shift these\n",
      " |      dates forward or backward with a timedelta object or `'shift_forward'`\n",
      " |      or `'shift_backward'`.\n",
      " |      \n",
      " |      >>> s = pd.Series(range(2),\n",
      " |      ...               index=pd.DatetimeIndex(['2015-03-29 02:30:00',\n",
      " |      ...                                       '2015-03-29 03:30:00']))\n",
      " |      >>> s.tz_localize('Europe/Warsaw', nonexistent='shift_forward')\n",
      " |      2015-03-29 03:00:00+02:00    0\n",
      " |      2015-03-29 03:30:00+02:00    1\n",
      " |      dtype: int64\n",
      " |      >>> s.tz_localize('Europe/Warsaw', nonexistent='shift_backward')\n",
      " |      2015-03-29 01:59:59.999999999+01:00    0\n",
      " |      2015-03-29 03:30:00+02:00              1\n",
      " |      dtype: int64\n",
      " |      >>> s.tz_localize('Europe/Warsaw', nonexistent=pd.Timedelta('1H'))\n",
      " |      2015-03-29 03:30:00+02:00    0\n",
      " |      2015-03-29 03:30:00+02:00    1\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  xs(self, key, axis=0, level=None, drop_level: 'bool_t' = True)\n",
      " |      Return cross-section from the Series/DataFrame.\n",
      " |      \n",
      " |      This method takes a `key` argument to select data at a particular\n",
      " |      level of a MultiIndex.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : label or tuple of label\n",
      " |          Label contained in the index, or partially in a MultiIndex.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Axis to retrieve cross-section on.\n",
      " |      level : object, defaults to first n levels (n=1 or len(key))\n",
      " |          In case of a key partially contained in a MultiIndex, indicate\n",
      " |          which levels are used. Levels can be referred by label or position.\n",
      " |      drop_level : bool, default True\n",
      " |          If False, returns object with same levels as self.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Cross-section from the original Series or DataFrame\n",
      " |          corresponding to the selected index levels.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Access a group of rows and columns\n",
      " |          by label(s) or a boolean array.\n",
      " |      DataFrame.iloc : Purely integer-location based indexing\n",
      " |          for selection by position.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      `xs` can not be used to set values.\n",
      " |      \n",
      " |      MultiIndex Slicers is a generic way to get/set values on\n",
      " |      any level or levels.\n",
      " |      It is a superset of `xs` functionality, see\n",
      " |      :ref:`MultiIndex Slicers <advanced.mi_slicers>`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> d = {'num_legs': [4, 4, 2, 2],\n",
      " |      ...      'num_wings': [0, 0, 2, 2],\n",
      " |      ...      'class': ['mammal', 'mammal', 'mammal', 'bird'],\n",
      " |      ...      'animal': ['cat', 'dog', 'bat', 'penguin'],\n",
      " |      ...      'locomotion': ['walks', 'walks', 'flies', 'walks']}\n",
      " |      >>> df = pd.DataFrame(data=d)\n",
      " |      >>> df = df.set_index(['class', 'animal', 'locomotion'])\n",
      " |      >>> df\n",
      " |                                 num_legs  num_wings\n",
      " |      class  animal  locomotion\n",
      " |      mammal cat     walks              4          0\n",
      " |             dog     walks              4          0\n",
      " |             bat     flies              2          2\n",
      " |      bird   penguin walks              2          2\n",
      " |      \n",
      " |      Get values at specified index\n",
      " |      \n",
      " |      >>> df.xs('mammal')\n",
      " |                         num_legs  num_wings\n",
      " |      animal locomotion\n",
      " |      cat    walks              4          0\n",
      " |      dog    walks              4          0\n",
      " |      bat    flies              2          2\n",
      " |      \n",
      " |      Get values at several indexes\n",
      " |      \n",
      " |      >>> df.xs(('mammal', 'dog'))\n",
      " |                  num_legs  num_wings\n",
      " |      locomotion\n",
      " |      walks              4          0\n",
      " |      \n",
      " |      Get values at specified index and level\n",
      " |      \n",
      " |      >>> df.xs('cat', level=1)\n",
      " |                         num_legs  num_wings\n",
      " |      class  locomotion\n",
      " |      mammal walks              4          0\n",
      " |      \n",
      " |      Get values at several indexes and levels\n",
      " |      \n",
      " |      >>> df.xs(('bird', 'walks'),\n",
      " |      ...       level=[0, 'locomotion'])\n",
      " |               num_legs  num_wings\n",
      " |      animal\n",
      " |      penguin         2          2\n",
      " |      \n",
      " |      Get values at specified column and axis\n",
      " |      \n",
      " |      >>> df.xs('num_wings', axis=1)\n",
      " |      class   animal   locomotion\n",
      " |      mammal  cat      walks         0\n",
      " |              dog      walks         0\n",
      " |              bat      flies         2\n",
      " |      bird    penguin  walks         2\n",
      " |      Name: num_wings, dtype: int64\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from pandas.core.generic.NDFrame:\n",
      " |  \n",
      " |  dtypes\n",
      " |      Return the dtypes in the DataFrame.\n",
      " |      \n",
      " |      This returns a Series with the data type of each column.\n",
      " |      The result's index is the original DataFrame's columns. Columns\n",
      " |      with mixed types are stored with the ``object`` dtype. See\n",
      " |      :ref:`the User Guide <basics.dtypes>` for more.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.Series\n",
      " |          The data type of each column.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'float': [1.0],\n",
      " |      ...                    'int': [1],\n",
      " |      ...                    'datetime': [pd.Timestamp('20180310')],\n",
      " |      ...                    'string': ['foo']})\n",
      " |      >>> df.dtypes\n",
      " |      float              float64\n",
      " |      int                  int64\n",
      " |      datetime    datetime64[ns]\n",
      " |      string              object\n",
      " |      dtype: object\n",
      " |  \n",
      " |  empty\n",
      " |      Indicator whether Series/DataFrame is empty.\n",
      " |      \n",
      " |      True if Series/DataFrame is entirely empty (no items), meaning any of the\n",
      " |      axes are of length 0.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |          If Series/DataFrame is empty, return True, if not return False.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.dropna : Return series without null values.\n",
      " |      DataFrame.dropna : Return DataFrame with labels on given axis omitted\n",
      " |          where (all or any) data are missing.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If Series/DataFrame contains only NaNs, it is still not considered empty. See\n",
      " |      the example below.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      An example of an actual empty DataFrame. Notice the index is empty:\n",
      " |      \n",
      " |      >>> df_empty = pd.DataFrame({'A' : []})\n",
      " |      >>> df_empty\n",
      " |      Empty DataFrame\n",
      " |      Columns: [A]\n",
      " |      Index: []\n",
      " |      >>> df_empty.empty\n",
      " |      True\n",
      " |      \n",
      " |      If we only have NaNs in our DataFrame, it is not considered empty! We\n",
      " |      will need to drop the NaNs to make the DataFrame empty:\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A' : [np.nan]})\n",
      " |      >>> df\n",
      " |          A\n",
      " |      0 NaN\n",
      " |      >>> df.empty\n",
      " |      False\n",
      " |      >>> df.dropna().empty\n",
      " |      True\n",
      " |      \n",
      " |      >>> ser_empty = pd.Series({'A' : []})\n",
      " |      >>> ser_empty\n",
      " |      A    []\n",
      " |      dtype: object\n",
      " |      >>> ser_empty.empty\n",
      " |      False\n",
      " |      >>> ser_empty = pd.Series()\n",
      " |      >>> ser_empty.empty\n",
      " |      True\n",
      " |  \n",
      " |  flags\n",
      " |      Get the properties associated with this pandas object.\n",
      " |      \n",
      " |      The available flags are\n",
      " |      \n",
      " |      * :attr:`Flags.allows_duplicate_labels`\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Flags : Flags that apply to pandas objects.\n",
      " |      DataFrame.attrs : Global metadata applying to this dataset.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      \"Flags\" differ from \"metadata\". Flags reflect properties of the\n",
      " |      pandas object (the Series or DataFrame). Metadata refer to properties\n",
      " |      of the dataset, and should be stored in :attr:`DataFrame.attrs`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2]})\n",
      " |      >>> df.flags\n",
      " |      <Flags(allows_duplicate_labels=True)>\n",
      " |      \n",
      " |      Flags can be get or set using ``.``\n",
      " |      \n",
      " |      >>> df.flags.allows_duplicate_labels\n",
      " |      True\n",
      " |      >>> df.flags.allows_duplicate_labels = False\n",
      " |      \n",
      " |      Or by slicing with a key\n",
      " |      \n",
      " |      >>> df.flags[\"allows_duplicate_labels\"]\n",
      " |      False\n",
      " |      >>> df.flags[\"allows_duplicate_labels\"] = True\n",
      " |  \n",
      " |  ndim\n",
      " |      Return an int representing the number of axes / array dimensions.\n",
      " |      \n",
      " |      Return 1 if Series. Otherwise return 2 if DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      ndarray.ndim : Number of array dimensions.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series({'a': 1, 'b': 2, 'c': 3})\n",
      " |      >>> s.ndim\n",
      " |      1\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n",
      " |      >>> df.ndim\n",
      " |      2\n",
      " |  \n",
      " |  size\n",
      " |      Return an int representing the number of elements in this object.\n",
      " |      \n",
      " |      Return the number of rows if Series. Otherwise return the number of\n",
      " |      rows times number of columns if DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      ndarray.size : Number of elements in the array.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series({'a': 1, 'b': 2, 'c': 3})\n",
      " |      >>> s.size\n",
      " |      3\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n",
      " |      >>> df.size\n",
      " |      4\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.generic.NDFrame:\n",
      " |  \n",
      " |  attrs\n",
      " |      Dictionary of global attributes of this dataset.\n",
      " |      \n",
      " |      .. warning::\n",
      " |      \n",
      " |         attrs is experimental and may change without warning.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.flags : Global flags applying to this object.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pandas.core.generic.NDFrame:\n",
      " |  \n",
      " |  __array_priority__ = 1000\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.PandasObject:\n",
      " |  \n",
      " |  __sizeof__(self) -> 'int'\n",
      " |      Generates the total memory usage for an object that returns\n",
      " |      either a value or Series of values\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.accessor.DirNamesMixin:\n",
      " |  \n",
      " |  __dir__(self) -> 'list[str]'\n",
      " |      Provide method name lookup and completion.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Only provide 'public' methods.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.accessor.DirNamesMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from pandas.core.indexing.IndexingMixin:\n",
      " |  \n",
      " |  at\n",
      " |      Access a single value for a row/column label pair.\n",
      " |      \n",
      " |      Similar to ``loc``, in that both provide label-based lookups. Use\n",
      " |      ``at`` if you only need to get or set a single value in a DataFrame\n",
      " |      or Series.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError\n",
      " |          If 'label' does not exist in DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.iat : Access a single value for a row/column pair by integer\n",
      " |          position.\n",
      " |      DataFrame.loc : Access a group of rows and columns by label(s).\n",
      " |      Series.at : Access a single value using a label.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],\n",
      " |      ...                   index=[4, 5, 6], columns=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |          A   B   C\n",
      " |      4   0   2   3\n",
      " |      5   0   4   1\n",
      " |      6  10  20  30\n",
      " |      \n",
      " |      Get value at specified row/column pair\n",
      " |      \n",
      " |      >>> df.at[4, 'B']\n",
      " |      2\n",
      " |      \n",
      " |      Set value at specified row/column pair\n",
      " |      \n",
      " |      >>> df.at[4, 'B'] = 10\n",
      " |      >>> df.at[4, 'B']\n",
      " |      10\n",
      " |      \n",
      " |      Get value within a Series\n",
      " |      \n",
      " |      >>> df.loc[5].at['B']\n",
      " |      4\n",
      " |  \n",
      " |  iat\n",
      " |      Access a single value for a row/column pair by integer position.\n",
      " |      \n",
      " |      Similar to ``iloc``, in that both provide integer-based lookups. Use\n",
      " |      ``iat`` if you only need to get or set a single value in a DataFrame\n",
      " |      or Series.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      IndexError\n",
      " |          When integer position is out of bounds.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.at : Access a single value for a row/column label pair.\n",
      " |      DataFrame.loc : Access a group of rows and columns by label(s).\n",
      " |      DataFrame.iloc : Access a group of rows and columns by integer position(s).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],\n",
      " |      ...                   columns=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |          A   B   C\n",
      " |      0   0   2   3\n",
      " |      1   0   4   1\n",
      " |      2  10  20  30\n",
      " |      \n",
      " |      Get value at specified row/column pair\n",
      " |      \n",
      " |      >>> df.iat[1, 2]\n",
      " |      1\n",
      " |      \n",
      " |      Set value at specified row/column pair\n",
      " |      \n",
      " |      >>> df.iat[1, 2] = 10\n",
      " |      >>> df.iat[1, 2]\n",
      " |      10\n",
      " |      \n",
      " |      Get value within a series\n",
      " |      \n",
      " |      >>> df.loc[0].iat[1]\n",
      " |      2\n",
      " |  \n",
      " |  iloc\n",
      " |      Purely integer-location based indexing for selection by position.\n",
      " |      \n",
      " |      ``.iloc[]`` is primarily integer position based (from ``0`` to\n",
      " |      ``length-1`` of the axis), but may also be used with a boolean\n",
      " |      array.\n",
      " |      \n",
      " |      Allowed inputs are:\n",
      " |      \n",
      " |      - An integer, e.g. ``5``.\n",
      " |      - A list or array of integers, e.g. ``[4, 3, 0]``.\n",
      " |      - A slice object with ints, e.g. ``1:7``.\n",
      " |      - A boolean array.\n",
      " |      - A ``callable`` function with one argument (the calling Series or\n",
      " |        DataFrame) and that returns valid output for indexing (one of the above).\n",
      " |        This is useful in method chains, when you don't have a reference to the\n",
      " |        calling object, but would like to base your selection on some value.\n",
      " |      \n",
      " |      ``.iloc`` will raise ``IndexError`` if a requested indexer is\n",
      " |      out-of-bounds, except *slice* indexers which allow out-of-bounds\n",
      " |      indexing (this conforms with python/numpy *slice* semantics).\n",
      " |      \n",
      " |      See more at :ref:`Selection by Position <indexing.integer>`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.iat : Fast integer location scalar accessor.\n",
      " |      DataFrame.loc : Purely label-location based indexer for selection by label.\n",
      " |      Series.iloc : Purely integer-location based indexing for\n",
      " |                     selection by position.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> mydict = [{'a': 1, 'b': 2, 'c': 3, 'd': 4},\n",
      " |      ...           {'a': 100, 'b': 200, 'c': 300, 'd': 400},\n",
      " |      ...           {'a': 1000, 'b': 2000, 'c': 3000, 'd': 4000 }]\n",
      " |      >>> df = pd.DataFrame(mydict)\n",
      " |      >>> df\n",
      " |            a     b     c     d\n",
      " |      0     1     2     3     4\n",
      " |      1   100   200   300   400\n",
      " |      2  1000  2000  3000  4000\n",
      " |      \n",
      " |      **Indexing just the rows**\n",
      " |      \n",
      " |      With a scalar integer.\n",
      " |      \n",
      " |      >>> type(df.iloc[0])\n",
      " |      <class 'pandas.core.series.Series'>\n",
      " |      >>> df.iloc[0]\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      c    3\n",
      " |      d    4\n",
      " |      Name: 0, dtype: int64\n",
      " |      \n",
      " |      With a list of integers.\n",
      " |      \n",
      " |      >>> df.iloc[[0]]\n",
      " |         a  b  c  d\n",
      " |      0  1  2  3  4\n",
      " |      >>> type(df.iloc[[0]])\n",
      " |      <class 'pandas.core.frame.DataFrame'>\n",
      " |      \n",
      " |      >>> df.iloc[[0, 1]]\n",
      " |           a    b    c    d\n",
      " |      0    1    2    3    4\n",
      " |      1  100  200  300  400\n",
      " |      \n",
      " |      With a `slice` object.\n",
      " |      \n",
      " |      >>> df.iloc[:3]\n",
      " |            a     b     c     d\n",
      " |      0     1     2     3     4\n",
      " |      1   100   200   300   400\n",
      " |      2  1000  2000  3000  4000\n",
      " |      \n",
      " |      With a boolean mask the same length as the index.\n",
      " |      \n",
      " |      >>> df.iloc[[True, False, True]]\n",
      " |            a     b     c     d\n",
      " |      0     1     2     3     4\n",
      " |      2  1000  2000  3000  4000\n",
      " |      \n",
      " |      With a callable, useful in method chains. The `x` passed\n",
      " |      to the ``lambda`` is the DataFrame being sliced. This selects\n",
      " |      the rows whose index label even.\n",
      " |      \n",
      " |      >>> df.iloc[lambda x: x.index % 2 == 0]\n",
      " |            a     b     c     d\n",
      " |      0     1     2     3     4\n",
      " |      2  1000  2000  3000  4000\n",
      " |      \n",
      " |      **Indexing both axes**\n",
      " |      \n",
      " |      You can mix the indexer types for the index and columns. Use ``:`` to\n",
      " |      select the entire axis.\n",
      " |      \n",
      " |      With scalar integers.\n",
      " |      \n",
      " |      >>> df.iloc[0, 1]\n",
      " |      2\n",
      " |      \n",
      " |      With lists of integers.\n",
      " |      \n",
      " |      >>> df.iloc[[0, 2], [1, 3]]\n",
      " |            b     d\n",
      " |      0     2     4\n",
      " |      2  2000  4000\n",
      " |      \n",
      " |      With `slice` objects.\n",
      " |      \n",
      " |      >>> df.iloc[1:3, 0:3]\n",
      " |            a     b     c\n",
      " |      1   100   200   300\n",
      " |      2  1000  2000  3000\n",
      " |      \n",
      " |      With a boolean array whose length matches the columns.\n",
      " |      \n",
      " |      >>> df.iloc[:, [True, False, True, False]]\n",
      " |            a     c\n",
      " |      0     1     3\n",
      " |      1   100   300\n",
      " |      2  1000  3000\n",
      " |      \n",
      " |      With a callable function that expects the Series or DataFrame.\n",
      " |      \n",
      " |      >>> df.iloc[:, lambda df: [0, 2]]\n",
      " |            a     c\n",
      " |      0     1     3\n",
      " |      1   100   300\n",
      " |      2  1000  3000\n",
      " |  \n",
      " |  loc\n",
      " |      Access a group of rows and columns by label(s) or a boolean array.\n",
      " |      \n",
      " |      ``.loc[]`` is primarily label based, but may also be used with a\n",
      " |      boolean array.\n",
      " |      \n",
      " |      Allowed inputs are:\n",
      " |      \n",
      " |      - A single label, e.g. ``5`` or ``'a'``, (note that ``5`` is\n",
      " |        interpreted as a *label* of the index, and **never** as an\n",
      " |        integer position along the index).\n",
      " |      - A list or array of labels, e.g. ``['a', 'b', 'c']``.\n",
      " |      - A slice object with labels, e.g. ``'a':'f'``.\n",
      " |      \n",
      " |        .. warning:: Note that contrary to usual python slices, **both** the\n",
      " |            start and the stop are included\n",
      " |      \n",
      " |      - A boolean array of the same length as the axis being sliced,\n",
      " |        e.g. ``[True, False, True]``.\n",
      " |      - An alignable boolean Series. The index of the key will be aligned before\n",
      " |        masking.\n",
      " |      - An alignable Index. The Index of the returned selection will be the input.\n",
      " |      - A ``callable`` function with one argument (the calling Series or\n",
      " |        DataFrame) and that returns valid output for indexing (one of the above)\n",
      " |      \n",
      " |      See more at :ref:`Selection by Label <indexing.label>`.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError\n",
      " |          If any items are not found.\n",
      " |      IndexingError\n",
      " |          If an indexed key is passed and its index is unalignable to the frame index.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.at : Access a single value for a row/column label pair.\n",
      " |      DataFrame.iloc : Access group of rows and columns by integer position(s).\n",
      " |      DataFrame.xs : Returns a cross-section (row(s) or column(s)) from the\n",
      " |          Series/DataFrame.\n",
      " |      Series.loc : Access group of values using labels.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Getting values**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],\n",
      " |      ...      index=['cobra', 'viper', 'sidewinder'],\n",
      " |      ...      columns=['max_speed', 'shield'])\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra               1       2\n",
      " |      viper               4       5\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Single label. Note this returns the row as a Series.\n",
      " |      \n",
      " |      >>> df.loc['viper']\n",
      " |      max_speed    4\n",
      " |      shield       5\n",
      " |      Name: viper, dtype: int64\n",
      " |      \n",
      " |      List of labels. Note using ``[[]]`` returns a DataFrame.\n",
      " |      \n",
      " |      >>> df.loc[['viper', 'sidewinder']]\n",
      " |                  max_speed  shield\n",
      " |      viper               4       5\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Single label for row and column\n",
      " |      \n",
      " |      >>> df.loc['cobra', 'shield']\n",
      " |      2\n",
      " |      \n",
      " |      Slice with labels for row and single label for column. As mentioned\n",
      " |      above, note that both the start and stop of the slice are included.\n",
      " |      \n",
      " |      >>> df.loc['cobra':'viper', 'max_speed']\n",
      " |      cobra    1\n",
      " |      viper    4\n",
      " |      Name: max_speed, dtype: int64\n",
      " |      \n",
      " |      Boolean list with the same length as the row axis\n",
      " |      \n",
      " |      >>> df.loc[[False, False, True]]\n",
      " |                  max_speed  shield\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Alignable boolean Series:\n",
      " |      \n",
      " |      >>> df.loc[pd.Series([False, True, False],\n",
      " |      ...        index=['viper', 'sidewinder', 'cobra'])]\n",
      " |                  max_speed  shield\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Index (same behavior as ``df.reindex``)\n",
      " |      \n",
      " |      >>> df.loc[pd.Index([\"cobra\", \"viper\"], name=\"foo\")]\n",
      " |             max_speed  shield\n",
      " |      foo\n",
      " |      cobra          1       2\n",
      " |      viper          4       5\n",
      " |      \n",
      " |      Conditional that returns a boolean Series\n",
      " |      \n",
      " |      >>> df.loc[df['shield'] > 6]\n",
      " |                  max_speed  shield\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Conditional that returns a boolean Series with column labels specified\n",
      " |      \n",
      " |      >>> df.loc[df['shield'] > 6, ['max_speed']]\n",
      " |                  max_speed\n",
      " |      sidewinder          7\n",
      " |      \n",
      " |      Callable that returns a boolean Series\n",
      " |      \n",
      " |      >>> df.loc[lambda df: df['shield'] == 8]\n",
      " |                  max_speed  shield\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      **Setting values**\n",
      " |      \n",
      " |      Set value for all items matching the list of labels\n",
      " |      \n",
      " |      >>> df.loc[['viper', 'sidewinder'], ['shield']] = 50\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra               1       2\n",
      " |      viper               4      50\n",
      " |      sidewinder          7      50\n",
      " |      \n",
      " |      Set value for an entire row\n",
      " |      \n",
      " |      >>> df.loc['cobra'] = 10\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra              10      10\n",
      " |      viper               4      50\n",
      " |      sidewinder          7      50\n",
      " |      \n",
      " |      Set value for an entire column\n",
      " |      \n",
      " |      >>> df.loc[:, 'max_speed'] = 30\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra              30      10\n",
      " |      viper              30      50\n",
      " |      sidewinder         30      50\n",
      " |      \n",
      " |      Set value for rows matching callable condition\n",
      " |      \n",
      " |      >>> df.loc[df['shield'] > 35] = 0\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra              30      10\n",
      " |      viper               0       0\n",
      " |      sidewinder          0       0\n",
      " |      \n",
      " |      **Getting values on a DataFrame with an index that has integer labels**\n",
      " |      \n",
      " |      Another example using integers for the index\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],\n",
      " |      ...      index=[7, 8, 9], columns=['max_speed', 'shield'])\n",
      " |      >>> df\n",
      " |         max_speed  shield\n",
      " |      7          1       2\n",
      " |      8          4       5\n",
      " |      9          7       8\n",
      " |      \n",
      " |      Slice with integer labels for rows. As mentioned above, note that both\n",
      " |      the start and stop of the slice are included.\n",
      " |      \n",
      " |      >>> df.loc[7:9]\n",
      " |         max_speed  shield\n",
      " |      7          1       2\n",
      " |      8          4       5\n",
      " |      9          7       8\n",
      " |      \n",
      " |      **Getting values with a MultiIndex**\n",
      " |      \n",
      " |      A number of examples using a DataFrame with a MultiIndex\n",
      " |      \n",
      " |      >>> tuples = [\n",
      " |      ...    ('cobra', 'mark i'), ('cobra', 'mark ii'),\n",
      " |      ...    ('sidewinder', 'mark i'), ('sidewinder', 'mark ii'),\n",
      " |      ...    ('viper', 'mark ii'), ('viper', 'mark iii')\n",
      " |      ... ]\n",
      " |      >>> index = pd.MultiIndex.from_tuples(tuples)\n",
      " |      >>> values = [[12, 2], [0, 4], [10, 20],\n",
      " |      ...         [1, 4], [7, 1], [16, 36]]\n",
      " |      >>> df = pd.DataFrame(values, columns=['max_speed', 'shield'], index=index)\n",
      " |      >>> df\n",
      " |                           max_speed  shield\n",
      " |      cobra      mark i           12       2\n",
      " |                 mark ii           0       4\n",
      " |      sidewinder mark i           10      20\n",
      " |                 mark ii           1       4\n",
      " |      viper      mark ii           7       1\n",
      " |                 mark iii         16      36\n",
      " |      \n",
      " |      Single label. Note this returns a DataFrame with a single index.\n",
      " |      \n",
      " |      >>> df.loc['cobra']\n",
      " |               max_speed  shield\n",
      " |      mark i          12       2\n",
      " |      mark ii          0       4\n",
      " |      \n",
      " |      Single index tuple. Note this returns a Series.\n",
      " |      \n",
      " |      >>> df.loc[('cobra', 'mark ii')]\n",
      " |      max_speed    0\n",
      " |      shield       4\n",
      " |      Name: (cobra, mark ii), dtype: int64\n",
      " |      \n",
      " |      Single label for row and column. Similar to passing in a tuple, this\n",
      " |      returns a Series.\n",
      " |      \n",
      " |      >>> df.loc['cobra', 'mark i']\n",
      " |      max_speed    12\n",
      " |      shield        2\n",
      " |      Name: (cobra, mark i), dtype: int64\n",
      " |      \n",
      " |      Single tuple. Note using ``[[]]`` returns a DataFrame.\n",
      " |      \n",
      " |      >>> df.loc[[('cobra', 'mark ii')]]\n",
      " |                     max_speed  shield\n",
      " |      cobra mark ii          0       4\n",
      " |      \n",
      " |      Single tuple for the index with a single label for the column\n",
      " |      \n",
      " |      >>> df.loc[('cobra', 'mark i'), 'shield']\n",
      " |      2\n",
      " |      \n",
      " |      Slice from index tuple to single label\n",
      " |      \n",
      " |      >>> df.loc[('cobra', 'mark i'):'viper']\n",
      " |                           max_speed  shield\n",
      " |      cobra      mark i           12       2\n",
      " |                 mark ii           0       4\n",
      " |      sidewinder mark i           10      20\n",
      " |                 mark ii           1       4\n",
      " |      viper      mark ii           7       1\n",
      " |                 mark iii         16      36\n",
      " |      \n",
      " |      Slice from index tuple to index tuple\n",
      " |      \n",
      " |      >>> df.loc[('cobra', 'mark i'):('viper', 'mark ii')]\n",
      " |                          max_speed  shield\n",
      " |      cobra      mark i          12       2\n",
      " |                 mark ii          0       4\n",
      " |      sidewinder mark i          10      20\n",
      " |                 mark ii          1       4\n",
      " |      viper      mark ii          7       1\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.arraylike.OpsMixin:\n",
      " |  \n",
      " |  __add__(self, other)\n",
      " |  \n",
      " |  __and__(self, other)\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __floordiv__(self, other)\n",
      " |  \n",
      " |  __ge__(self, other)\n",
      " |      Return self>=value.\n",
      " |  \n",
      " |  __gt__(self, other)\n",
      " |      Return self>value.\n",
      " |  \n",
      " |  __le__(self, other)\n",
      " |      Return self<=value.\n",
      " |  \n",
      " |  __lt__(self, other)\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __mod__(self, other)\n",
      " |  \n",
      " |  __mul__(self, other)\n",
      " |  \n",
      " |  __ne__(self, other)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  __or__(self, other)\n",
      " |  \n",
      " |  __pow__(self, other)\n",
      " |  \n",
      " |  __radd__(self, other)\n",
      " |  \n",
      " |  __rand__(self, other)\n",
      " |  \n",
      " |  __rfloordiv__(self, other)\n",
      " |  \n",
      " |  __rmod__(self, other)\n",
      " |  \n",
      " |  __rmul__(self, other)\n",
      " |  \n",
      " |  __ror__(self, other)\n",
      " |  \n",
      " |  __rpow__(self, other)\n",
      " |  \n",
      " |  __rsub__(self, other)\n",
      " |  \n",
      " |  __rtruediv__(self, other)\n",
      " |  \n",
      " |  __rxor__(self, other)\n",
      " |  \n",
      " |  __sub__(self, other)\n",
      " |  \n",
      " |  __truediv__(self, other)\n",
      " |  \n",
      " |  __xor__(self, other)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pandas.core.arraylike.OpsMixin:\n",
      " |  \n",
      " |  __hash__ = None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "bcff959b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pred\n",
       "0       3\n",
       "1       3\n",
       "2       2\n",
       "3       3\n",
       "4       1\n",
       "5       3\n",
       "6       3\n",
       "7       1\n",
       "8       3\n",
       "9       0\n",
       "..    ...\n",
       "990     2\n",
       "991     3\n",
       "992     3\n",
       "993     0\n",
       "994     0\n",
       "995     2\n",
       "996     1\n",
       "997     0\n",
       "998     2\n",
       "999     2\n",
       "\n",
       "[1000 rows x 1 columns]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred = pd.DataFrame(df_pred, columns=[\"Pred\"])\n",
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "d1521ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>pc</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.475451</td>\n",
       "      <td>1</td>\n",
       "      <td>0.312601</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.581269</td>\n",
       "      <td>-1.487247</td>\n",
       "      <td>1.535535</td>\n",
       "      <td>-0.580671</td>\n",
       "      <td>0.976026</td>\n",
       "      <td>-0.926990</td>\n",
       "      <td>0.391912</td>\n",
       "      <td>1.229373</td>\n",
       "      <td>0.001158</td>\n",
       "      <td>0.397363</td>\n",
       "      <td>-1.653355</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.942782</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.255832</td>\n",
       "      <td>1</td>\n",
       "      <td>1.509303</td>\n",
       "      <td>1.006341</td>\n",
       "      <td>1.478120</td>\n",
       "      <td>0.293833</td>\n",
       "      <td>0.319433</td>\n",
       "      <td>0.274729</td>\n",
       "      <td>-0.871028</td>\n",
       "      <td>1.614643</td>\n",
       "      <td>-1.388231</td>\n",
       "      <td>-1.254383</td>\n",
       "      <td>-0.743418</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.292077</td>\n",
       "      <td>1</td>\n",
       "      <td>1.519087</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.367116</td>\n",
       "      <td>1.362567</td>\n",
       "      <td>1.334582</td>\n",
       "      <td>-0.580671</td>\n",
       "      <td>-0.993754</td>\n",
       "      <td>1.485693</td>\n",
       "      <td>0.287236</td>\n",
       "      <td>0.236313</td>\n",
       "      <td>1.158982</td>\n",
       "      <td>1.105254</td>\n",
       "      <td>-0.197456</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.688249</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.255832</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.477493</td>\n",
       "      <td>-0.062340</td>\n",
       "      <td>-1.249091</td>\n",
       "      <td>1.605590</td>\n",
       "      <td>1.632619</td>\n",
       "      <td>-0.767532</td>\n",
       "      <td>1.165604</td>\n",
       "      <td>1.612804</td>\n",
       "      <td>-0.461972</td>\n",
       "      <td>-1.254383</td>\n",
       "      <td>-0.743418</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.429135</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.169994</td>\n",
       "      <td>0</td>\n",
       "      <td>0.847037</td>\n",
       "      <td>-0.062340</td>\n",
       "      <td>-0.904602</td>\n",
       "      <td>0.731085</td>\n",
       "      <td>1.304323</td>\n",
       "      <td>0.281662</td>\n",
       "      <td>-0.977979</td>\n",
       "      <td>-0.336535</td>\n",
       "      <td>0.695852</td>\n",
       "      <td>0.633326</td>\n",
       "      <td>-0.743418</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.498540</td>\n",
       "      <td>1</td>\n",
       "      <td>1.639736</td>\n",
       "      <td>1</td>\n",
       "      <td>0.902226</td>\n",
       "      <td>1.006341</td>\n",
       "      <td>1.679072</td>\n",
       "      <td>1.605590</td>\n",
       "      <td>-0.173012</td>\n",
       "      <td>-0.134318</td>\n",
       "      <td>-0.684431</td>\n",
       "      <td>1.256958</td>\n",
       "      <td>-0.461972</td>\n",
       "      <td>0.397363</td>\n",
       "      <td>-1.471368</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.086174</td>\n",
       "      <td>0</td>\n",
       "      <td>1.036493</td>\n",
       "      <td>0</td>\n",
       "      <td>0.736660</td>\n",
       "      <td>1.718794</td>\n",
       "      <td>0.473358</td>\n",
       "      <td>-1.017923</td>\n",
       "      <td>-1.157902</td>\n",
       "      <td>1.515736</td>\n",
       "      <td>0.305440</td>\n",
       "      <td>1.594414</td>\n",
       "      <td>0.464287</td>\n",
       "      <td>-0.782455</td>\n",
       "      <td>-0.197456</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.961290</td>\n",
       "      <td>0</td>\n",
       "      <td>1.036493</td>\n",
       "      <td>1</td>\n",
       "      <td>1.564491</td>\n",
       "      <td>1.006341</td>\n",
       "      <td>-0.818479</td>\n",
       "      <td>-1.455175</td>\n",
       "      <td>-1.322051</td>\n",
       "      <td>1.582755</td>\n",
       "      <td>1.456877</td>\n",
       "      <td>-0.592156</td>\n",
       "      <td>-1.156666</td>\n",
       "      <td>-0.782455</td>\n",
       "      <td>1.258443</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.318132</td>\n",
       "      <td>1</td>\n",
       "      <td>1.639736</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.477493</td>\n",
       "      <td>0.293887</td>\n",
       "      <td>-1.105554</td>\n",
       "      <td>0.293833</td>\n",
       "      <td>1.468471</td>\n",
       "      <td>-0.164361</td>\n",
       "      <td>-0.827792</td>\n",
       "      <td>1.237648</td>\n",
       "      <td>-0.230407</td>\n",
       "      <td>0.869290</td>\n",
       "      <td>-0.197456</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.628097</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.255832</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.477493</td>\n",
       "      <td>-0.062340</td>\n",
       "      <td>0.903970</td>\n",
       "      <td>-0.580671</td>\n",
       "      <td>1.632619</td>\n",
       "      <td>-1.329104</td>\n",
       "      <td>-0.525141</td>\n",
       "      <td>-1.368214</td>\n",
       "      <td>-1.388231</td>\n",
       "      <td>-1.254383</td>\n",
       "      <td>-1.107393</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>1.292077</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.411291</td>\n",
       "      <td>0</td>\n",
       "      <td>0.184772</td>\n",
       "      <td>1.006341</td>\n",
       "      <td>0.645603</td>\n",
       "      <td>-1.455175</td>\n",
       "      <td>0.155284</td>\n",
       "      <td>-0.880770</td>\n",
       "      <td>-0.700360</td>\n",
       "      <td>0.553541</td>\n",
       "      <td>-1.156666</td>\n",
       "      <td>-1.018419</td>\n",
       "      <td>-0.379444</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>1.268942</td>\n",
       "      <td>1</td>\n",
       "      <td>1.277790</td>\n",
       "      <td>0</td>\n",
       "      <td>0.460716</td>\n",
       "      <td>0.293887</td>\n",
       "      <td>0.990092</td>\n",
       "      <td>-0.580671</td>\n",
       "      <td>1.632619</td>\n",
       "      <td>-1.317549</td>\n",
       "      <td>-0.161051</td>\n",
       "      <td>1.121791</td>\n",
       "      <td>0.927417</td>\n",
       "      <td>0.161399</td>\n",
       "      <td>1.258443</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>1.495667</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.255832</td>\n",
       "      <td>1</td>\n",
       "      <td>1.564491</td>\n",
       "      <td>1.362567</td>\n",
       "      <td>-1.162969</td>\n",
       "      <td>-1.017923</td>\n",
       "      <td>-1.650347</td>\n",
       "      <td>0.905632</td>\n",
       "      <td>1.042724</td>\n",
       "      <td>0.389870</td>\n",
       "      <td>-0.461972</td>\n",
       "      <td>0.633326</td>\n",
       "      <td>0.348506</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>-1.576686</td>\n",
       "      <td>1</td>\n",
       "      <td>1.398439</td>\n",
       "      <td>1</td>\n",
       "      <td>1.233359</td>\n",
       "      <td>-0.418566</td>\n",
       "      <td>0.731725</td>\n",
       "      <td>1.605590</td>\n",
       "      <td>1.140174</td>\n",
       "      <td>-0.166672</td>\n",
       "      <td>0.114293</td>\n",
       "      <td>-1.657856</td>\n",
       "      <td>-1.156666</td>\n",
       "      <td>0.161399</td>\n",
       "      <td>-0.743418</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>-0.722998</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.169994</td>\n",
       "      <td>1</td>\n",
       "      <td>0.681471</td>\n",
       "      <td>1.006341</td>\n",
       "      <td>-0.014670</td>\n",
       "      <td>-1.017923</td>\n",
       "      <td>-1.650347</td>\n",
       "      <td>-0.836861</td>\n",
       "      <td>-0.805036</td>\n",
       "      <td>-1.337870</td>\n",
       "      <td>-0.925101</td>\n",
       "      <td>-0.074565</td>\n",
       "      <td>0.166518</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1.044531</td>\n",
       "      <td>1</td>\n",
       "      <td>0.433249</td>\n",
       "      <td>0</td>\n",
       "      <td>1.122981</td>\n",
       "      <td>-0.062340</td>\n",
       "      <td>0.875263</td>\n",
       "      <td>1.168338</td>\n",
       "      <td>1.140174</td>\n",
       "      <td>0.039007</td>\n",
       "      <td>-0.743596</td>\n",
       "      <td>-0.016549</td>\n",
       "      <td>0.464287</td>\n",
       "      <td>0.633326</td>\n",
       "      <td>0.712481</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-1.479519</td>\n",
       "      <td>0</td>\n",
       "      <td>0.312601</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.139759</td>\n",
       "      <td>1.362567</td>\n",
       "      <td>1.334582</td>\n",
       "      <td>-0.143419</td>\n",
       "      <td>-1.322051</td>\n",
       "      <td>1.212995</td>\n",
       "      <td>0.892536</td>\n",
       "      <td>-0.189415</td>\n",
       "      <td>-0.925101</td>\n",
       "      <td>-1.018419</td>\n",
       "      <td>1.440430</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-0.146932</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.169994</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.415702</td>\n",
       "      <td>-0.062340</td>\n",
       "      <td>-1.708411</td>\n",
       "      <td>-1.455175</td>\n",
       "      <td>0.319433</td>\n",
       "      <td>-0.346930</td>\n",
       "      <td>-0.943846</td>\n",
       "      <td>-0.842260</td>\n",
       "      <td>-1.619796</td>\n",
       "      <td>-1.254383</td>\n",
       "      <td>0.530493</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.658173</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.255832</td>\n",
       "      <td>1</td>\n",
       "      <td>0.902226</td>\n",
       "      <td>-0.418566</td>\n",
       "      <td>0.903970</td>\n",
       "      <td>-1.017923</td>\n",
       "      <td>0.319433</td>\n",
       "      <td>-1.361458</td>\n",
       "      <td>-0.927917</td>\n",
       "      <td>0.340217</td>\n",
       "      <td>0.695852</td>\n",
       "      <td>1.341217</td>\n",
       "      <td>-0.925406</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.049718</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.255832</td>\n",
       "      <td>0</td>\n",
       "      <td>0.074394</td>\n",
       "      <td>-1.487247</td>\n",
       "      <td>0.014038</td>\n",
       "      <td>0.731085</td>\n",
       "      <td>1.468471</td>\n",
       "      <td>-0.393150</td>\n",
       "      <td>-1.437643</td>\n",
       "      <td>0.633537</td>\n",
       "      <td>-0.693537</td>\n",
       "      <td>-0.782455</td>\n",
       "      <td>-1.471368</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     battery_power  blue  clock_speed  dual_sim  int_memory     m_dep  \\\n",
       "0        -0.475451     1     0.312601         1   -1.581269 -1.487247   \n",
       "1        -0.942782     1    -1.255832         1    1.509303  1.006341   \n",
       "2         1.292077     1     1.519087         0   -0.367116  1.362567   \n",
       "3         0.688249     0    -1.255832         1   -0.477493 -0.062340   \n",
       "4         0.429135     0    -0.169994         0    0.847037 -0.062340   \n",
       "5         0.498540     1     1.639736         1    0.902226  1.006341   \n",
       "6         1.086174     0     1.036493         0    0.736660  1.718794   \n",
       "7        -0.961290     0     1.036493         1    1.564491  1.006341   \n",
       "8        -0.318132     1     1.639736         1   -0.477493  0.293887   \n",
       "9         0.628097     0    -1.255832         0   -0.477493 -0.062340   \n",
       "..             ...   ...          ...       ...         ...       ...   \n",
       "990       1.292077     0    -0.411291         0    0.184772  1.006341   \n",
       "991       1.268942     1     1.277790         0    0.460716  0.293887   \n",
       "992       1.495667     0    -1.255832         1    1.564491  1.362567   \n",
       "993      -1.576686     1     1.398439         1    1.233359 -0.418566   \n",
       "994      -0.722998     1    -0.169994         1    0.681471  1.006341   \n",
       "995       1.044531     1     0.433249         0    1.122981 -0.062340   \n",
       "996      -1.479519     0     0.312601         1   -1.139759  1.362567   \n",
       "997      -0.146932     0    -0.169994         0   -1.415702 -0.062340   \n",
       "998       0.658173     1    -1.255832         1    0.902226 -0.418566   \n",
       "999       0.049718     1    -1.255832         0    0.074394 -1.487247   \n",
       "\n",
       "     mobile_wt   n_cores        pc  px_height  px_width       ram      sc_h  \\\n",
       "0     1.535535 -0.580671  0.976026  -0.926990  0.391912  1.229373  0.001158   \n",
       "1     1.478120  0.293833  0.319433   0.274729 -0.871028  1.614643 -1.388231   \n",
       "2     1.334582 -0.580671 -0.993754   1.485693  0.287236  0.236313  1.158982   \n",
       "3    -1.249091  1.605590  1.632619  -0.767532  1.165604  1.612804 -0.461972   \n",
       "4    -0.904602  0.731085  1.304323   0.281662 -0.977979 -0.336535  0.695852   \n",
       "5     1.679072  1.605590 -0.173012  -0.134318 -0.684431  1.256958 -0.461972   \n",
       "6     0.473358 -1.017923 -1.157902   1.515736  0.305440  1.594414  0.464287   \n",
       "7    -0.818479 -1.455175 -1.322051   1.582755  1.456877 -0.592156 -1.156666   \n",
       "8    -1.105554  0.293833  1.468471  -0.164361 -0.827792  1.237648 -0.230407   \n",
       "9     0.903970 -0.580671  1.632619  -1.329104 -0.525141 -1.368214 -1.388231   \n",
       "..         ...       ...       ...        ...       ...       ...       ...   \n",
       "990   0.645603 -1.455175  0.155284  -0.880770 -0.700360  0.553541 -1.156666   \n",
       "991   0.990092 -0.580671  1.632619  -1.317549 -0.161051  1.121791  0.927417   \n",
       "992  -1.162969 -1.017923 -1.650347   0.905632  1.042724  0.389870 -0.461972   \n",
       "993   0.731725  1.605590  1.140174  -0.166672  0.114293 -1.657856 -1.156666   \n",
       "994  -0.014670 -1.017923 -1.650347  -0.836861 -0.805036 -1.337870 -0.925101   \n",
       "995   0.875263  1.168338  1.140174   0.039007 -0.743596 -0.016549  0.464287   \n",
       "996   1.334582 -0.143419 -1.322051   1.212995  0.892536 -0.189415 -0.925101   \n",
       "997  -1.708411 -1.455175  0.319433  -0.346930 -0.943846 -0.842260 -1.619796   \n",
       "998   0.903970 -1.017923  0.319433  -1.361458 -0.927917  0.340217  0.695852   \n",
       "999   0.014038  0.731085  1.468471  -0.393150 -1.437643  0.633537 -0.693537   \n",
       "\n",
       "         sc_w  talk_time  three_g  touch_screen  wifi  Pred  \n",
       "0    0.397363  -1.653355        0             1     0     3  \n",
       "1   -1.254383  -0.743418        1             0     0     3  \n",
       "2    1.105254  -0.197456        0             1     1     2  \n",
       "3   -1.254383  -0.743418        1             1     0     3  \n",
       "4    0.633326  -0.743418        1             0     1     1  \n",
       "5    0.397363  -1.471368        1             1     1     3  \n",
       "6   -0.782455  -0.197456        0             0     0     3  \n",
       "7   -0.782455   1.258443        0             1     1     1  \n",
       "8    0.869290  -0.197456        1             1     0     3  \n",
       "9   -1.254383  -1.107393        1             0     1     0  \n",
       "..        ...        ...      ...           ...   ...   ...  \n",
       "990 -1.018419  -0.379444        1             1     1     2  \n",
       "991  0.161399   1.258443        1             1     1     3  \n",
       "992  0.633326   0.348506        1             0     1     3  \n",
       "993  0.161399  -0.743418        1             1     1     0  \n",
       "994 -0.074565   0.166518        1             1     1     0  \n",
       "995  0.633326   0.712481        1             1     0     2  \n",
       "996 -1.018419   1.440430        0             1     1     1  \n",
       "997 -1.254383   0.530493        1             0     0     0  \n",
       "998  1.341217  -0.925406        0             1     0     2  \n",
       "999 -0.782455  -1.471368        1             0     1     2  \n",
       "\n",
       "[1000 rows x 19 columns]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_pred = pd.merge(df_test,df_pred, how=\"right\", left_index=True, right_index=True)\n",
    "df_test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e7707e",
   "metadata": {},
   "source": [
    "# 5/ Optimisation des hyper-paramètres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f29a44d",
   "metadata": {},
   "source": [
    "# 6/ Explication de l'importance des variables (Shap value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52e26c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
